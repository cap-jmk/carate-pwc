{"cells":[{"cell_type":"markdown","metadata":{"id":"vItLD--qsu06"},"source":["# CARATE-BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":681},"executionInfo":{"elapsed":254837,"status":"ok","timestamp":1621935261924,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"pG6IoPOFvuPS","outputId":"4966e348-a55c-4f61-cf56-2f70822495a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (19.3.1)\n","Requirement already satisfied: install in /usr/local/lib/python3.7/dist-packages (1.3.4)\n","Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.7/dist-packages (2021.3.2.1)\n","Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi) (1.19.5)\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.8.1+cu111\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2MB)\n","\u001b[K     |█████████████▌                  | 834.1MB 1.3MB/s eta 0:14:41tcmalloc: large alloc 1147494400 bytes == 0x56429bb32000 @  0x7f362a520615 0x5642624c1cdc 0x5642625a152a 0x5642624c4afd 0x5642625b5fed 0x564262538988 0x5642625334ae 0x5642624c63ea 0x5642625387f0 0x5642625334ae 0x5642624c63ea 0x56426253532a 0x5642625b6e36 0x564262534853 0x5642625b6e36 0x564262534853 0x5642625b6e36 0x564262534853 0x5642625b6e36 0x5642626393e1 0x5642625996a9 0x564262504cc4 0x5642624c5559 0x5642625394f8 0x5642624c630a 0x5642625343b5 0x5642625337ad 0x5642624c63ea 0x5642625343b5 0x5642624c630a 0x5642625343b5\n","\u001b[K     |█████████████████               | 1055.7MB 1.3MB/s eta 0:12:16tcmalloc: large alloc 1434370048 bytes == 0x5642e0188000 @  0x7f362a520615 0x5642624c1cdc 0x5642625a152a 0x5642624c4afd 0x5642625b5fed 0x564262538988 0x5642625334ae 0x5642624c63ea 0x5642625387f0 0x5642625334ae 0x5642624c63ea 0x56426253532a 0x5642625b6e36 0x564262534853 0x5642625b6e36 0x564262534853 0x5642625b6e36 0x564262534853 0x5642625b6e36 0x5642626393e1 0x5642625996a9 0x564262504cc4 0x5642624c5559 0x5642625394f8 0x5642624c630a 0x5642625343b5 0x5642625337ad 0x5642624c63ea 0x5642625343b5 0x5642624c630a 0x5642625343b5\n","\u001b[K     |█████████████████████▋          | 1336.2MB 1.2MB/s eta 0:09:03tcmalloc: large alloc 1792966656 bytes == 0x564264fba000 @  0x7f362a520615 0x5642624c1cdc 0x5642625a152a 0x5642624c4afd 0x5642625b5fed 0x564262538988 0x5642625334ae 0x5642624c63ea 0x5642625387f0 0x5642625334ae 0x5642624c63ea 0x56426253532a 0x5642625b6e36 0x564262534853 0x5642625b6e36 0x564262534853 0x5642625b6e36 0x564262534853 0x5642625b6e36 0x5642626393e1 0x5642625996a9 0x564262504cc4 0x5642624c5559 0x5642625394f8 0x5642624c630a 0x5642625343b5 0x5642625337ad 0x5642624c63ea 0x5642625343b5 0x5642624c630a 0x5642625343b5\n","\u001b[K     |███████████████████████████▎    | 1691.1MB 77.4MB/s eta 0:00:04tcmalloc: large alloc 2241208320 bytes == 0x5642cfda2000 @  0x7f362a520615 0x5642624c1cdc 0x5642625a152a 0x5642624c4afd 0x5642625b5fed 0x564262538988 0x5642625334ae 0x5642624c63ea 0x5642625387f0 0x5642625334ae 0x5642624c63ea 0x56426253532a 0x5642625b6e36 0x564262534853 0x5642625b6e36 0x564262534853 0x5642625b6e36 0x564262534853 0x5642625b6e36 0x5642626393e1 0x5642625996a9 0x564262504cc4 0x5642624c5559 0x5642625394f8 0x5642624c630a 0x5642625343b5 0x5642625337ad 0x5642624c63ea 0x5642625343b5 0x5642624c630a 0x5642625343b5\n","\u001b[K     |████████████████████████████████| 1982.2MB 117.7MB/s eta 0:00:01tcmalloc: large alloc 1982177280 bytes == 0x564355704000 @  0x7f362a51f1e7 0x5642624f7f37 0x5642624c1cdc 0x5642625a152a 0x5642624c4afd 0x5642625b5fed 0x564262538988 0x5642625334ae 0x5642624c63ea 0x56426253460e 0x5642625334ae 0x5642624c63ea 0x56426253460e 0x5642625334ae 0x5642624c63ea 0x56426253460e 0x5642625334ae 0x5642624c63ea 0x56426253460e 0x5642625334ae 0x5642624c63ea 0x56426253460e 0x5642624c630a 0x56426253460e 0x5642625334ae 0x5642624c63ea 0x56426253532a 0x5642625334ae 0x5642624c63ea 0x56426253532a 0x5642625334ae\n","tcmalloc: large alloc 2477727744 bytes == 0x56443fe20000 @  0x7f362a520615 0x5642624c1cdc 0x5642625a152a 0x5642624c4afd 0x5642625b5fed 0x564262538988 0x5642625334ae 0x5642624c63ea 0x56426253460e 0x5642625334ae 0x5642624c63ea 0x56426253460e 0x5642625334ae 0x5642624c63ea 0x56426253460e 0x5642625334ae 0x5642624c63ea 0x56426253460e 0x5642625334ae 0x5642624c63ea 0x56426253460e 0x5642624c630a 0x56426253460e 0x5642625334ae 0x5642624c63ea 0x56426253532a 0x5642625334ae 0x5642624c63ea 0x56426253532a 0x5642625334ae 0x5642624c6a81\n","\u001b[K     |████████████████████████████████| 1982.2MB 6.4kB/s \n","\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/torchvision/\u001b[0m\n","\u001b[?25hCollecting torchvision==0.9.1+cu111\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6MB)\n","\u001b[K     |████████████████████████████████| 17.6MB 342kB/s \n","\u001b[?25hCollecting torchaudio==0.8.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n","\u001b[K     |████████████████████████████████| 1.9MB 15.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (3.7.4.3)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu111) (7.1.2)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Found existing installation: torch 1.8.1+cu101\n","    Uninstalling torch-1.8.1+cu101:\n","      Successfully uninstalled torch-1.8.1+cu101\n","  Found existing installation: torchvision 0.9.1+cu101\n","    Uninstalling torchvision-0.9.1+cu101:\n","      Successfully uninstalled torchvision-0.9.1+cu101\n","Successfully installed torch-1.8.1+cu111 torchaudio-0.8.1 torchvision-0.9.1+cu111\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch","torchvision"]}}},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["\n","!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n","!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n","!pip install -q torch-geometric\n","!pip install rdkit-pypi\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZGIvEN36tMwy"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jbIOeyJvLw-3"},"outputs":[],"source":["def save_training_data(output_proba): \n","  \"\"\"\n","  Saves the training data to txt to plot AUC_ROC_CURVES\n","  \"\"\"\n","  file \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21523,"status":"ok","timestamp":1640360042274,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"2YPYO9QVsJOk","outputId":"fb983251-5732-46b0-f2df-85fda7c5380f"},"outputs":[{"name":"stdout","output_type":"stream","text":["PREFIX=/usr/local\n","Unpacking payload ...\n","Collecting package metadata (current_repodata.json): ...working... done\n","Solving environment: ...working... done\n","\n","## Package Plan ##\n","\n","  environment location: /usr/local\n","\n","  added / updated specs:\n","    - _libgcc_mutex==0.1=main\n","    - _openmp_mutex==4.5=1_gnu\n","    - brotlipy==0.7.0=py39h27cfd23_1003\n","    - ca-certificates==2021.7.5=h06a4308_1\n","    - certifi==2021.5.30=py39h06a4308_0\n","    - cffi==1.14.6=py39h400218f_0\n","    - chardet==4.0.0=py39h06a4308_1003\n","    - conda-package-handling==1.7.3=py39h27cfd23_1\n","    - conda==4.10.3=py39h06a4308_0\n","    - cryptography==3.4.7=py39hd23ed53_0\n","    - idna==2.10=pyhd3eb1b0_0\n","    - ld_impl_linux-64==2.35.1=h7274673_9\n","    - libffi==3.3=he6710b0_2\n","    - libgcc-ng==9.3.0=h5101ec6_17\n","    - libgomp==9.3.0=h5101ec6_17\n","    - libstdcxx-ng==9.3.0=hd4cf53a_17\n","    - ncurses==6.2=he6710b0_1\n","    - openssl==1.1.1k=h27cfd23_0\n","    - pip==21.1.3=py39h06a4308_0\n","    - pycosat==0.6.3=py39h27cfd23_0\n","    - pycparser==2.20=py_2\n","    - pyopenssl==20.0.1=pyhd3eb1b0_1\n","    - pysocks==1.7.1=py39h06a4308_0\n","    - python==3.9.5=h12debd9_4\n","    - readline==8.1=h27cfd23_0\n","    - requests==2.25.1=pyhd3eb1b0_0\n","    - ruamel_yaml==0.15.100=py39h27cfd23_0\n","    - setuptools==52.0.0=py39h06a4308_0\n","    - six==1.16.0=pyhd3eb1b0_0\n","    - sqlite==3.36.0=hc218d9a_0\n","    - tk==8.6.10=hbc83047_0\n","    - tqdm==4.61.2=pyhd3eb1b0_1\n","    - tzdata==2021a=h52ac0ba_0\n","    - urllib3==1.26.6=pyhd3eb1b0_1\n","    - wheel==0.36.2=pyhd3eb1b0_0\n","    - xz==5.2.5=h7b6447c_0\n","    - yaml==0.2.5=h7b6447c_0\n","    - zlib==1.2.11=h7b6447c_3\n","\n","\n","The following NEW packages will be INSTALLED:\n","\n","  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n","  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-4.5-1_gnu\n","  brotlipy           pkgs/main/linux-64::brotlipy-0.7.0-py39h27cfd23_1003\n","  ca-certificates    pkgs/main/linux-64::ca-certificates-2021.7.5-h06a4308_1\n","  certifi            pkgs/main/linux-64::certifi-2021.5.30-py39h06a4308_0\n","  cffi               pkgs/main/linux-64::cffi-1.14.6-py39h400218f_0\n","  chardet            pkgs/main/linux-64::chardet-4.0.0-py39h06a4308_1003\n","  conda              pkgs/main/linux-64::conda-4.10.3-py39h06a4308_0\n","  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.7.3-py39h27cfd23_1\n","  cryptography       pkgs/main/linux-64::cryptography-3.4.7-py39hd23ed53_0\n","  idna               pkgs/main/noarch::idna-2.10-pyhd3eb1b0_0\n","  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.35.1-h7274673_9\n","  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n","  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.3.0-h5101ec6_17\n","  libgomp            pkgs/main/linux-64::libgomp-9.3.0-h5101ec6_17\n","  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.3.0-hd4cf53a_17\n","  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1\n","  openssl            pkgs/main/linux-64::openssl-1.1.1k-h27cfd23_0\n","  pip                pkgs/main/linux-64::pip-21.1.3-py39h06a4308_0\n","  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py39h27cfd23_0\n","  pycparser          pkgs/main/noarch::pycparser-2.20-py_2\n","  pyopenssl          pkgs/main/noarch::pyopenssl-20.0.1-pyhd3eb1b0_1\n","  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py39h06a4308_0\n","  python             pkgs/main/linux-64::python-3.9.5-h12debd9_4\n","  readline           pkgs/main/linux-64::readline-8.1-h27cfd23_0\n","  requests           pkgs/main/noarch::requests-2.25.1-pyhd3eb1b0_0\n","  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.100-py39h27cfd23_0\n","  setuptools         pkgs/main/linux-64::setuptools-52.0.0-py39h06a4308_0\n","  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_0\n","  sqlite             pkgs/main/linux-64::sqlite-3.36.0-hc218d9a_0\n","  tk                 pkgs/main/linux-64::tk-8.6.10-hbc83047_0\n","  tqdm               pkgs/main/noarch::tqdm-4.61.2-pyhd3eb1b0_1\n","  tzdata             pkgs/main/noarch::tzdata-2021a-h52ac0ba_0\n","  urllib3            pkgs/main/noarch::urllib3-1.26.6-pyhd3eb1b0_1\n","  wheel              pkgs/main/noarch::wheel-0.36.2-pyhd3eb1b0_0\n","  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n","  yaml               pkgs/main/linux-64::yaml-0.2.5-h7b6447c_0\n","  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n","\n","\n","Preparing transaction: ...working... done\n","Executing transaction: ...working... done\n","installation finished.\n","WARNING:\n","    You currently have a PYTHONPATH environment variable set. This may cause\n","    unexpected behavior when running the Python interpreter in Miniconda3.\n","    For best results, please verify that your PYTHONPATH only points to\n","    directories of packages that are compatible with the Python interpreter\n","    in Miniconda3: /usr/local\n"]},{"name":"stderr","output_type":"stream","text":["--2021-12-24 15:33:40--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c84f, ...\n","Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh [following]\n","--2021-12-24 15:33:40--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n","Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 66709754 (64M) [application/x-sh]\n","Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n","\n","     0K .......... .......... .......... .......... ..........  0% 66.6M 1s\n","    50K .......... .......... .......... .......... ..........  0% 2.42M 14s\n","   100K .......... .......... .......... .......... ..........  0% 76.1M 9s\n","   150K .......... .......... .......... .......... ..........  0%  101M 7s\n","   200K .......... .......... .......... .......... ..........  0% 5.06M 8s\n","   250K .......... .......... .......... .......... ..........  0%  140M 7s\n","   300K .......... .......... .......... .......... ..........  0% 67.3M 6s\n","   350K .......... .......... .......... .......... ..........  0% 68.2M 5s\n","   400K .......... .......... .......... .......... ..........  0%  200M 5s\n","   450K .......... .......... .......... .......... ..........  0% 58.3M 4s\n","   500K .......... .......... .......... .......... ..........  0% 71.7M 4s\n","   550K .......... .......... .......... .......... ..........  0% 65.3M 4s\n","   600K .......... .......... .......... .......... ..........  0% 7.64M 4s\n","   650K .......... .......... .......... .......... ..........  1%  182M 4s\n","   700K .......... .......... .......... .......... ..........  1% 60.8M 4s\n","   750K .......... .......... .......... .......... ..........  1% 66.7M 4s\n","   800K .......... .......... .......... .......... ..........  1%  232M 3s\n","   850K .......... .......... .......... .......... ..........  1% 66.1M 3s\n","   900K .......... .......... .......... .......... ..........  1% 63.5M 3s\n","   950K .......... .......... .......... .......... ..........  1% 54.9M 3s\n","  1000K .......... .......... .......... .......... ..........  1% 31.3M 3s\n","  1050K .......... .......... .......... .......... ..........  1%  194M 3s\n","  1100K .......... .......... .......... .......... ..........  1%  107M 3s\n","  1150K .......... .......... .......... .......... ..........  1% 42.1M 3s\n","  1200K .......... .......... .......... .......... ..........  1%  193M 3s\n","  1250K .......... .......... .......... .......... ..........  1% 71.3M 3s\n","  1300K .......... .......... .......... .......... ..........  2% 66.3M 2s\n","  1350K .......... .......... .......... .......... ..........  2% 46.5M 2s\n","  1400K .......... .......... .......... .......... ..........  2%  210M 2s\n","  1450K .......... .......... .......... .......... ..........  2%  156M 2s\n","  1500K .......... .......... .......... .......... ..........  2% 92.4M 2s\n","  1550K .......... .......... .......... .......... ..........  2% 93.0M 2s\n","  1600K .......... .......... .......... .......... ..........  2% 82.1M 2s\n","  1650K .......... .......... .......... .......... ..........  2%  236M 2s\n","  1700K .......... .......... .......... .......... ..........  2%  117M 2s\n","  1750K .......... .......... .......... .......... ..........  2% 22.1M 2s\n","  1800K .......... .......... .......... .......... ..........  2%  168M 2s\n","  1850K .......... .......... .......... .......... ..........  2%  125M 2s\n","  1900K .......... .......... .......... .......... ..........  2%  120M 2s\n","  1950K .......... .......... .......... .......... ..........  3%  165M 2s\n","  2000K .......... .......... .......... .......... ..........  3% 76.9M 2s\n","  2050K .......... .......... .......... .......... ..........  3%  141M 2s\n","  2100K .......... .......... .......... .......... ..........  3%  132M 2s\n","  2150K .......... .......... .......... .......... ..........  3%  190M 2s\n","  2200K .......... .......... .......... .......... ..........  3% 92.5M 2s\n","  2250K .......... .......... .......... .......... ..........  3%  153M 2s\n","  2300K .......... .......... .......... .......... ..........  3% 94.0M 2s\n","  2350K .......... .......... .......... .......... ..........  3%  116M 2s\n","  2400K .......... .......... .......... .......... ..........  3%  257M 2s\n","  2450K .......... .......... .......... .......... ..........  3%  114M 2s\n","  2500K .......... .......... .......... .......... ..........  3%  138M 2s\n","  2550K .......... .......... .......... .......... ..........  3%  105M 2s\n","  2600K .......... .......... .......... .......... ..........  4%  117M 2s\n","  2650K .......... .......... .......... .......... ..........  4%  359M 1s\n","  2700K .......... .......... .......... .......... ..........  4%  143M 1s\n","  2750K .......... .......... .......... .......... ..........  4%  155M 1s\n","  2800K .......... .......... .......... .......... ..........  4%  174M 1s\n","  2850K .......... .......... .......... .......... ..........  4%  240M 1s\n","  2900K .......... .......... .......... .......... ..........  4%  244M 1s\n","  2950K .......... .......... .......... .......... ..........  4%  206M 1s\n","  3000K .......... .......... .......... .......... ..........  4%  229M 1s\n","  3050K .......... .......... .......... .......... ..........  4%  256M 1s\n","  3100K .......... .......... .......... .......... ..........  4%  306M 1s\n","  3150K .......... .......... .......... .......... ..........  4%  175M 1s\n","  3200K .......... .......... .......... .......... ..........  4%  242M 1s\n","  3250K .......... .......... .......... .......... ..........  5%  172M 1s\n","  3300K .......... .......... .......... .......... ..........  5%  268M 1s\n","  3350K .......... .......... .......... .......... ..........  5%  213M 1s\n","  3400K .......... .......... .......... .......... ..........  5%  197M 1s\n","  3450K .......... .......... .......... .......... ..........  5%  298M 1s\n","  3500K .......... .......... .......... .......... ..........  5%  176M 1s\n","  3550K .......... .......... .......... .......... ..........  5%  236M 1s\n","  3600K .......... .......... .......... .......... ..........  5%  277M 1s\n","  3650K .......... .......... .......... .......... ..........  5%  207M 1s\n","  3700K .......... .......... .......... .......... ..........  5%  215M 1s\n","  3750K .......... .......... .......... .......... ..........  5%  215M 1s\n","  3800K .......... .......... .......... .......... ..........  5%  226M 1s\n","  3850K .......... .......... .......... .......... ..........  5%  231M 1s\n","  3900K .......... .......... .......... .......... ..........  6%  201M 1s\n","  3950K .......... .......... .......... .......... ..........  6%  173M 1s\n","  4000K .......... .......... .......... .......... ..........  6%  220M 1s\n","  4050K .......... .......... .......... .......... ..........  6%  211M 1s\n","  4100K .......... .......... .......... .......... ..........  6%  202M 1s\n","  4150K .......... .......... .......... .......... ..........  6%  190M 1s\n","  4200K .......... .......... .......... .......... ..........  6%  225M 1s\n","  4250K .......... .......... .......... .......... ..........  6%  219M 1s\n","  4300K .......... .......... .......... .......... ..........  6%  207M 1s\n","  4350K .......... .......... .......... .......... ..........  6%  176M 1s\n","  4400K .......... .......... .......... .......... ..........  6%  212M 1s\n","  4450K .......... .......... .......... .......... ..........  6%  228M 1s\n","  4500K .......... .......... .......... .......... ..........  6%  206M 1s\n","  4550K .......... .......... .......... .......... ..........  7%  191M 1s\n","  4600K .......... .......... .......... .......... ..........  7%  201M 1s\n","  4650K .......... .......... .......... .......... ..........  7%  217M 1s\n","  4700K .......... .......... .......... .......... ..........  7%  234M 1s\n","  4750K .......... .......... .......... .......... ..........  7%  172M 1s\n","  4800K .......... .......... .......... .......... ..........  7%  205M 1s\n","  4850K .......... .......... .......... .......... ..........  7%  211M 1s\n","  4900K .......... .......... .......... .......... ..........  7%  214M 1s\n","  4950K .......... .......... .......... .......... ..........  7%  181M 1s\n","  5000K .......... .......... .......... .......... ..........  7%  202M 1s\n","  5050K .......... .......... .......... .......... ..........  7%  212M 1s\n","  5100K .......... .......... .......... .......... ..........  7%  216M 1s\n","  5150K .......... .......... .......... .......... ..........  7%  162M 1s\n","  5200K .......... .......... .......... .......... ..........  8%  213M 1s\n","  5250K .......... .......... .......... .......... ..........  8%  202M 1s\n","  5300K .......... .......... .......... .......... ..........  8%  208M 1s\n","  5350K .......... .......... .......... .......... ..........  8%  177M 1s\n","  5400K .......... .......... .......... .......... ..........  8%  215M 1s\n","  5450K .......... .......... .......... .......... ..........  8%  202M 1s\n","  5500K .......... .......... .......... .......... ..........  8%  202M 1s\n","  5550K .......... .......... .......... .......... ..........  8%  170M 1s\n","  5600K .......... .......... .......... .......... ..........  8%  217M 1s\n","  5650K .......... .......... .......... .......... ..........  8%  212M 1s\n","  5700K .......... .......... .......... .......... ..........  8%  215M 1s\n","  5750K .......... .......... .......... .......... ..........  8%  189M 1s\n","  5800K .......... .......... .......... .......... ..........  8%  237M 1s\n","  5850K .......... .......... .......... .......... ..........  9%  233M 1s\n","  5900K .......... .......... .......... .......... ..........  9%  238M 1s\n","  5950K .......... .......... .......... .......... ..........  9%  189M 1s\n","  6000K .......... .......... .......... .......... ..........  9%  204M 1s\n","  6050K .......... .......... .......... .......... ..........  9%  201M 1s\n","  6100K .......... .......... .......... .......... ..........  9%  206M 1s\n","  6150K .......... .......... .......... .......... ..........  9%  195M 1s\n","  6200K .......... .......... .......... .......... ..........  9%  220M 1s\n","  6250K .......... .......... .......... .......... ..........  9%  230M 1s\n","  6300K .......... .......... .......... .......... ..........  9%  238M 1s\n","  6350K .......... .......... .......... .......... ..........  9%  192M 1s\n","  6400K .......... .......... .......... .......... ..........  9%  214M 1s\n","  6450K .......... .......... .......... .......... ..........  9%  223M 1s\n","  6500K .......... .......... .......... .......... .......... 10%  213M 1s\n","  6550K .......... .......... .......... .......... .......... 10%  174M 1s\n","  6600K .......... .......... .......... .......... .......... 10%  178M 1s\n","  6650K .......... .......... .......... .......... .......... 10%  188M 1s\n","  6700K .......... .......... .......... .......... .......... 10%  199M 1s\n","  6750K .......... .......... .......... .......... .......... 10%  173M 1s\n","  6800K .......... .......... .......... .......... .......... 10%  188M 1s\n","  6850K .......... .......... .......... .......... .......... 10%  196M 1s\n","  6900K .......... .......... .......... .......... .......... 10%  206M 1s\n","  6950K .......... .......... .......... .......... .......... 10%  183M 1s\n","  7000K .......... .......... .......... .......... .......... 10%  183M 1s\n","  7050K .......... .......... .......... .......... .......... 10%  217M 1s\n","  7100K .......... .......... .......... .......... .......... 10%  233M 1s\n","  7150K .......... .......... .......... .......... .......... 11%  192M 1s\n","  7200K .......... .......... .......... .......... .......... 11%  191M 1s\n","  7250K .......... .......... .......... .......... .......... 11%  202M 1s\n","  7300K .......... .......... .......... .......... .......... 11%  223M 1s\n","  7350K .......... .......... .......... .......... .......... 11%  234M 1s\n","  7400K .......... .......... .......... .......... .......... 11%  256M 1s\n","  7450K .......... .......... .......... .......... .......... 11%  202M 1s\n","  7500K .......... .......... .......... .......... .......... 11%  263M 1s\n","  7550K .......... .......... .......... .......... .......... 11%  236M 1s\n","  7600K .......... .......... .......... .......... .......... 11%  276M 1s\n","  7650K .......... .......... .......... .......... .......... 11%  260M 1s\n","  7700K .......... .......... .......... .......... .......... 11%  239M 1s\n","  7750K .......... .......... .......... .......... .......... 11%  213M 1s\n","  7800K .......... .......... .......... .......... .......... 12%  249M 1s\n","  7850K .......... .......... .......... .......... .......... 12%  250M 1s\n","  7900K .......... .......... .......... .......... .......... 12%  262M 1s\n","  7950K .......... .......... .......... .......... .......... 12%  169M 1s\n","  8000K .......... .......... .......... .......... .......... 12%  257M 1s\n","  8050K .......... .......... .......... .......... .......... 12%  242M 1s\n","  8100K .......... .......... .......... .......... .......... 12%  240M 1s\n","  8150K .......... .......... .......... .......... .......... 12%  162M 1s\n","  8200K .......... .......... .......... .......... .......... 12%  219M 1s\n","  8250K .......... .......... .......... .......... .......... 12%  239M 1s\n","  8300K .......... .......... .......... .......... .......... 12%  246M 1s\n","  8350K .......... .......... .......... .......... .......... 12%  205M 1s\n","  8400K .......... .......... .......... .......... .......... 12%  234M 1s\n","  8450K .......... .......... .......... .......... .......... 13%  240M 1s\n","  8500K .......... .......... .......... .......... .......... 13%  244M 1s\n","  8550K .......... .......... .......... .......... .......... 13%  220M 1s\n","  8600K .......... .......... .......... .......... .......... 13%  109M 1s\n","  8650K .......... .......... .......... .......... .......... 13%  219M 1s\n","  8700K .......... .......... .......... .......... .......... 13%  231M 1s\n","  8750K .......... .......... .......... .......... .......... 13%  223M 1s\n","  8800K .......... .......... .......... .......... .......... 13%  264M 1s\n","  8850K .......... .......... .......... .......... .......... 13%  240M 1s\n","  8900K .......... .......... .......... .......... .......... 13%  236M 1s\n","  8950K .......... .......... .......... .......... .......... 13%  237M 1s\n","  9000K .......... .......... .......... .......... .......... 13%  292M 1s\n","  9050K .......... .......... .......... .......... .......... 13%  270M 1s\n","  9100K .......... .......... .......... .......... .......... 14%  284M 1s\n","  9150K .......... .......... .......... .......... .......... 14%  285M 1s\n","  9200K .......... .......... .......... .......... .......... 14%  347M 1s\n","  9250K .......... .......... .......... .......... .......... 14%  455M 1s\n","  9300K .......... .......... .......... .......... .......... 14%  463M 1s\n","  9350K .......... .......... .......... .......... .......... 14%  102M 1s\n","  9400K .......... .......... .......... .......... .......... 14%  220M 1s\n","  9450K .......... .......... .......... .......... .......... 14%  241M 1s\n","  9500K .......... .......... .......... .......... .......... 14%  259M 1s\n","  9550K .......... .......... .......... .......... .......... 14%  194M 1s\n","  9600K .......... .......... .......... .......... .......... 14%  246M 1s\n","  9650K .......... .......... .......... .......... .......... 14%  349M 1s\n","  9700K .......... .......... .......... .......... .......... 14%  280M 1s\n","  9750K .......... .......... .......... .......... .......... 15%  263M 1s\n","  9800K .......... .......... .......... .......... .......... 15%  416M 1s\n","  9850K .......... .......... .......... .......... .......... 15%  382M 1s\n","  9900K .......... .......... .......... .......... .......... 15% 93.6M 1s\n","  9950K .......... .......... .......... .......... .......... 15%  186M 1s\n"," 10000K .......... .......... .......... .......... .......... 15%  201M 1s\n"," 10050K .......... .......... .......... .......... .......... 15%  236M 1s\n"," 10100K .......... .......... .......... .......... .......... 15%  270M 1s\n"," 10150K .......... .......... .......... .......... .......... 15%  211M 1s\n"," 10200K .......... .......... .......... .......... .......... 15%  314M 1s\n"," 10250K .......... .......... .......... .......... .......... 15%  227M 1s\n"," 10300K .......... .......... .......... .......... .......... 15%  260M 1s\n"," 10350K .......... .......... .......... .......... .......... 15%  192M 1s\n"," 10400K .......... .......... .......... .......... .......... 16%  231M 1s\n"," 10450K .......... .......... .......... .......... .......... 16%  312M 1s\n"," 10500K .......... .......... .......... .......... .......... 16%  350M 1s\n"," 10550K .......... .......... .......... .......... .......... 16%  305M 1s\n"," 10600K .......... .......... .......... .......... .......... 16%  441M 1s\n"," 10650K .......... .......... .......... .......... .......... 16%  445M 1s\n"," 10700K .......... .......... .......... .......... .......... 16%  388M 1s\n"," 10750K .......... .......... .......... .......... .......... 16%  227M 1s\n"," 10800K .......... .......... .......... .......... .......... 16%  240M 1s\n"," 10850K .......... .......... .......... .......... .......... 16%  252M 1s\n"," 10900K .......... .......... .......... .......... .......... 16%  249M 1s\n"," 10950K .......... .......... .......... .......... .......... 16%  220M 1s\n"," 11000K .......... .......... .......... .......... .......... 16%  267M 0s\n"," 11050K .......... .......... .......... .......... .......... 17%  249M 0s\n"," 11100K .......... .......... .......... .......... .......... 17%  255M 0s\n"," 11150K .......... .......... .......... .......... .......... 17%  216M 0s\n"," 11200K .......... .......... .......... .......... .......... 17%  247M 0s\n"," 11250K .......... .......... .......... .......... .......... 17%  270M 0s\n"," 11300K .......... .......... .......... .......... .......... 17%  249M 0s\n"," 11350K .......... .......... .......... .......... .......... 17%  185M 0s\n"," 11400K .......... .......... .......... .......... .......... 17%  230M 0s\n"," 11450K .......... .......... .......... .......... .......... 17%  393M 0s\n"," 11500K .......... .......... .......... .......... .......... 17%  407M 0s\n"," 11550K .......... .......... .......... .......... .......... 17%  233M 0s\n"," 11600K .......... .......... .......... .......... .......... 17%  326M 0s\n"," 11650K .......... .......... .......... .......... .......... 17%  394M 0s\n"," 11700K .......... .......... .......... .......... .......... 18%  427M 0s\n"," 11750K .......... .......... .......... .......... .......... 18%  339M 0s\n"," 11800K .......... .......... .......... .......... .......... 18%  461M 0s\n"," 11850K .......... .......... .......... .......... .......... 18%  459M 0s\n"," 11900K .......... .......... .......... .......... .......... 18%  451M 0s\n"," 11950K .......... .......... .......... .......... .......... 18%  382M 0s\n"," 12000K .......... .......... .......... .......... .......... 18%  405M 0s\n"," 12050K .......... .......... .......... .......... .......... 18% 55.7M 0s\n"," 12100K .......... .......... .......... .......... .......... 18%  218M 0s\n"," 12150K .......... .......... .......... .......... .......... 18%  221M 0s\n"," 12200K .......... .......... .......... .......... .......... 18%  263M 0s\n"," 12250K .......... .......... .......... .......... .......... 18% 23.2M 0s\n"," 12300K .......... .......... .......... .......... .......... 18%  219M 0s\n"," 12350K .......... .......... .......... .......... .......... 19%  229M 0s\n"," 12400K .......... .......... .......... .......... .......... 19%  235M 0s\n"," 12450K .......... .......... .......... .......... .......... 19%  289M 0s\n"," 12500K .......... .......... .......... .......... .......... 19% 70.2M 0s\n"," 12550K .......... .......... .......... .......... .......... 19%  160M 0s\n"," 12600K .......... .......... .......... .......... .......... 19%  350M 0s\n"," 12650K .......... .......... .......... .......... .......... 19%  286M 0s\n"," 12700K .......... .......... .......... .......... .......... 19%  296M 0s\n"," 12750K .......... .......... .......... .......... .......... 19%  332M 0s\n"," 12800K .......... .......... .......... .......... .......... 19%  277M 0s\n"," 12850K .......... .......... .......... .......... .......... 19%  339M 0s\n"," 12900K .......... .......... .......... .......... .......... 19%  342M 0s\n"," 12950K .......... .......... .......... .......... .......... 19%  350M 0s\n"," 13000K .......... .......... .......... .......... .......... 20%  364M 0s\n"," 13050K .......... .......... .......... .......... .......... 20%  376M 0s\n"," 13100K .......... .......... .......... .......... .......... 20%  376M 0s\n"," 13150K .......... .......... .......... .......... .......... 20%  179M 0s\n"," 13200K .......... .......... .......... .......... .......... 20%  240M 0s\n"," 13250K .......... .......... .......... .......... .......... 20%  237M 0s\n"," 13300K .......... .......... .......... .......... .......... 20%  230M 0s\n"," 13350K .......... .......... .......... .......... .......... 20%  215M 0s\n"," 13400K .......... .......... .......... .......... .......... 20%  311M 0s\n"," 13450K .......... .......... .......... .......... .......... 20%  375M 0s\n"," 13500K .......... .......... .......... .......... .......... 20%  268M 0s\n"," 13550K .......... .......... .......... .......... .......... 20%  290M 0s\n"," 13600K .......... .......... .......... .......... .......... 20%  333M 0s\n"," 13650K .......... .......... .......... .......... .......... 21%  305M 0s\n"," 13700K .......... .......... .......... .......... .......... 21%  352M 0s\n"," 13750K .......... .......... .......... .......... .......... 21%  317M 0s\n"," 13800K .......... .......... .......... .......... .......... 21%  366M 0s\n"," 13850K .......... .......... .......... .......... .......... 21%  312M 0s\n"," 13900K .......... .......... .......... .......... .......... 21%  261M 0s\n"," 13950K .......... .......... .......... .......... .......... 21%  169M 0s\n"," 14000K .......... .......... .......... .......... .......... 21%  225M 0s\n"," 14050K .......... .......... .......... .......... .......... 21%  255M 0s\n"," 14100K .......... .......... .......... .......... .......... 21%  285M 0s\n"," 14150K .......... .......... .......... .......... .......... 21%  195M 0s\n"," 14200K .......... .......... .......... .......... .......... 21%  240M 0s\n"," 14250K .......... .......... .......... .......... .......... 21%  263M 0s\n"," 14300K .......... .......... .......... .......... .......... 22%  241M 0s\n"," 14350K .......... .......... .......... .......... .......... 22% 24.4M 0s\n"," 14400K .......... .......... .......... .......... .......... 22%  227M 0s\n"," 14450K .......... .......... .......... .......... .......... 22%  208M 0s\n"," 14500K .......... .......... .......... .......... .......... 22%  203M 0s\n"," 14550K .......... .......... .......... .......... .......... 22%  213M 0s\n"," 14600K .......... .......... .......... .......... .......... 22%  264M 0s\n"," 14650K .......... .......... .......... .......... .......... 22%  222M 0s\n"," 14700K .......... .......... .......... .......... .......... 22%  188M 0s\n"," 14750K .......... .......... .......... .......... .......... 22%  179M 0s\n"," 14800K .......... .......... .......... .......... .......... 22%  241M 0s\n"," 14850K .......... .......... .......... .......... .......... 22%  293M 0s\n"," 14900K .......... .......... .......... .......... .......... 22%  329M 0s\n"," 14950K .......... .......... .......... .......... .......... 23%  278M 0s\n"," 15000K .......... .......... .......... .......... .......... 23%  228M 0s\n"," 15050K .......... .......... .......... .......... .......... 23%  225M 0s\n"," 15100K .......... .......... .......... .......... .......... 23%  324M 0s\n"," 15150K .......... .......... .......... .......... .......... 23%  295M 0s\n"," 15200K .......... .......... .......... .......... .......... 23%  295M 0s\n"," 15250K .......... .......... .......... .......... .......... 23%  318M 0s\n"," 15300K .......... .......... .......... .......... .......... 23%  314M 0s\n"," 15350K .......... .......... .......... .......... .......... 23%  216M 0s\n"," 15400K .......... .......... .......... .......... .......... 23%  239M 0s\n"," 15450K .......... .......... .......... .......... .......... 23%  213M 0s\n"," 15500K .......... .......... .......... .......... .......... 23%  285M 0s\n"," 15550K .......... .......... .......... .......... .......... 23%  200M 0s\n"," 15600K .......... .......... .......... .......... .......... 24%  213M 0s\n"," 15650K .......... .......... .......... .......... .......... 24%  225M 0s\n"," 15700K .......... .......... .......... .......... .......... 24%  220M 0s\n"," 15750K .......... .......... .......... .......... .......... 24%  185M 0s\n"," 15800K .......... .......... .......... .......... .......... 24%  221M 0s\n"," 15850K .......... .......... .......... .......... .......... 24%  253M 0s\n"," 15900K .......... .......... .......... .......... .......... 24%  341M 0s\n"," 15950K .......... .......... .......... .......... .......... 24%  269M 0s\n"," 16000K .......... .......... .......... .......... .......... 24%  330M 0s\n"," 16050K .......... .......... .......... .......... .......... 24%  329M 0s\n"," 16100K .......... .......... .......... .......... .......... 24%  307M 0s\n"," 16150K .......... .......... .......... .......... .......... 24%  210M 0s\n"," 16200K .......... .......... .......... .......... .......... 24%  230M 0s\n"," 16250K .......... .......... .......... .......... .......... 25%  264M 0s\n"," 16300K .......... .......... .......... .......... .......... 25%  280M 0s\n"," 16350K .......... .......... .......... .......... .......... 25%  299M 0s\n"," 16400K .......... .......... .......... .......... .......... 25%  291M 0s\n"," 16450K .......... .......... .......... .......... .......... 25%  339M 0s\n"," 16500K .......... .......... .......... .......... .......... 25%  330M 0s\n"," 16550K .......... .......... .......... .......... .......... 25%  244M 0s\n"," 16600K .......... .......... .......... .......... .......... 25%  282M 0s\n"," 16650K .......... .......... .......... .......... .......... 25%  390M 0s\n"," 16700K .......... .......... .......... .......... .......... 25%  394M 0s\n"," 16750K .......... .......... .......... .......... .......... 25%  312M 0s\n"," 16800K .......... .......... .......... .......... .......... 25%  289M 0s\n"," 16850K .......... .......... .......... .......... .......... 25%  242M 0s\n"," 16900K .......... .......... .......... .......... .......... 26%  253M 0s\n"," 16950K .......... .......... .......... .......... .......... 26%  237M 0s\n"," 17000K .......... .......... .......... .......... .......... 26%  258M 0s\n"," 17050K .......... .......... .......... .......... .......... 26%  258M 0s\n"," 17100K .......... .......... .......... .......... .......... 26%  207M 0s\n"," 17150K .......... .......... .......... .......... .......... 26%  180M 0s\n"," 17200K .......... .......... .......... .......... .......... 26%  238M 0s\n"," 17250K .......... .......... .......... .......... .......... 26%  260M 0s\n"," 17300K .......... .......... .......... .......... .......... 26%  241M 0s\n"," 17350K .......... .......... .......... .......... .......... 26%  222M 0s\n"," 17400K .......... .......... .......... .......... .......... 26%  266M 0s\n"," 17450K .......... .......... .......... .......... .......... 26%  259M 0s\n"," 17500K .......... .......... .......... .......... .......... 26% 39.4M 0s\n"," 17550K .......... .......... .......... .......... .......... 27%  153M 0s\n"," 17600K .......... .......... .......... .......... .......... 27%  206M 0s\n"," 17650K .......... .......... .......... .......... .......... 27%  225M 0s\n"," 17700K .......... .......... .......... .......... .......... 27%  220M 0s\n"," 17750K .......... .......... .......... .......... .......... 27%  179M 0s\n"," 17800K .......... .......... .......... .......... .......... 27%  236M 0s\n"," 17850K .......... .......... .......... .......... .......... 27%  230M 0s\n"," 17900K .......... .......... .......... .......... .......... 27%  245M 0s\n"," 17950K .......... .......... .......... .......... .......... 27%  183M 0s\n"," 18000K .......... .......... .......... .......... .......... 27%  202M 0s\n"," 18050K .......... .......... .......... .......... .......... 27%  259M 0s\n"," 18100K .......... .......... .......... .......... .......... 27%  246M 0s\n"," 18150K .......... .......... .......... .......... .......... 27%  240M 0s\n"," 18200K .......... .......... .......... .......... .......... 28%  333M 0s\n"," 18250K .......... .......... .......... .......... .......... 28%  244M 0s\n"," 18300K .......... .......... .......... .......... .......... 28%  244M 0s\n"," 18350K .......... .......... .......... .......... .......... 28%  194M 0s\n"," 18400K .......... .......... .......... .......... .......... 28%  287M 0s\n"," 18450K .......... .......... .......... .......... .......... 28%  277M 0s\n"," 18500K .......... .......... .......... .......... .......... 28%  271M 0s\n"," 18550K .......... .......... .......... .......... .......... 28%  223M 0s\n"," 18600K .......... .......... .......... .......... .......... 28%  276M 0s\n"," 18650K .......... .......... .......... .......... .......... 28%  435M 0s\n"," 18700K .......... .......... .......... .......... .......... 28%  390M 0s\n"," 18750K .......... .......... .......... .......... .......... 28%  292M 0s\n"," 18800K .......... .......... .......... .......... .......... 28%  379M 0s\n"," 18850K .......... .......... .......... .......... .......... 29%  397M 0s\n"," 18900K .......... .......... .......... .......... .......... 29%  389M 0s\n"," 18950K .......... .......... .......... .......... .......... 29%  275M 0s\n"," 19000K .......... .......... .......... .......... .......... 29%  418M 0s\n"," 19050K .......... .......... .......... .......... .......... 29%  441M 0s\n"," 19100K .......... .......... .......... .......... .......... 29%  391M 0s\n"," 19150K .......... .......... .......... .......... .......... 29%  318M 0s\n"," 19200K .......... .......... .......... .......... .......... 29%  293M 0s\n"," 19250K .......... .......... .......... .......... .......... 29%  245M 0s\n"," 19300K .......... .......... .......... .......... .......... 29%  251M 0s\n"," 19350K .......... .......... .......... .......... .......... 29%  226M 0s\n"," 19400K .......... .......... .......... .......... .......... 29%  304M 0s\n"," 19450K .......... .......... .......... .......... .......... 29%  257M 0s\n"," 19500K .......... .......... .......... .......... .......... 30%  294M 0s\n"," 19550K .......... .......... .......... .......... .......... 30%  311M 0s\n"," 19600K .......... .......... .......... .......... .......... 30%  124M 0s\n"," 19650K .......... .......... .......... .......... .......... 30%  187M 0s\n"," 19700K .......... .......... .......... .......... .......... 30%  218M 0s\n"," 19750K .......... .......... .......... .......... .......... 30%  199M 0s\n"," 19800K .......... .......... .......... .......... .......... 30%  243M 0s\n"," 19850K .......... .......... .......... .......... .......... 30%  263M 0s\n"," 19900K .......... .......... .......... .......... .......... 30%  274M 0s\n"," 19950K .......... .......... .......... .......... .......... 30%  226M 0s\n"," 20000K .......... .......... .......... .......... .......... 30%  296M 0s\n"," 20050K .......... .......... .......... .......... .......... 30%  317M 0s\n"," 20100K .......... .......... .......... .......... .......... 30%  310M 0s\n"," 20150K .......... .......... .......... .......... .......... 31%  266M 0s\n"," 20200K .......... .......... .......... .......... .......... 31%  287M 0s\n"," 20250K .......... .......... .......... .......... .......... 31%  304M 0s\n"," 20300K .......... .......... .......... .......... .......... 31%  243M 0s\n"," 20350K .......... .......... .......... .......... .......... 31%  227M 0s\n"," 20400K .......... .......... .......... .......... .......... 31%  376M 0s\n"," 20450K .......... .......... .......... .......... .......... 31%  316M 0s\n"," 20500K .......... .......... .......... .......... .......... 31%  217M 0s\n"," 20550K .......... .......... .......... .......... .......... 31%  232M 0s\n"," 20600K .......... .......... .......... .......... .......... 31%  271M 0s\n"," 20650K .......... .......... .......... .......... .......... 31%  274M 0s\n"," 20700K .......... .......... .......... .......... .......... 31%  255M 0s\n"," 20750K .......... .......... .......... .......... .......... 31%  207M 0s\n"," 20800K .......... .......... .......... .......... .......... 32%  290M 0s\n"," 20850K .......... .......... .......... .......... .......... 32%  284M 0s\n"," 20900K .......... .......... .......... .......... .......... 32%  297M 0s\n"," 20950K .......... .......... .......... .......... .......... 32%  228M 0s\n"," 21000K .......... .......... .......... .......... .......... 32%  215M 0s\n"," 21050K .......... .......... .......... .......... .......... 32%  249M 0s\n"," 21100K .......... .......... .......... .......... .......... 32%  240M 0s\n"," 21150K .......... .......... .......... .......... .......... 32%  198M 0s\n"," 21200K .......... .......... .......... .......... .......... 32%  231M 0s\n"," 21250K .......... .......... .......... .......... .......... 32%  283M 0s\n"," 21300K .......... .......... .......... .......... .......... 32%  260M 0s\n"," 21350K .......... .......... .......... .......... .......... 32%  218M 0s\n"," 21400K .......... .......... .......... .......... .......... 32%  259M 0s\n"," 21450K .......... .......... .......... .......... .......... 33%  248M 0s\n"," 21500K .......... .......... .......... .......... .......... 33% 24.9M 0s\n"," 21550K .......... .......... .......... .......... .......... 33%  178M 0s\n"," 21600K .......... .......... .......... .......... .......... 33%  267M 0s\n"," 21650K .......... .......... .......... .......... .......... 33%  373M 0s\n"," 21700K .......... .......... .......... .......... .......... 33%  272M 0s\n"," 21750K .......... .......... .......... .......... .......... 33% 99.9M 0s\n"," 21800K .......... .......... .......... .......... .......... 33%  284M 0s\n"," 21850K .......... .......... .......... .......... .......... 33%  220M 0s\n"," 21900K .......... .......... .......... .......... .......... 33%  219M 0s\n"," 21950K .......... .......... .......... .......... .......... 33%  176M 0s\n"," 22000K .......... .......... .......... .......... .......... 33%  240M 0s\n"," 22050K .......... .......... .......... .......... .......... 33%  193M 0s\n"," 22100K .......... .......... .......... .......... .......... 34%  218M 0s\n"," 22150K .......... .......... .......... .......... .......... 34%  172M 0s\n"," 22200K .......... .......... .......... .......... .......... 34%  200M 0s\n"," 22250K .......... .......... .......... .......... .......... 34%  259M 0s\n"," 22300K .......... .......... .......... .......... .......... 34%  299M 0s\n"," 22350K .......... .......... .......... .......... .......... 34%  212M 0s\n"," 22400K .......... .......... .......... .......... .......... 34%  203M 0s\n"," 22450K .......... .......... .......... .......... .......... 34%  221M 0s\n"," 22500K .......... .......... .......... .......... .......... 34%  205M 0s\n"," 22550K .......... .......... .......... .......... .......... 34%  220M 0s\n"," 22600K .......... .......... .......... .......... .......... 34%  294M 0s\n"," 22650K .......... .......... .......... .......... .......... 34%  291M 0s\n"," 22700K .......... .......... .......... .......... .......... 34%  231M 0s\n"," 22750K .......... .......... .......... .......... .......... 34%  226M 0s\n"," 22800K .......... .......... .......... .......... .......... 35%  215M 0s\n"," 22850K .......... .......... .......... .......... .......... 35%  285M 0s\n"," 22900K .......... .......... .......... .......... .......... 35%  221M 0s\n"," 22950K .......... .......... .......... .......... .......... 35%  260M 0s\n"," 23000K .......... .......... .......... .......... .......... 35%  379M 0s\n"," 23050K .......... .......... .......... .......... .......... 35%  258M 0s\n"," 23100K .......... .......... .......... .......... .......... 35%  378M 0s\n"," 23150K .......... .......... .......... .......... .......... 35%  215M 0s\n"," 23200K .......... .......... .......... .......... .......... 35%  209M 0s\n"," 23250K .......... .......... .......... .......... .......... 35%  265M 0s\n"," 23300K .......... .......... .......... .......... .......... 35%  366M 0s\n"," 23350K .......... .......... .......... .......... .......... 35%  298M 0s\n"," 23400K .......... .......... .......... .......... .......... 35%  363M 0s\n"," 23450K .......... .......... .......... .......... .......... 36%  281M 0s\n"," 23500K .......... .......... .......... .......... .......... 36%  390M 0s\n"," 23550K .......... .......... .......... .......... .......... 36%  273M 0s\n"," 23600K .......... .......... .......... .......... .......... 36%  363M 0s\n"," 23650K .......... .......... .......... .......... .......... 36%  330M 0s\n"," 23700K .......... .......... .......... .......... .......... 36%  374M 0s\n"," 23750K .......... .......... .......... .......... .......... 36%  298M 0s\n"," 23800K .......... .......... .......... .......... .......... 36%  315M 0s\n"," 23850K .......... .......... .......... .......... .......... 36%  274M 0s\n"," 23900K .......... .......... .......... .......... .......... 36%  324M 0s\n"," 23950K .......... .......... .......... .......... .......... 36%  323M 0s\n"," 24000K .......... .......... .......... .......... .......... 36%  335M 0s\n"," 24050K .......... .......... .......... .......... .......... 36%  356M 0s\n"," 24100K .......... .......... .......... .......... .......... 37%  323M 0s\n"," 24150K .......... .......... .......... .......... .......... 37%  260M 0s\n"," 24200K .......... .......... .......... .......... .......... 37%  377M 0s\n"," 24250K .......... .......... .......... .......... .......... 37%  335M 0s\n"," 24300K .......... .......... .......... .......... .......... 37%  200M 0s\n"," 24350K .......... .......... .......... .......... .......... 37%  215M 0s\n"," 24400K .......... .......... .......... .......... .......... 37%  293M 0s\n"," 24450K .......... .......... .......... .......... .......... 37%  270M 0s\n"," 24500K .......... .......... .......... .......... .......... 37%  345M 0s\n"," 24550K .......... .......... .......... .......... .......... 37%  297M 0s\n"," 24600K .......... .......... .......... .......... .......... 37%  294M 0s\n"," 24650K .......... .......... .......... .......... .......... 37%  296M 0s\n"," 24700K .......... .......... .......... .......... .......... 37%  314M 0s\n"," 24750K .......... .......... .......... .......... .......... 38% 31.8M 0s\n"," 24800K .......... .......... .......... .......... .......... 38%  217M 0s\n"," 24850K .......... .......... .......... .......... .......... 38%  210M 0s\n"," 24900K .......... .......... .......... .......... .......... 38%  213M 0s\n"," 24950K .......... .......... .......... .......... .......... 38%  191M 0s\n"," 25000K .......... .......... .......... .......... .......... 38%  252M 0s\n"," 25050K .......... .......... .......... .......... .......... 38%  207M 0s\n"," 25100K .......... .......... .......... .......... .......... 38%  304M 0s\n"," 25150K .......... .......... .......... .......... .......... 38%  195M 0s\n"," 25200K .......... .......... .......... .......... .......... 38%  348M 0s\n"," 25250K .......... .......... .......... .......... .......... 38%  220M 0s\n"," 25300K .......... .......... .......... .......... .......... 38%  309M 0s\n"," 25350K .......... .......... .......... .......... .......... 38%  184M 0s\n"," 25400K .......... .......... .......... .......... .......... 39%  245M 0s\n"," 25450K .......... .......... .......... .......... .......... 39%  222M 0s\n"," 25500K .......... .......... .......... .......... .......... 39%  242M 0s\n"," 25550K .......... .......... .......... .......... .......... 39%  171M 0s\n"," 25600K .......... .......... .......... .......... .......... 39%  310M 0s\n"," 25650K .......... .......... .......... .......... .......... 39%  249M 0s\n"," 25700K .......... .......... .......... .......... .......... 39%  306M 0s\n"," 25750K .......... .......... .......... .......... .......... 39%  233M 0s\n"," 25800K .......... .......... .......... .......... .......... 39%  262M 0s\n"," 25850K .......... .......... .......... .......... .......... 39%  276M 0s\n"," 25900K .......... .......... .......... .......... .......... 39%  263M 0s\n"," 25950K .......... .......... .......... .......... .......... 39%  285M 0s\n"," 26000K .......... .......... .......... .......... .......... 39%  349M 0s\n"," 26050K .......... .......... .......... .......... .......... 40%  346M 0s\n"," 26100K .......... .......... .......... .......... .......... 40%  306M 0s\n"," 26150K .......... .......... .......... .......... .......... 40%  322M 0s\n"," 26200K .......... .......... .......... .......... .......... 40%  329M 0s\n"," 26250K .......... .......... .......... .......... .......... 40%  305M 0s\n"," 26300K .......... .......... .......... .......... .......... 40%  274M 0s\n"," 26350K .......... .......... .......... .......... .......... 40%  228M 0s\n"," 26400K .......... .......... .......... .......... .......... 40%  243M 0s\n"," 26450K .......... .......... .......... .......... .......... 40%  259M 0s\n"," 26500K .......... .......... .......... .......... .......... 40%  268M 0s\n"," 26550K .......... .......... .......... .......... .......... 40%  239M 0s\n"," 26600K .......... .......... .......... .......... .......... 40%  274M 0s\n"," 26650K .......... .......... .......... .......... .......... 40% 87.7M 0s\n"," 26700K .......... .......... .......... .......... .......... 41%  212M 0s\n"," 26750K .......... .......... .......... .......... .......... 41%  180M 0s\n"," 26800K .......... .......... .......... .......... .......... 41%  181M 0s\n"," 26850K .......... .......... .......... .......... .......... 41%  218M 0s\n"," 26900K .......... .......... .......... .......... .......... 41%  206M 0s\n"," 26950K .......... .......... .......... .......... .......... 41%  228M 0s\n"," 27000K .......... .......... .......... .......... .......... 41%  227M 0s\n"," 27050K .......... .......... .......... .......... .......... 41%  230M 0s\n"," 27100K .......... .......... .......... .......... .......... 41%  229M 0s\n"," 27150K .......... .......... .......... .......... .......... 41%  227M 0s\n"," 27200K .......... .......... .......... .......... .......... 41%  278M 0s\n"," 27250K .......... .......... .......... .......... .......... 41%  232M 0s\n"," 27300K .......... .......... .......... .......... .......... 41%  218M 0s\n"," 27350K .......... .......... .......... .......... .......... 42%  284M 0s\n"," 27400K .......... .......... .......... .......... .......... 42%  255M 0s\n"," 27450K .......... .......... .......... .......... .......... 42%  216M 0s\n"," 27500K .......... .......... .......... .......... .......... 42%  235M 0s\n"," 27550K .......... .......... .......... .......... .......... 42%  261M 0s\n"," 27600K .......... .......... .......... .......... .......... 42%  270M 0s\n"," 27650K .......... .......... .......... .......... .......... 42%  259M 0s\n"," 27700K .......... .......... .......... .......... .......... 42%  228M 0s\n"," 27750K .......... .......... .......... .......... .......... 42%  178M 0s\n"," 27800K .......... .......... .......... .......... .......... 42%  213M 0s\n"," 27850K .......... .......... .......... .......... .......... 42%  239M 0s\n"," 27900K .......... .......... .......... .......... .......... 42%  209M 0s\n"," 27950K .......... .......... .......... .......... .......... 42%  193M 0s\n"," 28000K .......... .......... .......... .......... .......... 43%  222M 0s\n"," 28050K .......... .......... .......... .......... .......... 43%  226M 0s\n"," 28100K .......... .......... .......... .......... .......... 43%  249M 0s\n"," 28150K .......... .......... .......... .......... .......... 43%  218M 0s\n"," 28200K .......... .......... .......... .......... .......... 43%  197M 0s\n"," 28250K .......... .......... .......... .......... .......... 43%  219M 0s\n"," 28300K .......... .......... .......... .......... .......... 43%  213M 0s\n"," 28350K .......... .......... .......... .......... .......... 43%  168M 0s\n"," 28400K .......... .......... .......... .......... .......... 43%  207M 0s\n"," 28450K .......... .......... .......... .......... .......... 43%  230M 0s\n"," 28500K .......... .......... .......... .......... .......... 43%  244M 0s\n"," 28550K .......... .......... .......... .......... .......... 43%  221M 0s\n"," 28600K .......... .......... .......... .......... .......... 43%  245M 0s\n"," 28650K .......... .......... .......... .......... .......... 44%  238M 0s\n"," 28700K .......... .......... .......... .......... .......... 44%  247M 0s\n"," 28750K .......... .......... .......... .......... .......... 44%  209M 0s\n"," 28800K .......... .......... .......... .......... .......... 44%  258M 0s\n"," 28850K .......... .......... .......... .......... .......... 44%  238M 0s\n"," 28900K .......... .......... .......... .......... .......... 44%  239M 0s\n"," 28950K .......... .......... .......... .......... .......... 44%  230M 0s\n"," 29000K .......... .......... .......... .......... .......... 44%  254M 0s\n"," 29050K .......... .......... .......... .......... .......... 44%  252M 0s\n"," 29100K .......... .......... .......... .......... .......... 44%  171M 0s\n"," 29150K .......... .......... .......... .......... .......... 44%  174M 0s\n"," 29200K .......... .......... .......... .......... .......... 44%  204M 0s\n"," 29250K .......... .......... .......... .......... .......... 44%  248M 0s\n"," 29300K .......... .......... .......... .......... .......... 45%  200M 0s\n"," 29350K .......... .......... .......... .......... .......... 45%  186M 0s\n"," 29400K .......... .......... .......... .......... .......... 45%  238M 0s\n"," 29450K .......... .......... .......... .......... .......... 45%  319M 0s\n"," 29500K .......... .......... .......... .......... .......... 45%  339M 0s\n"," 29550K .......... .......... .......... .......... .......... 45%  295M 0s\n"," 29600K .......... .......... .......... .......... .......... 45%  251M 0s\n"," 29650K .......... .......... .......... .......... .......... 45%  224M 0s\n"," 29700K .......... .......... .......... .......... .......... 45%  213M 0s\n"," 29750K .......... .......... .......... .......... .......... 45%  203M 0s\n"," 29800K .......... .......... .......... .......... .......... 45%  214M 0s\n"," 29850K .......... .......... .......... .......... .......... 45%  247M 0s\n"," 29900K .......... .......... .......... .......... .......... 45%  243M 0s\n"," 29950K .......... .......... .......... .......... .......... 46%  175M 0s\n"," 30000K .......... .......... .......... .......... .......... 46%  214M 0s\n"," 30050K .......... .......... .......... .......... .......... 46%  230M 0s\n"," 30100K .......... .......... .......... .......... .......... 46%  233M 0s\n"," 30150K .......... .......... .......... .......... .......... 46%  212M 0s\n"," 30200K .......... .......... .......... .......... .......... 46%  247M 0s\n"," 30250K .......... .......... .......... .......... .......... 46%  190M 0s\n"," 30300K .......... .......... .......... .......... .......... 46%  219M 0s\n"," 30350K .......... .......... .......... .......... .......... 46%  176M 0s\n"," 30400K .......... .......... .......... .......... .......... 46%  227M 0s\n"," 30450K .......... .......... .......... .......... .......... 46%  200M 0s\n"," 30500K .......... .......... .......... .......... .......... 46%  233M 0s\n"," 30550K .......... .......... .......... .......... .......... 46%  197M 0s\n"," 30600K .......... .......... .......... .......... .......... 47%  201M 0s\n"," 30650K .......... .......... .......... .......... .......... 47%  226M 0s\n"," 30700K .......... .......... .......... .......... .......... 47%  212M 0s\n"," 30750K .......... .......... .......... .......... .......... 47%  199M 0s\n"," 30800K .......... .......... .......... .......... .......... 47%  227M 0s\n"," 30850K .......... .......... .......... .......... .......... 47%  241M 0s\n"," 30900K .......... .......... .......... .......... .......... 47%  221M 0s\n"," 30950K .......... .......... .......... .......... .......... 47%  287M 0s\n"," 31000K .......... .......... .......... .......... .......... 47%  379M 0s\n"," 31050K .......... .......... .......... .......... .......... 47%  316M 0s\n"," 31100K .......... .......... .......... .......... .......... 47%  313M 0s\n"," 31150K .......... .......... .......... .......... .......... 47%  314M 0s\n"," 31200K .......... .......... .......... .......... .......... 47%  267M 0s\n"," 31250K .......... .......... .......... .......... .......... 48%  246M 0s\n"," 31300K .......... .......... .......... .......... .......... 48%  278M 0s\n"," 31350K .......... .......... .......... .......... .......... 48%  324M 0s\n"," 31400K .......... .......... .......... .......... .......... 48%  263M 0s\n"," 31450K .......... .......... .......... .......... .......... 48%  243M 0s\n"," 31500K .......... .......... .......... .......... .......... 48%  252M 0s\n"," 31550K .......... .......... .......... .......... .......... 48%  186M 0s\n"," 31600K .......... .......... .......... .......... .......... 48%  187M 0s\n"," 31650K .......... .......... .......... .......... .......... 48%  204M 0s\n"," 31700K .......... .......... .......... .......... .......... 48% 11.1M 0s\n"," 31750K .......... .......... .......... .......... .......... 48%  199M 0s\n"," 31800K .......... .......... .......... .......... .......... 48%  227M 0s\n"," 31850K .......... .......... .......... .......... .......... 48%  217M 0s\n"," 31900K .......... .......... .......... .......... .......... 49%  228M 0s\n"," 31950K .......... .......... .......... .......... .......... 49%  216M 0s\n"," 32000K .......... .......... .......... .......... .......... 49%  253M 0s\n"," 32050K .......... .......... .......... .......... .......... 49%  251M 0s\n"," 32100K .......... .......... .......... .......... .......... 49%  263M 0s\n"," 32150K .......... .......... .......... .......... .......... 49%  192M 0s\n"," 32200K .......... .......... .......... .......... .......... 49%  243M 0s\n"," 32250K .......... .......... .......... .......... .......... 49%  242M 0s\n"," 32300K .......... .......... .......... .......... .......... 49%  234M 0s\n"," 32350K .......... .......... .......... .......... .......... 49%  185M 0s\n"," 32400K .......... .......... .......... .......... .......... 49%  266M 0s\n"," 32450K .......... .......... .......... .......... .......... 49%  302M 0s\n"," 32500K .......... .......... .......... .......... .......... 49%  318M 0s\n"," 32550K .......... .......... .......... .......... .......... 50%  257M 0s\n"," 32600K .......... .......... .......... .......... .......... 50%  289M 0s\n"," 32650K .......... .......... .......... .......... .......... 50%  279M 0s\n"," 32700K .......... .......... .......... .......... .......... 50%  314M 0s\n"," 32750K .......... .......... .......... .......... .......... 50%  243M 0s\n"," 32800K .......... .......... .......... .......... .......... 50%  312M 0s\n"," 32850K .......... .......... .......... .......... .......... 50%  300M 0s\n"," 32900K .......... .......... .......... .......... .......... 50%  252M 0s\n"," 32950K .......... .......... .......... .......... .......... 50%  276M 0s\n"," 33000K .......... .......... .......... .......... .......... 50%  315M 0s\n"," 33050K .......... .......... .......... .......... .......... 50%  296M 0s\n"," 33100K .......... .......... .......... .......... .......... 50%  302M 0s\n"," 33150K .......... .......... .......... .......... .......... 50%  351M 0s\n"," 33200K .......... .......... .......... .......... .......... 51%  410M 0s\n"," 33250K .......... .......... .......... .......... .......... 51%  320M 0s\n"," 33300K .......... .......... .......... .......... .......... 51%  242M 0s\n"," 33350K .......... .......... .......... .......... .......... 51%  215M 0s\n"," 33400K .......... .......... .......... .......... .......... 51%  232M 0s\n"," 33450K .......... .......... .......... .......... .......... 51%  287M 0s\n"," 33500K .......... .......... .......... .......... .......... 51%  268M 0s\n"," 33550K .......... .......... .......... .......... .......... 51%  223M 0s\n"," 33600K .......... .......... .......... .......... .......... 51%  261M 0s\n"," 33650K .......... .......... .......... .......... .......... 51%  272M 0s\n"," 33700K .......... .......... .......... .......... .......... 51%  297M 0s\n"," 33750K .......... .......... .......... .......... .......... 51%  223M 0s\n"," 33800K .......... .......... .......... .......... .......... 51%  284M 0s\n"," 33850K .......... .......... .......... .......... .......... 52%  302M 0s\n"," 33900K .......... .......... .......... .......... .......... 52%  302M 0s\n"," 33950K .......... .......... .......... .......... .......... 52%  258M 0s\n"," 34000K .......... .......... .......... .......... .......... 52%  297M 0s\n"," 34050K .......... .......... .......... .......... .......... 52%  277M 0s\n"," 34100K .......... .......... .......... .......... .......... 52%  315M 0s\n"," 34150K .......... .......... .......... .......... .......... 52%  278M 0s\n"," 34200K .......... .......... .......... .......... .......... 52%  325M 0s\n"," 34250K .......... .......... .......... .......... .......... 52%  320M 0s\n"," 34300K .......... .......... .......... .......... .......... 52%  317M 0s\n"," 34350K .......... .......... .......... .......... .......... 52%  196M 0s\n"," 34400K .......... .......... .......... .......... .......... 52%  259M 0s\n"," 34450K .......... .......... .......... .......... .......... 52%  287M 0s\n"," 34500K .......... .......... .......... .......... .......... 53%  256M 0s\n"," 34550K .......... .......... .......... .......... .......... 53%  192M 0s\n"," 34600K .......... .......... .......... .......... .......... 53%  212M 0s\n"," 34650K .......... .......... .......... .......... .......... 53%  218M 0s\n"," 34700K .......... .......... .......... .......... .......... 53%  213M 0s\n"," 34750K .......... .......... .......... .......... .......... 53%  200M 0s\n"," 34800K .......... .......... .......... .......... .......... 53%  283M 0s\n"," 34850K .......... .......... .......... .......... .......... 53%  265M 0s\n"," 34900K .......... .......... .......... .......... .......... 53%  289M 0s\n"," 34950K .......... .......... .......... .......... .......... 53%  282M 0s\n"," 35000K .......... .......... .......... .......... .......... 53%  342M 0s\n"," 35050K .......... .......... .......... .......... .......... 53%  214M 0s\n"," 35100K .......... .......... .......... .......... .......... 53%  245M 0s\n"," 35150K .......... .......... .......... .......... .......... 54%  185M 0s\n"," 35200K .......... .......... .......... .......... .......... 54%  280M 0s\n"," 35250K .......... .......... .......... .......... .......... 54%  249M 0s\n"," 35300K .......... .......... .......... .......... .......... 54%  217M 0s\n"," 35350K .......... .......... .......... .......... .......... 54%  256M 0s\n"," 35400K .......... .......... .......... .......... .......... 54%  388M 0s\n"," 35450K .......... .......... .......... .......... .......... 54%  298M 0s\n"," 35500K .......... .......... .......... .......... .......... 54%  371M 0s\n"," 35550K .......... .......... .......... .......... .......... 54%  328M 0s\n"," 35600K .......... .......... .......... .......... .......... 54%  317M 0s\n"," 35650K .......... .......... .......... .......... .......... 54%  261M 0s\n"," 35700K .......... .......... .......... .......... .......... 54%  367M 0s\n"," 35750K .......... .......... .......... .......... .......... 54%  322M 0s\n"," 35800K .......... .......... .......... .......... .......... 55%  338M 0s\n"," 35850K .......... .......... .......... .......... .......... 55%  374M 0s\n"," 35900K .......... .......... .......... .......... .......... 55%  373M 0s\n"," 35950K .......... .......... .......... .......... .......... 55%  298M 0s\n"," 36000K .......... .......... .......... .......... .......... 55%  303M 0s\n"," 36050K .......... .......... .......... .......... .......... 55%  324M 0s\n"," 36100K .......... .......... .......... .......... .......... 55%  369M 0s\n"," 36150K .......... .......... .......... .......... .......... 55%  336M 0s\n"," 36200K .......... .......... .......... .......... .......... 55%  381M 0s\n"," 36250K .......... .......... .......... .......... .......... 55%  211M 0s\n"," 36300K .......... .......... .......... .......... .......... 55%  186M 0s\n"," 36350K .......... .......... .......... .......... .......... 55%  175M 0s\n"," 36400K .......... .......... .......... .......... .......... 55%  242M 0s\n"," 36450K .......... .......... .......... .......... .......... 56%  364M 0s\n"," 36500K .......... .......... .......... .......... .......... 56%  362M 0s\n"," 36550K .......... .......... .......... .......... .......... 56%  245M 0s\n"," 36600K .......... .......... .......... .......... .......... 56%  373M 0s\n"," 36650K .......... .......... .......... .......... .......... 56%  365M 0s\n"," 36700K .......... .......... .......... .......... .......... 56%  374M 0s\n"," 36750K .......... .......... .......... .......... .......... 56%  309M 0s\n"," 36800K .......... .......... .......... .......... .......... 56%  363M 0s\n"," 36850K .......... .......... .......... .......... .......... 56%  351M 0s\n"," 36900K .......... .......... .......... .......... .......... 56%  309M 0s\n"," 36950K .......... .......... .......... .......... .......... 56%  339M 0s\n"," 37000K .......... .......... .......... .......... .......... 56%  396M 0s\n"," 37050K .......... .......... .......... .......... .......... 56% 20.7M 0s\n"," 37100K .......... .......... .......... .......... .......... 57%  251M 0s\n"," 37150K .......... .......... .......... .......... .......... 57%  266M 0s\n"," 37200K .......... .......... .......... .......... .......... 57%  371M 0s\n"," 37250K .......... .......... .......... .......... .......... 57%  345M 0s\n"," 37300K .......... .......... .......... .......... .......... 57%  373M 0s\n"," 37350K .......... .......... .......... .......... .......... 57%  341M 0s\n"," 37400K .......... .......... .......... .......... .......... 57%  406M 0s\n"," 37450K .......... .......... .......... .......... .......... 57%  401M 0s\n"," 37500K .......... .......... .......... .......... .......... 57% 55.7M 0s\n"," 37550K .......... .......... .......... .......... .......... 57%  179M 0s\n"," 37600K .......... .......... .......... .......... .......... 57%  229M 0s\n"," 37650K .......... .......... .......... .......... .......... 57%  209M 0s\n"," 37700K .......... .......... .......... .......... .......... 57%  220M 0s\n"," 37750K .......... .......... .......... .......... .......... 58%  187M 0s\n"," 37800K .......... .......... .......... .......... .......... 58%  277M 0s\n"," 37850K .......... .......... .......... .......... .......... 58%  219M 0s\n"," 37900K .......... .......... .......... .......... .......... 58%  223M 0s\n"," 37950K .......... .......... .......... .......... .......... 58%  189M 0s\n"," 38000K .......... .......... .......... .......... .......... 58%  232M 0s\n"," 38050K .......... .......... .......... .......... .......... 58%  338M 0s\n"," 38100K .......... .......... .......... .......... .......... 58%  329M 0s\n"," 38150K .......... .......... .......... .......... .......... 58%  256M 0s\n"," 38200K .......... .......... .......... .......... .......... 58%  298M 0s\n"," 38250K .......... .......... .......... .......... .......... 58%  395M 0s\n"," 38300K .......... .......... .......... .......... .......... 58%  401M 0s\n"," 38350K .......... .......... .......... .......... .......... 58%  286M 0s\n"," 38400K .......... .......... .......... .......... .......... 59%  401M 0s\n"," 38450K .......... .......... .......... .......... .......... 59%  407M 0s\n"," 38500K .......... .......... .......... .......... .......... 59%  256M 0s\n"," 38550K .......... .......... .......... .......... .......... 59%  200M 0s\n"," 38600K .......... .......... .......... .......... .......... 59%  211M 0s\n"," 38650K .......... .......... .......... .......... .......... 59%  308M 0s\n"," 38700K .......... .......... .......... .......... .......... 59%  373M 0s\n"," 38750K .......... .......... .......... .......... .......... 59%  294M 0s\n"," 38800K .......... .......... .......... .......... .......... 59%  376M 0s\n"," 38850K .......... .......... .......... .......... .......... 59%  384M 0s\n"," 38900K .......... .......... .......... .......... .......... 59%  348M 0s\n"," 38950K .......... .......... .......... .......... .......... 59%  299M 0s\n"," 39000K .......... .......... .......... .......... .......... 59%  260M 0s\n"," 39050K .......... .......... .......... .......... .......... 60%  247M 0s\n"," 39100K .......... .......... .......... .......... .......... 60%  255M 0s\n"," 39150K .......... .......... .......... .......... .......... 60%  214M 0s\n"," 39200K .......... .......... .......... .......... .......... 60%  231M 0s\n"," 39250K .......... .......... .......... .......... .......... 60%  203M 0s\n"," 39300K .......... .......... .......... .......... .......... 60%  226M 0s\n"," 39350K .......... .......... .......... .......... .......... 60%  208M 0s\n"," 39400K .......... .......... .......... .......... .......... 60%  219M 0s\n"," 39450K .......... .......... .......... .......... .......... 60%  256M 0s\n"," 39500K .......... .......... .......... .......... .......... 60%  271M 0s\n"," 39550K .......... .......... .......... .......... .......... 60%  224M 0s\n"," 39600K .......... .......... .......... .......... .......... 60%  276M 0s\n"," 39650K .......... .......... .......... .......... .......... 60%  270M 0s\n"," 39700K .......... .......... .......... .......... .......... 61%  229M 0s\n"," 39750K .......... .......... .......... .......... .......... 61%  183M 0s\n"," 39800K .......... .......... .......... .......... .......... 61%  215M 0s\n"," 39850K .......... .......... .......... .......... .......... 61%  267M 0s\n"," 39900K .......... .......... .......... .......... .......... 61%  247M 0s\n"," 39950K .......... .......... .......... .......... .......... 61%  194M 0s\n"," 40000K .......... .......... .......... .......... .......... 61%  246M 0s\n"," 40050K .......... .......... .......... .......... .......... 61%  253M 0s\n"," 40100K .......... .......... .......... .......... .......... 61%  258M 0s\n"," 40150K .......... .......... .......... .......... .......... 61%  210M 0s\n"," 40200K .......... .......... .......... .......... .......... 61%  234M 0s\n"," 40250K .......... .......... .......... .......... .......... 61%  208M 0s\n"," 40300K .......... .......... .......... .......... .......... 61%  252M 0s\n"," 40350K .......... .......... .......... .......... .......... 62%  219M 0s\n"," 40400K .......... .......... .......... .......... .......... 62%  206M 0s\n"," 40450K .......... .......... .......... .......... .......... 62%  228M 0s\n"," 40500K .......... .......... .......... .......... .......... 62%  241M 0s\n"," 40550K .......... .......... .......... .......... .......... 62%  195M 0s\n"," 40600K .......... .......... .......... .......... .......... 62%  125M 0s\n"," 40650K .......... .......... .......... .......... .......... 62%  168M 0s\n"," 40700K .......... .......... .......... .......... .......... 62%  191M 0s\n"," 40750K .......... .......... .......... .......... .......... 62%  189M 0s\n"," 40800K .......... .......... .......... .......... .......... 62%  289M 0s\n"," 40850K .......... .......... .......... .......... .......... 62%  389M 0s\n"," 40900K .......... .......... .......... .......... .......... 62%  399M 0s\n"," 40950K .......... .......... .......... .......... .......... 62%  392M 0s\n"," 41000K .......... .......... .......... .......... .......... 63%  446M 0s\n"," 41050K .......... .......... .......... .......... .......... 63%  419M 0s\n"," 41100K .......... .......... .......... .......... .......... 63%  449M 0s\n"," 41150K .......... .......... .......... .......... .......... 63%  227M 0s\n"," 41200K .......... .......... .......... .......... .......... 63%  209M 0s\n"," 41250K .......... .......... .......... .......... .......... 63%  209M 0s\n"," 41300K .......... .......... .......... .......... .......... 63%  209M 0s\n"," 41350K .......... .......... .......... .......... .......... 63%  257M 0s\n"," 41400K .......... .......... .......... .......... .......... 63%  281M 0s\n"," 41450K .......... .......... .......... .......... .......... 63%  320M 0s\n"," 41500K .......... .......... .......... .......... .......... 63%  283M 0s\n"," 41550K .......... .......... .......... .......... .......... 63%  255M 0s\n"," 41600K .......... .......... .......... .......... .......... 63%  309M 0s\n"," 41650K .......... .......... .......... .......... .......... 64%  265M 0s\n"," 41700K .......... .......... .......... .......... .......... 64%  294M 0s\n"," 41750K .......... .......... .......... .......... .......... 64%  259M 0s\n"," 41800K .......... .......... .......... .......... .......... 64%  296M 0s\n"," 41850K .......... .......... .......... .......... .......... 64%  215M 0s\n"," 41900K .......... .......... .......... .......... .......... 64%  199M 0s\n"," 41950K .......... .......... .......... .......... .......... 64%  197M 0s\n"," 42000K .......... .......... .......... .......... .......... 64%  248M 0s\n"," 42050K .......... .......... .......... .......... .......... 64%  303M 0s\n"," 42100K .......... .......... .......... .......... .......... 64%  298M 0s\n"," 42150K .......... .......... .......... .......... .......... 64%  256M 0s\n"," 42200K .......... .......... .......... .......... .......... 64%  284M 0s\n"," 42250K .......... .......... .......... .......... .......... 64%  354M 0s\n"," 42300K .......... .......... .......... .......... .......... 65%  435M 0s\n"," 42350K .......... .......... .......... .......... .......... 65%  310M 0s\n"," 42400K .......... .......... .......... .......... .......... 65%  274M 0s\n"," 42450K .......... .......... .......... .......... .......... 65%  246M 0s\n"," 42500K .......... .......... .......... .......... .......... 65%  282M 0s\n"," 42550K .......... .......... .......... .......... .......... 65%  303M 0s\n"," 42600K .......... .......... .......... .......... .......... 65%  441M 0s\n"," 42650K .......... .......... .......... .......... .......... 65%  326M 0s\n"," 42700K .......... .......... .......... .......... .......... 65%  281M 0s\n"," 42750K .......... .......... .......... .......... .......... 65%  207M 0s\n"," 42800K .......... .......... .......... .......... .......... 65%  266M 0s\n"," 42850K .......... .......... .......... .......... .......... 65%  291M 0s\n"," 42900K .......... .......... .......... .......... .......... 65%  241M 0s\n"," 42950K .......... .......... .......... .......... .......... 66% 28.2M 0s\n"," 43000K .......... .......... .......... .......... .......... 66%  228M 0s\n"," 43050K .......... .......... .......... .......... .......... 66%  218M 0s\n"," 43100K .......... .......... .......... .......... .......... 66%  188M 0s\n"," 43150K .......... .......... .......... .......... .......... 66%  132M 0s\n"," 43200K .......... .......... .......... .......... .......... 66%  244M 0s\n"," 43250K .......... .......... .......... .......... .......... 66%  154M 0s\n"," 43300K .......... .......... .......... .......... .......... 66%  149M 0s\n"," 43350K .......... .......... .......... .......... .......... 66%  192M 0s\n"," 43400K .......... .......... .......... .......... .......... 66%  238M 0s\n"," 43450K .......... .......... .......... .......... .......... 66%  307M 0s\n"," 43500K .......... .......... .......... .......... .......... 66%  227M 0s\n"," 43550K .......... .......... .......... .......... .......... 66%  149M 0s\n"," 43600K .......... .......... .......... .......... .......... 67%  168M 0s\n"," 43650K .......... .......... .......... .......... .......... 67%  162M 0s\n"," 43700K .......... .......... .......... .......... .......... 67%  179M 0s\n"," 43750K .......... .......... .......... .......... .......... 67%  201M 0s\n"," 43800K .......... .......... .......... .......... .......... 67%  256M 0s\n"," 43850K .......... .......... .......... .......... .......... 67%  263M 0s\n"," 43900K .......... .......... .......... .......... .......... 67%  203M 0s\n"," 43950K .......... .......... .......... .......... .......... 67%  152M 0s\n"," 44000K .......... .......... .......... .......... .......... 67%  160M 0s\n"," 44050K .......... .......... .......... .......... .......... 67%  239M 0s\n"," 44100K .......... .......... .......... .......... .......... 67%  239M 0s\n"," 44150K .......... .......... .......... .......... .......... 67%  238M 0s\n"," 44200K .......... .......... .......... .......... .......... 67%  298M 0s\n"," 44250K .......... .......... .......... .......... .......... 68%  311M 0s\n"," 44300K .......... .......... .......... .......... .......... 68%  312M 0s\n"," 44350K .......... .......... .......... .......... .......... 68%  224M 0s\n"," 44400K .......... .......... .......... .......... .......... 68%  247M 0s\n"," 44450K .......... .......... .......... .......... .......... 68%  224M 0s\n"," 44500K .......... .......... .......... .......... .......... 68%  237M 0s\n"," 44550K .......... .......... .......... .......... .......... 68%  147M 0s\n"," 44600K .......... .......... .......... .......... .......... 68%  176M 0s\n"," 44650K .......... .......... .......... .......... .......... 68%  201M 0s\n"," 44700K .......... .......... .......... .......... .......... 68%  192M 0s\n"," 44750K .......... .......... .......... .......... .......... 68%  180M 0s\n"," 44800K .......... .......... .......... .......... .......... 68%  230M 0s\n"," 44850K .......... .......... .......... .......... .......... 68%  304M 0s\n"," 44900K .......... .......... .......... .......... .......... 68%  260M 0s\n"," 44950K .......... .......... .......... .......... .......... 69%  273M 0s\n"," 45000K .......... .......... .......... .......... .......... 69%  276M 0s\n"," 45050K .......... .......... .......... .......... .......... 69% 91.7M 0s\n"," 45100K .......... .......... .......... .......... .......... 69%  106M 0s\n"," 45150K .......... .......... .......... .......... .......... 69%  178M 0s\n"," 45200K .......... .......... .......... .......... .......... 69%  239M 0s\n"," 45250K .......... .......... .......... .......... .......... 69%  105M 0s\n"," 45300K .......... .......... .......... .......... .......... 69%  168M 0s\n"," 45350K .......... .......... .......... .......... .......... 69%  134M 0s\n"," 45400K .......... .......... .......... .......... .......... 69%  159M 0s\n"," 45450K .......... .......... .......... .......... .......... 69%  266M 0s\n"," 45500K .......... .......... .......... .......... .......... 69%  214M 0s\n"," 45550K .......... .......... .......... .......... .......... 69%  147M 0s\n"," 45600K .......... .......... .......... .......... .......... 70%  230M 0s\n"," 45650K .......... .......... .......... .......... .......... 70%  155M 0s\n"," 45700K .......... .......... .......... .......... .......... 70%  196M 0s\n"," 45750K .......... .......... .......... .......... .......... 70%  154M 0s\n"," 45800K .......... .......... .......... .......... .......... 70%  277M 0s\n"," 45850K .......... .......... .......... .......... .......... 70%  246M 0s\n"," 45900K .......... .......... .......... .......... .......... 70%  245M 0s\n"," 45950K .......... .......... .......... .......... .......... 70%  235M 0s\n"," 46000K .......... .......... .......... .......... .......... 70%  279M 0s\n"," 46050K .......... .......... .......... .......... .......... 70%  261M 0s\n"," 46100K .......... .......... .......... .......... .......... 70%  280M 0s\n"," 46150K .......... .......... .......... .......... .......... 70%  226M 0s\n"," 46200K .......... .......... .......... .......... .......... 70%  239M 0s\n"," 46250K .......... .......... .......... .......... .......... 71%  299M 0s\n"," 46300K .......... .......... .......... .......... .......... 71%  300M 0s\n"," 46350K .......... .......... .......... .......... .......... 71%  221M 0s\n"," 46400K .......... .......... .......... .......... .......... 71%  249M 0s\n"," 46450K .......... .......... .......... .......... .......... 71%  295M 0s\n"," 46500K .......... .......... .......... .......... .......... 71%  264M 0s\n"," 46550K .......... .......... .......... .......... .......... 71%  264M 0s\n"," 46600K .......... .......... .......... .......... .......... 71%  300M 0s\n"," 46650K .......... .......... .......... .......... .......... 71%  223M 0s\n"," 46700K .......... .......... .......... .......... .......... 71%  295M 0s\n"," 46750K .......... .......... .......... .......... .......... 71%  250M 0s\n"," 46800K .......... .......... .......... .......... .......... 71%  249M 0s\n"," 46850K .......... .......... .......... .......... .......... 71%  254M 0s\n"," 46900K .......... .......... .......... .......... .......... 72%  217M 0s\n"," 46950K .......... .......... .......... .......... .......... 72%  164M 0s\n"," 47000K .......... .......... .......... .......... .......... 72% 25.8M 0s\n"," 47050K .......... .......... .......... .......... .......... 72% 40.8M 0s\n"," 47100K .......... .......... .......... .......... .......... 72%  183M 0s\n"," 47150K .......... .......... .......... .......... .......... 72%  132M 0s\n"," 47200K .......... .......... .......... .......... .......... 72%  243M 0s\n"," 47250K .......... .......... .......... .......... .......... 72% 12.6M 0s\n"," 47300K .......... .......... .......... .......... .......... 72% 34.9M 0s\n"," 47350K .......... .......... .......... .......... .......... 72%  123M 0s\n"," 47400K .......... .......... .......... .......... .......... 72%  144M 0s\n"," 47450K .......... .......... .......... .......... .......... 72%  233M 0s\n"," 47500K .......... .......... .......... .......... .......... 72% 42.2M 0s\n"," 47550K .......... .......... .......... .......... .......... 73% 58.9M 0s\n"," 47600K .......... .......... .......... .......... .......... 73%  220M 0s\n"," 47650K .......... .......... .......... .......... .......... 73%  188M 0s\n"," 47700K .......... .......... .......... .......... .......... 73%  228M 0s\n"," 47750K .......... .......... .......... .......... .......... 73%  204M 0s\n"," 47800K .......... .......... .......... .......... .......... 73%  199M 0s\n"," 47850K .......... .......... .......... .......... .......... 73%  242M 0s\n"," 47900K .......... .......... .......... .......... .......... 73%  217M 0s\n"," 47950K .......... .......... .......... .......... .......... 73%  209M 0s\n"," 48000K .......... .......... .......... .......... .......... 73%  193M 0s\n"," 48050K .......... .......... .......... .......... .......... 73% 89.3M 0s\n"," 48100K .......... .......... .......... .......... .......... 73%  113M 0s\n"," 48150K .......... .......... .......... .......... .......... 73%  133M 0s\n"," 48200K .......... .......... .......... .......... .......... 74%  135M 0s\n"," 48250K .......... .......... .......... .......... .......... 74%  221M 0s\n"," 48300K .......... .......... .......... .......... .......... 74%  145M 0s\n"," 48350K .......... .......... .......... .......... .......... 74% 78.3M 0s\n"," 48400K .......... .......... .......... .......... .......... 74%  177M 0s\n"," 48450K .......... .......... .......... .......... .......... 74%  238M 0s\n"," 48500K .......... .......... .......... .......... .......... 74%  222M 0s\n"," 48550K .......... .......... .......... .......... .......... 74%  174M 0s\n"," 48600K .......... .......... .......... .......... .......... 74%  183M 0s\n"," 48650K .......... .......... .......... .......... .......... 74%  198M 0s\n"," 48700K .......... .......... .......... .......... .......... 74%  175M 0s\n"," 48750K .......... .......... .......... .......... .......... 74%  203M 0s\n"," 48800K .......... .......... .......... .......... .......... 74%  165M 0s\n"," 48850K .......... .......... .......... .......... .......... 75%  212M 0s\n"," 48900K .......... .......... .......... .......... .......... 75%  210M 0s\n"," 48950K .......... .......... .......... .......... .......... 75%  222M 0s\n"," 49000K .......... .......... .......... .......... .......... 75%  136M 0s\n"," 49050K .......... .......... .......... .......... .......... 75%  254M 0s\n"," 49100K .......... .......... .......... .......... .......... 75%  257M 0s\n"," 49150K .......... .......... .......... .......... .......... 75%  182M 0s\n"," 49200K .......... .......... .......... .......... .......... 75%  282M 0s\n"," 49250K .......... .......... .......... .......... .......... 75%  292M 0s\n"," 49300K .......... .......... .......... .......... .......... 75%  251M 0s\n"," 49350K .......... .......... .......... .......... .......... 75%  228M 0s\n"," 49400K .......... .......... .......... .......... .......... 75%  276M 0s\n"," 49450K .......... .......... .......... .......... .......... 75%  262M 0s\n"," 49500K .......... .......... .......... .......... .......... 76% 7.61M 0s\n"," 49550K .......... .......... .......... .......... .......... 76%  115M 0s\n"," 49600K .......... .......... .......... .......... .......... 76%  250M 0s\n"," 49650K .......... .......... .......... .......... .......... 76%  248M 0s\n"," 49700K .......... .......... .......... .......... .......... 76%  151M 0s\n"," 49750K .......... .......... .......... .......... .......... 76% 4.64M 0s\n"," 49800K .......... .......... .......... .......... .......... 76%  156M 0s\n"," 49850K .......... .......... .......... .......... .......... 76%  135M 0s\n"," 49900K .......... .......... .......... .......... .......... 76%  241M 0s\n"," 49950K .......... .......... .......... .......... .......... 76%  138M 0s\n"," 50000K .......... .......... .......... .......... .......... 76%  126M 0s\n"," 50050K .......... .......... .......... .......... .......... 76%  158M 0s\n"," 50100K .......... .......... .......... .......... .......... 76%  140M 0s\n"," 50150K .......... .......... .......... .......... .......... 77%  149M 0s\n"," 50200K .......... .......... .......... .......... .......... 77%  151M 0s\n"," 50250K .......... .......... .......... .......... .......... 77%  158M 0s\n"," 50300K .......... .......... .......... .......... .......... 77%  154M 0s\n"," 50350K .......... .......... .......... .......... .......... 77%  115M 0s\n"," 50400K .......... .......... .......... .......... .......... 77%  256M 0s\n"," 50450K .......... .......... .......... .......... .......... 77%  245M 0s\n"," 50500K .......... .......... .......... .......... .......... 77%  249M 0s\n"," 50550K .......... .......... .......... .......... .......... 77%  237M 0s\n"," 50600K .......... .......... .......... .......... .......... 77%  274M 0s\n"," 50650K .......... .......... .......... .......... .......... 77%  173M 0s\n"," 50700K .......... .......... .......... .......... .......... 77%  190M 0s\n"," 50750K .......... .......... .......... .......... .......... 77%  179M 0s\n"," 50800K .......... .......... .......... .......... .......... 78%  270M 0s\n"," 50850K .......... .......... .......... .......... .......... 78%  266M 0s\n"," 50900K .......... .......... .......... .......... .......... 78%  241M 0s\n"," 50950K .......... .......... .......... .......... .......... 78%  239M 0s\n"," 51000K .......... .......... .......... .......... .......... 78%  280M 0s\n"," 51050K .......... .......... .......... .......... .......... 78%  294M 0s\n"," 51100K .......... .......... .......... .......... .......... 78%  279M 0s\n"," 51150K .......... .......... .......... .......... .......... 78%  224M 0s\n"," 51200K .......... .......... .......... .......... .......... 78%  192M 0s\n"," 51250K .......... .......... .......... .......... .......... 78%  253M 0s\n"," 51300K .......... .......... .......... .......... .......... 78%  286M 0s\n"," 51350K .......... .......... .......... .......... .......... 78%  250M 0s\n"," 51400K .......... .......... .......... .......... .......... 78%  290M 0s\n"," 51450K .......... .......... .......... .......... .......... 79%  256M 0s\n"," 51500K .......... .......... .......... .......... .......... 79%  273M 0s\n"," 51550K .......... .......... .......... .......... .......... 79%  235M 0s\n"," 51600K .......... .......... .......... .......... .......... 79%  286M 0s\n"," 51650K .......... .......... .......... .......... .......... 79%  280M 0s\n"," 51700K .......... .......... .......... .......... .......... 79%  123M 0s\n"," 51750K .......... .......... .......... .......... .......... 79%  200M 0s\n"," 51800K .......... .......... .......... .......... .......... 79% 60.4M 0s\n"," 51850K .......... .......... .......... .......... .......... 79% 83.6M 0s\n"," 51900K .......... .......... .......... .......... .......... 79%  276M 0s\n"," 51950K .......... .......... .......... .......... .......... 79% 10.4M 0s\n"," 52000K .......... .......... .......... .......... .......... 79%  268M 0s\n"," 52050K .......... .......... .......... .......... .......... 79%  367M 0s\n"," 52100K .......... .......... .......... .......... .......... 80%  310M 0s\n"," 52150K .......... .......... .......... .......... .......... 80% 14.7M 0s\n"," 52200K .......... .......... .......... .......... .......... 80%  169M 0s\n"," 52250K .......... .......... .......... .......... .......... 80%  182M 0s\n"," 52300K .......... .......... .......... .......... .......... 80%  182M 0s\n"," 52350K .......... .......... .......... .......... .......... 80%  154M 0s\n"," 52400K .......... .......... .......... .......... .......... 80%  226M 0s\n"," 52450K .......... .......... .......... .......... .......... 80%  169M 0s\n"," 52500K .......... .......... .......... .......... .......... 80%  167M 0s\n"," 52550K .......... .......... .......... .......... .......... 80%  244M 0s\n"," 52600K .......... .......... .......... .......... .......... 80%  162M 0s\n"," 52650K .......... .......... .......... .......... .......... 80%  142M 0s\n"," 52700K .......... .......... .......... .......... .......... 80%  211M 0s\n"," 52750K .......... .......... .......... .......... .......... 81%  166M 0s\n"," 52800K .......... .......... .......... .......... .......... 81%  157M 0s\n"," 52850K .......... .......... .......... .......... .......... 81%  166M 0s\n"," 52900K .......... .......... .......... .......... .......... 81%  192M 0s\n"," 52950K .......... .......... .......... .......... .......... 81%  183M 0s\n"," 53000K .......... .......... .......... .......... .......... 81%  146M 0s\n"," 53050K .......... .......... .......... .......... .......... 81%  225M 0s\n"," 53100K .......... .......... .......... .......... .......... 81%  173M 0s\n"," 53150K .......... .......... .......... .......... .......... 81%  137M 0s\n"," 53200K .......... .......... .......... .......... .......... 81%  177M 0s\n"," 53250K .......... .......... .......... .......... .......... 81%  272M 0s\n"," 53300K .......... .......... .......... .......... .......... 81%  166M 0s\n"," 53350K .......... .......... .......... .......... .......... 81%  171M 0s\n"," 53400K .......... .......... .......... .......... .......... 82%  207M 0s\n"," 53450K .......... .......... .......... .......... .......... 82%  232M 0s\n"," 53500K .......... .......... .......... .......... .......... 82%  279M 0s\n"," 53550K .......... .......... .......... .......... .......... 82%  220M 0s\n"," 53600K .......... .......... .......... .......... .......... 82%  241M 0s\n"," 53650K .......... .......... .......... .......... .......... 82%  286M 0s\n"," 53700K .......... .......... .......... .......... .......... 82%  283M 0s\n"," 53750K .......... .......... .......... .......... .......... 82%  233M 0s\n"," 53800K .......... .......... .......... .......... .......... 82%  278M 0s\n"," 53850K .......... .......... .......... .......... .......... 82%  258M 0s\n"," 53900K .......... .......... .......... .......... .......... 82%  235M 0s\n"," 53950K .......... .......... .......... .......... .......... 82%  212M 0s\n"," 54000K .......... .......... .......... .......... .......... 82%  230M 0s\n"," 54050K .......... .......... .......... .......... .......... 83%  238M 0s\n"," 54100K .......... .......... .......... .......... .......... 83%  234M 0s\n"," 54150K .......... .......... .......... .......... .......... 83%  225M 0s\n"," 54200K .......... .......... .......... .......... .......... 83%  230M 0s\n"," 54250K .......... .......... .......... .......... .......... 83%  212M 0s\n"," 54300K .......... .......... .......... .......... .......... 83%  144M 0s\n"," 54350K .......... .......... .......... .......... .......... 83%  208M 0s\n"," 54400K .......... .......... .......... .......... .......... 83%  182M 0s\n"," 54450K .......... .......... .......... .......... .......... 83%  173M 0s\n"," 54500K .......... .......... .......... .......... .......... 83%  202M 0s\n"," 54550K .......... .......... .......... .......... .......... 83%  227M 0s\n"," 54600K .......... .......... .......... .......... .......... 83%  242M 0s\n"," 54650K .......... .......... .......... .......... .......... 83%  258M 0s\n"," 54700K .......... .......... .......... .......... .......... 84%  227M 0s\n"," 54750K .......... .......... .......... .......... .......... 84%  199M 0s\n"," 54800K .......... .......... .......... .......... .......... 84%  256M 0s\n"," 54850K .......... .......... .......... .......... .......... 84%  257M 0s\n"," 54900K .......... .......... .......... .......... .......... 84%  228M 0s\n"," 54950K .......... .......... .......... .......... .......... 84%  218M 0s\n"," 55000K .......... .......... .......... .......... .......... 84%  180M 0s\n"," 55050K .......... .......... .......... .......... .......... 84%  260M 0s\n"," 55100K .......... .......... .......... .......... .......... 84%  255M 0s\n"," 55150K .......... .......... .......... .......... .......... 84%  213M 0s\n"," 55200K .......... .......... .......... .......... .......... 84%  241M 0s\n"," 55250K .......... .......... .......... .......... .......... 84%  260M 0s\n"," 55300K .......... .......... .......... .......... .......... 84%  277M 0s\n"," 55350K .......... .......... .......... .......... .......... 85%  241M 0s\n"," 55400K .......... .......... .......... .......... .......... 85%  196M 0s\n"," 55450K .......... .......... .......... .......... .......... 85%  148M 0s\n"," 55500K .......... .......... .......... .......... .......... 85%  170M 0s\n"," 55550K .......... .......... .......... .......... .......... 85%  214M 0s\n"," 55600K .......... .......... .......... .......... .......... 85%  186M 0s\n"," 55650K .......... .......... .......... .......... .......... 85%  158M 0s\n"," 55700K .......... .......... .......... .......... .......... 85%  269M 0s\n"," 55750K .......... .......... .......... .......... .......... 85%  198M 0s\n"," 55800K .......... .......... .......... .......... .......... 85%  246M 0s\n"," 55850K .......... .......... .......... .......... .......... 85%  283M 0s\n"," 55900K .......... .......... .......... .......... .......... 85%  265M 0s\n"," 55950K .......... .......... .......... .......... .......... 85%  232M 0s\n"," 56000K .......... .......... .......... .......... .......... 86%  249M 0s\n"," 56050K .......... .......... .......... .......... .......... 86% 40.6M 0s\n"," 56100K .......... .......... .......... .......... .......... 86%  124M 0s\n"," 56150K .......... .......... .......... .......... .......... 86%  178M 0s\n"," 56200K .......... .......... .......... .......... .......... 86%  154M 0s\n"," 56250K .......... .......... .......... .......... .......... 86%  142M 0s\n"," 56300K .......... .......... .......... .......... .......... 86%  197M 0s\n"," 56350K .......... .......... .......... .......... .......... 86%  201M 0s\n"," 56400K .......... .......... .......... .......... .......... 86%  271M 0s\n"," 56450K .......... .......... .......... .......... .......... 86%  264M 0s\n"," 56500K .......... .......... .......... .......... .......... 86%  275M 0s\n"," 56550K .......... .......... .......... .......... .......... 86%  271M 0s\n"," 56600K .......... .......... .......... .......... .......... 86%  291M 0s\n"," 56650K .......... .......... .......... .......... .......... 87%  271M 0s\n"," 56700K .......... .......... .......... .......... .......... 87%  263M 0s\n"," 56750K .......... .......... .......... .......... .......... 87%  246M 0s\n"," 56800K .......... .......... .......... .......... .......... 87%  179M 0s\n"," 56850K .......... .......... .......... .......... .......... 87%  191M 0s\n"," 56900K .......... .......... .......... .......... .......... 87%  261M 0s\n"," 56950K .......... .......... .......... .......... .......... 87%  238M 0s\n"," 57000K .......... .......... .......... .......... .......... 87%  286M 0s\n"," 57050K .......... .......... .......... .......... .......... 87%  292M 0s\n"," 57100K .......... .......... .......... .......... .......... 87% 10.2M 0s\n"," 57150K .......... .......... .......... .......... .......... 87%  201M 0s\n"," 57200K .......... .......... .......... .......... .......... 87%  222M 0s\n"," 57250K .......... .......... .......... .......... .......... 87%  256M 0s\n"," 57300K .......... .......... .......... .......... .......... 88% 23.4M 0s\n"," 57350K .......... .......... .......... .......... .......... 88%  198M 0s\n"," 57400K .......... .......... .......... .......... .......... 88%  303M 0s\n"," 57450K .......... .......... .......... .......... .......... 88%  247M 0s\n"," 57500K .......... .......... .......... .......... .......... 88%  295M 0s\n"," 57550K .......... .......... .......... .......... .......... 88%  176M 0s\n"," 57600K .......... .......... .......... .......... .......... 88%  378M 0s\n"," 57650K .......... .......... .......... .......... .......... 88%  374M 0s\n"," 57700K .......... .......... .......... .......... .......... 88%  376M 0s\n"," 57750K .......... .......... .......... .......... .......... 88%  265M 0s\n"," 57800K .......... .......... .......... .......... .......... 88%  294M 0s\n"," 57850K .......... .......... .......... .......... .......... 88%  323M 0s\n"," 57900K .......... .......... .......... .......... .......... 88%  307M 0s\n"," 57950K .......... .......... .......... .......... .......... 89%  208M 0s\n"," 58000K .......... .......... .......... .......... .......... 89% 77.1M 0s\n"," 58050K .......... .......... .......... .......... .......... 89%  303M 0s\n"," 58100K .......... .......... .......... .......... .......... 89%  392M 0s\n"," 58150K .......... .......... .......... .......... .......... 89%  336M 0s\n"," 58200K .......... .......... .......... .......... .......... 89%  311M 0s\n"," 58250K .......... .......... .......... .......... .......... 89%  405M 0s\n"," 58300K .......... .......... .......... .......... .......... 89%  412M 0s\n"," 58350K .......... .......... .......... .......... .......... 89%  331M 0s\n"," 58400K .......... .......... .......... .......... .......... 89%  266M 0s\n"," 58450K .......... .......... .......... .......... .......... 89%  355M 0s\n"," 58500K .......... .......... .......... .......... .......... 89%  391M 0s\n"," 58550K .......... .......... .......... .......... .......... 89%  296M 0s\n"," 58600K .......... .......... .......... .......... .......... 90%  370M 0s\n"," 58650K .......... .......... .......... .......... .......... 90%  401M 0s\n"," 58700K .......... .......... .......... .......... .......... 90%  252M 0s\n"," 58750K .......... .......... .......... .......... .......... 90%  223M 0s\n"," 58800K .......... .......... .......... .......... .......... 90%  369M 0s\n"," 58850K .......... .......... .......... .......... .......... 90%  377M 0s\n"," 58900K .......... .......... .......... .......... .......... 90%  348M 0s\n"," 58950K .......... .......... .......... .......... .......... 90%  324M 0s\n"," 59000K .......... .......... .......... .......... .......... 90%  389M 0s\n"," 59050K .......... .......... .......... .......... .......... 90%  363M 0s\n"," 59100K .......... .......... .......... .......... .......... 90%  259M 0s\n"," 59150K .......... .......... .......... .......... .......... 90%  312M 0s\n"," 59200K .......... .......... .......... .......... .......... 90%  317M 0s\n"," 59250K .......... .......... .......... .......... .......... 91%  324M 0s\n"," 59300K .......... .......... .......... .......... .......... 91%  386M 0s\n"," 59350K .......... .......... .......... .......... .......... 91%  247M 0s\n"," 59400K .......... .......... .......... .......... .......... 91%  405M 0s\n"," 59450K .......... .......... .......... .......... .......... 91%  424M 0s\n"," 59500K .......... .......... .......... .......... .......... 91%  307M 0s\n"," 59550K .......... .......... .......... .......... .......... 91%  257M 0s\n"," 59600K .......... .......... .......... .......... .......... 91%  436M 0s\n"," 59650K .......... .......... .......... .......... .......... 91%  345M 0s\n"," 59700K .......... .......... .......... .......... .......... 91%  322M 0s\n"," 59750K .......... .......... .......... .......... .......... 91%  229M 0s\n"," 59800K .......... .......... .......... .......... .......... 91%  272M 0s\n"," 59850K .......... .......... .......... .......... .......... 91%  348M 0s\n"," 59900K .......... .......... .......... .......... .......... 92%  442M 0s\n"," 59950K .......... .......... .......... .......... .......... 92%  252M 0s\n"," 60000K .......... .......... .......... .......... .......... 92%  422M 0s\n"," 60050K .......... .......... .......... .......... .......... 92%  335M 0s\n"," 60100K .......... .......... .......... .......... .......... 92%  290M 0s\n"," 60150K .......... .......... .......... .......... .......... 92%  263M 0s\n"," 60200K .......... .......... .......... .......... .......... 92%  420M 0s\n"," 60250K .......... .......... .......... .......... .......... 92% 37.3M 0s\n"," 60300K .......... .......... .......... .......... .......... 92%  291M 0s\n"," 60350K .......... .......... .......... .......... .......... 92%  261M 0s\n"," 60400K .......... .......... .......... .......... .......... 92%  270M 0s\n"," 60450K .......... .......... .......... .......... .......... 92%  338M 0s\n"," 60500K .......... .......... .......... .......... .......... 92%  254M 0s\n"," 60550K .......... .......... .......... .......... .......... 93%  189M 0s\n"," 60600K .......... .......... .......... .......... .......... 93%  254M 0s\n"," 60650K .......... .......... .......... .......... .......... 93%  255M 0s\n"," 60700K .......... .......... .......... .......... .......... 93% 40.8M 0s\n"," 60750K .......... .......... .......... .......... .......... 93%  189M 0s\n"," 60800K .......... .......... .......... .......... .......... 93%  247M 0s\n"," 60850K .......... .......... .......... .......... .......... 93%  384M 0s\n"," 60900K .......... .......... .......... .......... .......... 93%  346M 0s\n"," 60950K .......... .......... .......... .......... .......... 93%  256M 0s\n"," 61000K .......... .......... .......... .......... .......... 93%  242M 0s\n"," 61050K .......... .......... .......... .......... .......... 93%  307M 0s\n"," 61100K .......... .......... .......... .......... .......... 93%  313M 0s\n"," 61150K .......... .......... .......... .......... .......... 93%  243M 0s\n"," 61200K .......... .......... .......... .......... .......... 94%  376M 0s\n"," 61250K .......... .......... .......... .......... .......... 94%  396M 0s\n"," 61300K .......... .......... .......... .......... .......... 94%  253M 0s\n"," 61350K .......... .......... .......... .......... .......... 94%  199M 0s\n"," 61400K .......... .......... .......... .......... .......... 94%  241M 0s\n"," 61450K .......... .......... .......... .......... .......... 94%  377M 0s\n"," 61500K .......... .......... .......... .......... .......... 94%  374M 0s\n"," 61550K .......... .......... .......... .......... .......... 94%  267M 0s\n"," 61600K .......... .......... .......... .......... .......... 94%  217M 0s\n"," 61650K .......... .......... .......... .......... .......... 94%  292M 0s\n"," 61700K .......... .......... .......... .......... .......... 94%  297M 0s\n"," 61750K .......... .......... .......... .......... .......... 94%  262M 0s\n"," 61800K .......... .......... .......... .......... .......... 94%  217M 0s\n"," 61850K .......... .......... .......... .......... .......... 95%  223M 0s\n"," 61900K .......... .......... .......... .......... .......... 95%  303M 0s\n"," 61950K .......... .......... .......... .......... .......... 95%  207M 0s\n"," 62000K .......... .......... .......... .......... .......... 95%  404M 0s\n"," 62050K .......... .......... .......... .......... .......... 95%  420M 0s\n"," 62100K .......... .......... .......... .......... .......... 95%  274M 0s\n"," 62150K .......... .......... .......... .......... .......... 95%  373M 0s\n"," 62200K .......... .......... .......... .......... .......... 95%  463M 0s\n"," 62250K .......... .......... .......... .......... .......... 95%  415M 0s\n"," 62300K .......... .......... .......... .......... .......... 95%  318M 0s\n"," 62350K .......... .......... .......... .......... .......... 95%  369M 0s\n"," 62400K .......... .......... .......... .......... .......... 95%  443M 0s\n"," 62450K .......... .......... .......... .......... .......... 95%  400M 0s\n"," 62500K .......... .......... .......... .......... .......... 96%  312M 0s\n"," 62550K .......... .......... .......... .......... .......... 96%  281M 0s\n"," 62600K .......... .......... .......... .......... .......... 96%  395M 0s\n"," 62650K .......... .......... .......... .......... .......... 96%  386M 0s\n"," 62700K .......... .......... .......... .......... .......... 96%  261M 0s\n"," 62750K .......... .......... .......... .......... .......... 96%  311M 0s\n"," 62800K .......... .......... .......... .......... .......... 96%  365M 0s\n"," 62850K .......... .......... .......... .......... .......... 96%  370M 0s\n"," 62900K .......... .......... .......... .......... .......... 96% 71.9M 0s\n"," 62950K .......... .......... .......... .......... .......... 96%  291M 0s\n"," 63000K .......... .......... .......... .......... .......... 96%  388M 0s\n"," 63050K .......... .......... .......... .......... .......... 96%  321M 0s\n"," 63100K .......... .......... .......... .......... .......... 96%  384M 0s\n"," 63150K .......... .......... .......... .......... .......... 97% 87.2M 0s\n"," 63200K .......... .......... .......... .......... .......... 97%  246M 0s\n"," 63250K .......... .......... .......... .......... .......... 97%  298M 0s\n"," 63300K .......... .......... .......... .......... .......... 97%  310M 0s\n"," 63350K .......... .......... .......... .......... .......... 97% 18.1M 0s\n"," 63400K .......... .......... .......... .......... .......... 97%  120M 0s\n"," 63450K .......... .......... .......... .......... .......... 97%  163M 0s\n"," 63500K .......... .......... .......... .......... .......... 97%  184M 0s\n"," 63550K .......... .......... .......... .......... .......... 97%  116M 0s\n"," 63600K .......... .......... .......... .......... .......... 97%  196M 0s\n"," 63650K .......... .......... .......... .......... .......... 97%  228M 0s\n"," 63700K .......... .......... .......... .......... .......... 97%  182M 0s\n"," 63750K .......... .......... .......... .......... .......... 97%  102M 0s\n"," 63800K .......... .......... .......... .......... .......... 98%  186M 0s\n"," 63850K .......... .......... .......... .......... .......... 98%  265M 0s\n"," 63900K .......... .......... .......... .......... .......... 98%  135M 0s\n"," 63950K .......... .......... .......... .......... .......... 98%  195M 0s\n"," 64000K .......... .......... .......... .......... .......... 98%  277M 0s\n"," 64050K .......... .......... .......... .......... .......... 98%  278M 0s\n"," 64100K .......... .......... .......... .......... .......... 98%  249M 0s\n"," 64150K .......... .......... .......... .......... .......... 98%  212M 0s\n"," 64200K .......... .......... .......... .......... .......... 98%  275M 0s\n"," 64250K .......... .......... .......... .......... .......... 98%  290M 0s\n"," 64300K .......... .......... .......... .......... .......... 98%  265M 0s\n"," 64350K .......... .......... .......... .......... .......... 98%  243M 0s\n"," 64400K .......... .......... .......... .......... .......... 98%  269M 0s\n"," 64450K .......... .......... .......... .......... .......... 99%  321M 0s\n"," 64500K .......... .......... .......... .......... .......... 99%  276M 0s\n"," 64550K .......... .......... .......... .......... .......... 99%  255M 0s\n"," 64600K .......... .......... .......... .......... .......... 99%  267M 0s\n"," 64650K .......... .......... .......... .......... .......... 99%  278M 0s\n"," 64700K .......... .......... .......... .......... .......... 99%  255M 0s\n"," 64750K .......... .......... .......... .......... .......... 99%  209M 0s\n"," 64800K .......... .......... .......... .......... .......... 99%  238M 0s\n"," 64850K .......... .......... .......... .......... .......... 99%  264M 0s\n"," 64900K .......... .......... .......... .......... .......... 99%  254M 0s\n"," 64950K .......... .......... .......... .......... .......... 99%  228M 0s\n"," 65000K .......... .......... .......... .......... .......... 99%  277M 0s\n"," 65050K .......... .......... .......... .......... .......... 99%  258M 0s\n"," 65100K .......... .......... .......... .......... ......    100%  261M=0.4s\n","\n","2021-12-24 15:33:41 (164 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [66709754/66709754]\n","\n","\r  0%|          | 0/38 [00:00<?, ?it/s]\rExtracting : readline-8.1-h27cfd23_0.conda:   0%|          | 0/38 [00:00<?, ?it/s]\rExtracting : ruamel_yaml-0.15.100-py39h27cfd23_0.conda:   3%|▎         | 1/38 [00:00<00:03, 10.40it/s]\rExtracting : tk-8.6.10-hbc83047_0.conda:   5%|▌         | 2/38 [00:00<00:03, 11.99it/s]               \rExtracting : tk-8.6.10-hbc83047_0.conda:   8%|▊         | 3/38 [00:00<00:01, 17.97it/s]\rExtracting : yaml-0.2.5-h7b6447c_0.conda:   8%|▊         | 3/38 [00:00<00:01, 17.97it/s]\rExtracting : openssl-1.1.1k-h27cfd23_0.conda:  11%|█         | 4/38 [00:00<00:01, 17.97it/s]\rExtracting : openssl-1.1.1k-h27cfd23_0.conda:  13%|█▎        | 5/38 [00:00<00:02, 15.58it/s]\rExtracting : ld_impl_linux-64-2.35.1-h7274673_9.conda:  13%|█▎        | 5/38 [00:00<00:02, 15.58it/s]\rExtracting : ncurses-6.2-he6710b0_1.conda:  16%|█▌        | 6/38 [00:00<00:02, 15.58it/s]            \rExtracting : ncurses-6.2-he6710b0_1.conda:  18%|█▊        | 7/38 [00:00<00:02, 15.28it/s]\rExtracting : chardet-4.0.0-py39h06a4308_1003.conda:  18%|█▊        | 7/38 [00:00<00:02, 15.28it/s]\rExtracting : pysocks-1.7.1-py39h06a4308_0.conda:  21%|██        | 8/38 [00:00<00:01, 15.28it/s]   \rExtracting : wheel-0.36.2-pyhd3eb1b0_0.conda:  24%|██▎       | 9/38 [00:00<00:01, 15.28it/s]   \rExtracting : setuptools-52.0.0-py39h06a4308_0.conda:  26%|██▋       | 10/38 [00:00<00:01, 15.28it/s]\rExtracting : urllib3-1.26.6-pyhd3eb1b0_1.conda:  29%|██▉       | 11/38 [00:00<00:01, 15.28it/s]     \rExtracting : brotlipy-0.7.0-py39h27cfd23_1003.conda:  32%|███▏      | 12/38 [00:00<00:01, 15.28it/s]\rExtracting : tqdm-4.61.2-pyhd3eb1b0_1.conda:  34%|███▍      | 13/38 [00:00<00:01, 15.28it/s]        \rExtracting : pycosat-0.6.3-py39h27cfd23_0.conda:  37%|███▋      | 14/38 [00:00<00:01, 15.28it/s]\rExtracting : pycosat-0.6.3-py39h27cfd23_0.conda:  39%|███▉      | 15/38 [00:00<00:01, 18.98it/s]\rExtracting : requests-2.25.1-pyhd3eb1b0_0.conda:  39%|███▉      | 15/38 [00:00<00:01, 18.98it/s]\rExtracting : cryptography-3.4.7-py39hd23ed53_0.conda:  42%|████▏     | 16/38 [00:00<00:01, 18.98it/s]\rExtracting : _libgcc_mutex-0.1-main.conda:  45%|████▍     | 17/38 [00:00<00:01, 18.98it/s]           \rExtracting : libgomp-9.3.0-h5101ec6_17.conda:  47%|████▋     | 18/38 [00:00<00:01, 18.98it/s]\rExtracting : sqlite-3.36.0-hc218d9a_0.conda:  50%|█████     | 19/38 [00:00<00:01, 18.98it/s] \rExtracting : tzdata-2021a-h52ac0ba_0.conda:  53%|█████▎    | 20/38 [00:00<00:00, 18.98it/s] \rExtracting : libffi-3.3-he6710b0_2.conda:  55%|█████▌    | 21/38 [00:00<00:00, 18.98it/s]  \rExtracting : ca-certificates-2021.7.5-h06a4308_1.conda:  58%|█████▊    | 22/38 [00:00<00:00, 18.98it/s]\rExtracting : libgcc-ng-9.3.0-h5101ec6_17.conda:  61%|██████    | 23/38 [00:00<00:00, 18.98it/s]        \rExtracting : libgcc-ng-9.3.0-h5101ec6_17.conda:  63%|██████▎   | 24/38 [00:00<00:00, 21.63it/s]\rExtracting : libstdcxx-ng-9.3.0-hd4cf53a_17.conda:  63%|██████▎   | 24/38 [00:00<00:00, 21.63it/s]\rExtracting : pycparser-2.20-py_2.conda:  66%|██████▌   | 25/38 [00:00<00:00, 21.63it/s]           \rExtracting : conda-package-handling-1.7.3-py39h27cfd23_1.conda:  68%|██████▊   | 26/38 [00:00<00:00, 21.63it/s]\rExtracting : pyopenssl-20.0.1-pyhd3eb1b0_1.conda:  71%|███████   | 27/38 [00:00<00:00, 21.63it/s]              \rExtracting : zlib-1.2.11-h7b6447c_3.conda:  74%|███████▎  | 28/38 [00:00<00:00, 21.63it/s]       \rExtracting : pip-21.1.3-py39h06a4308_0.conda:  76%|███████▋  | 29/38 [00:01<00:00, 21.63it/s]\rExtracting : six-1.16.0-pyhd3eb1b0_0.conda:  79%|███████▉  | 30/38 [00:01<00:00, 21.63it/s]  \rExtracting : xz-5.2.5-h7b6447c_0.conda:  82%|████████▏ | 31/38 [00:01<00:00, 21.63it/s]    \rExtracting : certifi-2021.5.30-py39h06a4308_0.conda:  84%|████████▍ | 32/38 [00:01<00:00, 21.63it/s]\rExtracting : cffi-1.14.6-py39h400218f_0.conda:  87%|████████▋ | 33/38 [00:01<00:00, 21.63it/s]      \rExtracting : cffi-1.14.6-py39h400218f_0.conda:  89%|████████▉ | 34/38 [00:01<00:00, 26.52it/s]\rExtracting : python-3.9.5-h12debd9_4.tar.bz2:  89%|████████▉ | 34/38 [00:04<00:00, 26.52it/s] \rExtracting : conda-4.10.3-py39h06a4308_0.tar.bz2:  92%|█████████▏| 35/38 [00:04<00:00, 26.52it/s]\rExtracting : _openmp_mutex-4.5-1_gnu.tar.bz2:  95%|█████████▍| 36/38 [00:04<00:00, 26.52it/s]    \rExtracting : idna-2.10-pyhd3eb1b0_0.tar.bz2:  97%|█████████▋| 37/38 [00:04<00:00, 26.52it/s] \rExtracting : idna-2.10-pyhd3eb1b0_0.tar.bz2: 100%|██████████| 38/38 [00:04<00:00,  3.28it/s]\r                                                                                            \r"]}],"source":["%%bash\n","MINICONDA_INSTALLER_SCRIPT=Miniconda3-latest-Linux-x86_64.sh\n","MINICONDA_PREFIX=/usr/local\n","wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n","chmod +x $MINICONDA_INSTALLER_SCRIPT\n","./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":605,"status":"ok","timestamp":1640360063669,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"K5vObL7Osczi","outputId":"94f84510-ad9b-4aff-d491-d102a47fde87"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/bin/conda\n"]}],"source":["!which conda # should return /usr/local/bin/conda"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8794,"status":"ok","timestamp":1621631531651,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"E4We4KA4xMIS","outputId":"974bf67e-b198-4a2c-f667-51ceee442a3f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n","Solving environment: / \b\bdone\n","\n","## Package Plan ##\n","\n","  environment location: /usr/local/envs/cadd\n","\n","\n","\n","Proceed ([y]/n)? y\n","\n","Preparing transaction: \\ \b\bdone\n","Verifying transaction: / \b\bdone\n","Executing transaction: \\ \b\bdone\n","#\n","# To activate this environment, use\n","#\n","#     $ conda activate cadd\n","#\n","# To deactivate an active environment, use\n","#\n","#     $ conda deactivate\n","\n"]}],"source":["!conda create -n cadd\n","!source activate cadd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qub3K94Asc7w","outputId":"f4c3b796-7c8e-4554-c393-542781c7c740"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n","Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n","\n","\n","==> WARNING: A newer version of conda exists. <==\n","  current version: 4.10.3\n","  latest version: 4.11.0\n","\n","Please update conda by running\n","\n","    $ conda update -n base -c defaults conda\n","\n","\n","\n","## Package Plan ##\n","\n","  environment location: /usr/local\n","\n","  added / updated specs:\n","    - rdkit\n","\n","\n","The following packages will be downloaded:\n","\n","    package                    |            build\n","    ---------------------------|-----------------\n","    boost-1.74.0               |   py39h5472131_3         368 KB  conda-forge\n","    boost-cpp-1.74.0           |       h9359b55_0        16.4 MB  conda-forge\n","    bzip2-1.0.8                |       h7f98852_4         484 KB  conda-forge\n","    ca-certificates-2021.10.8  |       ha878542_0         139 KB  conda-forge\n","    cairo-1.16.0               |    h3fc0475_1005         1.5 MB  conda-forge\n","    certifi-2021.10.8          |   py39hf3d152e_1         145 KB  conda-forge\n","    conda-4.11.0               |   py39hf3d152e_0        16.8 MB  conda-forge\n","    cycler-0.11.0              |     pyhd8ed1ab_0          10 KB  conda-forge\n","    fontconfig-2.13.1          |    hba837de_1005         357 KB  conda-forge\n","    freetype-2.10.4            |       h0708190_1         890 KB  conda-forge\n","    glib-2.69.1                |       h5202010_0         1.7 MB\n","    icu-67.1                   |       he1b5a44_0        12.9 MB  conda-forge\n","    jpeg-9d                    |       h36c2ea0_0         264 KB  conda-forge\n","    kiwisolver-1.3.1           |   py39h2531618_0          80 KB\n","    lcms2-2.12                 |       hddcbb42_0         443 KB  conda-forge\n","    libblas-3.9.0              |11_linux64_openblas          12 KB  conda-forge\n","    libcblas-3.9.0             |11_linux64_openblas          11 KB  conda-forge\n","    libgfortran-ng-11.2.0      |      h69a702a_11          19 KB  conda-forge\n","    libgfortran5-11.2.0        |      h5c6108e_11         1.7 MB  conda-forge\n","    libiconv-1.16              |       h516909a_0         1.4 MB  conda-forge\n","    liblapack-3.9.0            |11_linux64_openblas          11 KB  conda-forge\n","    libopenblas-0.3.17         |pthreads_h8fe5266_1         9.2 MB  conda-forge\n","    libpng-1.6.37              |       h21135ba_2         306 KB  conda-forge\n","    libtiff-4.2.0              |       h85742a9_0         502 KB\n","    libuuid-2.32.1             |    h7f98852_1000          28 KB  conda-forge\n","    libwebp-base-1.2.0         |       h27cfd23_0         437 KB\n","    libxcb-1.13                |    h7f98852_1003         395 KB  conda-forge\n","    libxml2-2.9.10             |       h68273f3_2         1.3 MB  conda-forge\n","    lz4-c-1.9.3                |       h9c3ff4c_1         179 KB  conda-forge\n","    matplotlib-base-3.3.4      |   py39h2fa2bec_0         6.7 MB  conda-forge\n","    numpy-1.20.3               |   py39hdbf815f_1         5.8 MB  conda-forge\n","    olefile-0.46               |     pyh9f0ad1d_1          32 KB  conda-forge\n","    openssl-1.1.1l             |       h7f8727e_0         2.5 MB\n","    pandas-1.2.5               |   py39hde0f152_0        12.1 MB  conda-forge\n","    pcre-8.45                  |       h9c3ff4c_0         253 KB  conda-forge\n","    pillow-7.2.0               |   py39h6f3857e_2         678 KB  conda-forge\n","    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n","    pthread-stubs-0.4          |    h36c2ea0_1001           5 KB  conda-forge\n","    pycairo-1.20.1             |   py39hedcb9fc_0          77 KB  conda-forge\n","    pyparsing-3.0.6            |     pyhd8ed1ab_0          79 KB  conda-forge\n","    python-dateutil-2.8.2      |     pyhd8ed1ab_0         240 KB  conda-forge\n","    python_abi-3.9             |           2_cp39           4 KB  conda-forge\n","    pytz-2021.3                |     pyhd8ed1ab_0         242 KB  conda-forge\n","    rdkit-2020.09.5            |   py39hccf6a74_0        26.3 MB  conda-forge\n","    reportlab-3.5.68           |   py39he59360d_0         2.4 MB  conda-forge\n","    sqlalchemy-1.3.23          |   py39h3811e60_0         1.9 MB  conda-forge\n","    tornado-6.1                |   py39h3811e60_1         646 KB  conda-forge\n","    xorg-kbproto-1.0.7         |    h7f98852_1002          27 KB  conda-forge\n","    xorg-libice-1.0.10         |       h7f98852_0          58 KB  conda-forge\n","    xorg-libsm-1.2.3           |    hd9c2040_1000          26 KB  conda-forge\n","    xorg-libx11-1.7.2          |       h7f98852_0         941 KB  conda-forge\n","    xorg-libxau-1.0.9          |       h7f98852_0          13 KB  conda-forge\n","    xorg-libxdmcp-1.1.3        |       h7f98852_0          19 KB  conda-forge\n","    xorg-libxext-1.3.4         |       h7f98852_1          54 KB  conda-forge\n","    xorg-libxrender-0.9.10     |    h7f98852_1003          32 KB  conda-forge\n","    xorg-renderproto-0.11.1    |    h7f98852_1002           9 KB  conda-forge\n","    xorg-xextproto-7.3.0       |    h7f98852_1002          28 KB  conda-forge\n","    xorg-xproto-7.0.31         |    h7f98852_1007          73 KB  conda-forge\n","    zstd-1.4.9                 |       ha95c52a_0         431 KB  conda-forge\n","    ------------------------------------------------------------\n","                                           Total:       130.0 MB\n","\n","The following NEW packages will be INSTALLED:\n","\n","  boost              conda-forge/linux-64::boost-1.74.0-py39h5472131_3\n","  boost-cpp          conda-forge/linux-64::boost-cpp-1.74.0-h9359b55_0\n","  bzip2              conda-forge/linux-64::bzip2-1.0.8-h7f98852_4\n","  cairo              conda-forge/linux-64::cairo-1.16.0-h3fc0475_1005\n","  cycler             conda-forge/noarch::cycler-0.11.0-pyhd8ed1ab_0\n","  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-hba837de_1005\n","  freetype           conda-forge/linux-64::freetype-2.10.4-h0708190_1\n","  glib               pkgs/main/linux-64::glib-2.69.1-h5202010_0\n","  icu                conda-forge/linux-64::icu-67.1-he1b5a44_0\n","  jpeg               conda-forge/linux-64::jpeg-9d-h36c2ea0_0\n","  kiwisolver         pkgs/main/linux-64::kiwisolver-1.3.1-py39h2531618_0\n","  lcms2              conda-forge/linux-64::lcms2-2.12-hddcbb42_0\n","  libblas            conda-forge/linux-64::libblas-3.9.0-11_linux64_openblas\n","  libcblas           conda-forge/linux-64::libcblas-3.9.0-11_linux64_openblas\n","  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-11.2.0-h69a702a_11\n","  libgfortran5       conda-forge/linux-64::libgfortran5-11.2.0-h5c6108e_11\n","  libiconv           conda-forge/linux-64::libiconv-1.16-h516909a_0\n","  liblapack          conda-forge/linux-64::liblapack-3.9.0-11_linux64_openblas\n","  libopenblas        conda-forge/linux-64::libopenblas-0.3.17-pthreads_h8fe5266_1\n","  libpng             conda-forge/linux-64::libpng-1.6.37-h21135ba_2\n","  libtiff            pkgs/main/linux-64::libtiff-4.2.0-h85742a9_0\n","  libuuid            conda-forge/linux-64::libuuid-2.32.1-h7f98852_1000\n","  libwebp-base       pkgs/main/linux-64::libwebp-base-1.2.0-h27cfd23_0\n","  libxcb             conda-forge/linux-64::libxcb-1.13-h7f98852_1003\n","  libxml2            conda-forge/linux-64::libxml2-2.9.10-h68273f3_2\n","  lz4-c              conda-forge/linux-64::lz4-c-1.9.3-h9c3ff4c_1\n","  matplotlib-base    conda-forge/linux-64::matplotlib-base-3.3.4-py39h2fa2bec_0\n","  numpy              conda-forge/linux-64::numpy-1.20.3-py39hdbf815f_1\n","  olefile            conda-forge/noarch::olefile-0.46-pyh9f0ad1d_1\n","  pandas             conda-forge/linux-64::pandas-1.2.5-py39hde0f152_0\n","  pcre               conda-forge/linux-64::pcre-8.45-h9c3ff4c_0\n","  pillow             conda-forge/linux-64::pillow-7.2.0-py39h6f3857e_2\n","  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n","  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h36c2ea0_1001\n","  pycairo            conda-forge/linux-64::pycairo-1.20.1-py39hedcb9fc_0\n","  pyparsing          conda-forge/noarch::pyparsing-3.0.6-pyhd8ed1ab_0\n","  python-dateutil    conda-forge/noarch::python-dateutil-2.8.2-pyhd8ed1ab_0\n","  python_abi         conda-forge/linux-64::python_abi-3.9-2_cp39\n","  pytz               conda-forge/noarch::pytz-2021.3-pyhd8ed1ab_0\n","  rdkit              conda-forge/linux-64::rdkit-2020.09.5-py39hccf6a74_0\n","  reportlab          conda-forge/linux-64::reportlab-3.5.68-py39he59360d_0\n","  sqlalchemy         conda-forge/linux-64::sqlalchemy-1.3.23-py39h3811e60_0\n","  tornado            conda-forge/linux-64::tornado-6.1-py39h3811e60_1\n","  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h7f98852_1002\n","  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h7f98852_0\n","  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-hd9c2040_1000\n","  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.7.2-h7f98852_0\n","  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h7f98852_0\n","  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h7f98852_0\n","  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h7f98852_1\n","  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h7f98852_1003\n","  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h7f98852_1002\n","  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h7f98852_1002\n","  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h7f98852_1007\n","  zstd               conda-forge/linux-64::zstd-1.4.9-ha95c52a_0\n","\n","The following packages will be UPDATED:\n","\n","  ca-certificates    pkgs/main::ca-certificates-2021.7.5-h~ --> conda-forge::ca-certificates-2021.10.8-ha878542_0\n","  certifi            pkgs/main::certifi-2021.5.30-py39h06a~ --> conda-forge::certifi-2021.10.8-py39hf3d152e_1\n","  conda              pkgs/main::conda-4.10.3-py39h06a4308_0 --> conda-forge::conda-4.11.0-py39hf3d152e_0\n","  openssl                                 1.1.1k-h27cfd23_0 --> 1.1.1l-h7f8727e_0\n","\n","\n","Proceed ([y]/n)? y\n","\n","\n","Downloading and Extracting Packages\n","lcms2-2.12           | 443 KB    | : 100% 1.0/1 [00:00<00:00,  4.25it/s]                \n","cycler-0.11.0        | 10 KB     | : 100% 1.0/1 [00:00<00:00, 28.28it/s]\n","cairo-1.16.0         | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  3.31it/s]\n","reportlab-3.5.68     | 2.4 MB    | : 100% 1.0/1 [00:00<00:00,  2.52it/s]\n","ca-certificates-2021 | 139 KB    | : 100% 1.0/1 [00:00<00:00, 18.74it/s]\n","icu-67.1             | 12.9 MB   | : 100% 1.0/1 [00:01<00:00,  1.73s/it]               \n","pandas-1.2.5         | 12.1 MB   | : 100% 1.0/1 [00:02<00:00,  2.22s/it]               \n","lz4-c-1.9.3          | 179 KB    | : 100% 1.0/1 [00:00<00:00, 15.49it/s]\n","xorg-libxau-1.0.9    | 13 KB     | : 100% 1.0/1 [00:00<00:00, 23.55it/s]\n","xorg-libxdmcp-1.1.3  | 19 KB     | : 100% 1.0/1 [00:00<00:00, 21.37it/s]\n","libtiff-4.2.0        | 502 KB    | : 100% 1.0/1 [00:00<00:00,  5.87it/s]                \n","python-dateutil-2.8. | 240 KB    | : 100% 1.0/1 [00:00<00:00, 14.93it/s]\n","libuuid-2.32.1       | 28 KB     | : 100% 1.0/1 [00:00<00:00, 22.86it/s]\n","xorg-renderproto-0.1 | 9 KB      | : 100% 1.0/1 [00:00<00:00, 28.24it/s]\n","libgfortran-ng-11.2. | 19 KB     | : 100% 1.0/1 [00:00<00:00, 22.09it/s]\n","zstd-1.4.9           | 431 KB    | : 100% 1.0/1 [00:00<00:00,  9.58it/s]\n","libiconv-1.16        | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  5.36it/s]\n","pycairo-1.20.1       | 77 KB     | : 100% 1.0/1 [00:00<00:00, 21.06it/s]\n","xorg-xproto-7.0.31   | 73 KB     | : 100% 1.0/1 [00:00<00:00, 13.48it/s]\n","matplotlib-base-3.3. | 6.7 MB    | : 100% 1.0/1 [00:01<00:00,  1.05s/it]\n","conda-4.11.0         | 16.8 MB   | : 100% 1.0/1 [00:03<00:00,  3.62s/it]               \n","fontconfig-2.13.1    | 357 KB    | : 100% 1.0/1 [00:00<00:00,  4.22it/s]\n","libwebp-base-1.2.0   | 437 KB    | : 100% 1.0/1 [00:00<00:00,  6.26it/s]\n","xorg-libxrender-0.9. | 32 KB     | : 100% 1.0/1 [00:00<00:00, 18.17it/s]\n","rdkit-2020.09.5      | 26.3 MB   | : 100% 1.0/1 [00:04<00:00,  4.10s/it]               \n","numpy-1.20.3         | 5.8 MB    | : 100% 1.0/1 [00:01<00:00,  1.14s/it]\n","liblapack-3.9.0      | 11 KB     | : 100% 1.0/1 [00:00<00:00, 22.56it/s]\n","sqlalchemy-1.3.23    | 1.9 MB    | : 100% 1.0/1 [00:00<00:00,  2.26it/s]\n","olefile-0.46         | 32 KB     | : 100% 1.0/1 [00:00<00:00, 24.36it/s]\n","libblas-3.9.0        | 12 KB     | : 100% 1.0/1 [00:00<00:00, 20.25it/s]\n","boost-cpp-1.74.0     | 16.4 MB   | : 100% 1.0/1 [00:05<00:00,  5.32s/it]               \n","pyparsing-3.0.6      | 79 KB     | : 100% 1.0/1 [00:00<00:00, 19.11it/s]\n","xorg-libsm-1.2.3     | 26 KB     | : 100% 1.0/1 [00:00<00:00, 23.73it/s]\n","glib-2.69.1          | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  7.78it/s]\n","python_abi-3.9       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 24.84it/s]\n","bzip2-1.0.8          | 484 KB    | : 100% 1.0/1 [00:00<00:00,  7.69it/s]\n","freetype-2.10.4      | 890 KB    | : 100% 1.0/1 [00:00<00:00,  5.98it/s]\n","libxcb-1.13          | 395 KB    | : 100% 1.0/1 [00:00<00:00,  7.47it/s]\n","libpng-1.6.37        | 306 KB    | : 100% 1.0/1 [00:00<00:00, 11.27it/s]\n","libxml2-2.9.10       | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  2.87it/s]\n","pillow-7.2.0         | 678 KB    | : 100% 1.0/1 [00:00<00:00,  6.20it/s]\n","boost-1.74.0         | 368 KB    | : 100% 1.0/1 [00:00<00:00,  8.12it/s]\n","kiwisolver-1.3.1     | 80 KB     | : 100% 1.0/1 [00:00<00:00, 16.51it/s]\n","xorg-kbproto-1.0.7   | 27 KB     | : 100% 1.0/1 [00:00<00:00, 21.89it/s]\n","libcblas-3.9.0       | 11 KB     | : 100% 1.0/1 [00:00<00:00, 28.35it/s]\n","jpeg-9d              | 264 KB    | : 100% 1.0/1 [00:00<00:00, 11.05it/s]\n","xorg-libx11-1.7.2    | 941 KB    | : 100% 1.0/1 [00:00<00:00,  5.57it/s]\n","xorg-libxext-1.3.4   | 54 KB     | : 100% 1.0/1 [00:00<00:00, 20.86it/s]\n","xorg-libice-1.0.10   | 58 KB     | : 100% 1.0/1 [00:00<00:00, 18.71it/s]\n","pytz-2021.3          | 242 KB    | : 100% 1.0/1 [00:00<00:00,  8.25it/s]\n","libopenblas-0.3.17   | 9.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.52s/it]               \n","certifi-2021.10.8    | 145 KB    | : 100% 1.0/1 [00:00<00:00, 19.97it/s]\n","tornado-6.1          | 646 KB    | : 100% 1.0/1 [00:00<00:00,  5.57it/s]\n","libgfortran5-11.2.0  | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.23it/s]\n","pthread-stubs-0.4    | 5 KB      | : 100% 1.0/1 [00:00<00:00, 26.80it/s]\n","pixman-0.38.0        | 594 KB    | : 100% 1.0/1 [00:00<00:00,  8.52it/s]\n","pcre-8.45            | 253 KB    | : 100% 1.0/1 [00:00<00:00, 13.24it/s]\n","xorg-xextproto-7.3.0 | 28 KB     | : 100% 1.0/1 [00:00<00:00, 23.93it/s]\n","openssl-1.1.1l       | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  7.79it/s]\n","Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n","Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n","Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n","Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n","Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n","\n","## Package Plan ##\n","\n","  environment location: /usr/local\n","\n","  added / updated specs:\n","    - pytorch_geometric\n","    - pytorch_sparse\n","    - torch-scatter\n","\n","\n","The following packages will be downloaded:\n","\n","    package                    |            build\n","    ---------------------------|-----------------\n","    attrs-21.2.0               |     pyhd8ed1ab_0          44 KB  conda-forge\n","    coverage-5.5               |   py39h27cfd23_2         259 KB\n","    cudatoolkit-11.1.1         |       h6406543_8        1.20 GB  conda-forge\n","    cudnn-8.2.1.32             |       h86fa8c9_0       673.9 MB  conda-forge\n","    future-0.18.2              |   py39hf3d152e_4         715 KB  conda-forge\n","    googledrivedownloader-0.4  |     pyhd3deb0d_1           7 KB  conda-forge\n","    html5lib-1.1               |     pyh9f0ad1d_0          89 KB  conda-forge\n","    iniconfig-1.1.1            |     pyh9f0ad1d_0           8 KB  conda-forge\n","    intel-openmp-2021.4.0      |    h06a4308_3561         4.2 MB\n","    isodate-0.6.1              |     pyhd8ed1ab_0          28 KB  conda-forge\n","    jinja2-3.0.3               |     pyhd8ed1ab_0          99 KB  conda-forge\n","    joblib-1.1.0               |     pyhd8ed1ab_0         210 KB  conda-forge\n","    keepalive-0.5              |     pyhd8ed1ab_6          22 KB  conda-forge\n","    libblas-3.9.0              |   12_linux64_mkl          12 KB  conda-forge\n","    libcblas-3.9.0             |   12_linux64_mkl          12 KB  conda-forge\n","    liblapack-3.9.0            |   12_linux64_mkl          12 KB  conda-forge\n","    libprotobuf-3.16.0         |       h780b84a_0         2.5 MB  conda-forge\n","    magma-2.5.4                |       ha9b7cf9_2       104.7 MB  conda-forge\n","    markupsafe-2.0.1           |   py39h3811e60_0          22 KB  conda-forge\n","    mkl-2021.4.0               |     h06a4308_640       142.6 MB\n","    more-itertools-8.12.0      |     pyhd8ed1ab_0          47 KB  conda-forge\n","    nccl-2.11.4.1              |       h97a9cb7_0       174.2 MB  conda-forge\n","    networkx-2.6.3             |     pyhd8ed1ab_1         1.5 MB  conda-forge\n","    ninja-1.10.2               |       h4bd325d_0         2.4 MB  conda-forge\n","    packaging-21.3             |     pyhd8ed1ab_0          36 KB  conda-forge\n","    pluggy-1.0.0               |   py39hf3d152e_2          25 KB  conda-forge\n","    py-1.11.0                  |     pyh6c4a22f_0          74 KB  conda-forge\n","    pytest-6.2.5               |   py39hf3d152e_1         433 KB  conda-forge\n","    pytest-cov-3.0.0           |     pyhd8ed1ab_0          21 KB  conda-forge\n","    python-louvain-0.15        |     pyhd3deb0d_0          12 KB  conda-forge\n","    pytorch-1.9.0              |cuda111py39hc274426_1       871.6 MB  conda-forge\n","    pytorch-gpu-1.9.0          |cuda111py39h788eb59_1          12 KB  conda-forge\n","    pytorch_geometric-2.0.1    |     pyh6c4a22f_0         264 KB  conda-forge\n","    pytorch_scatter-2.0.7      |   py39ha2a3c8e_0         2.3 MB  conda-forge\n","    pytorch_sparse-0.6.10      |   py39ha2a3c8e_1         1.0 MB  conda-forge\n","    rdflib-6.0.2               |   py39hf3d152e_0         584 KB  conda-forge\n","    scikit-learn-0.24.2        |   py39h4dfa638_0         7.6 MB  conda-forge\n","    scipy-1.5.3                |   py39hee8e79c_0        19.3 MB  conda-forge\n","    sleef-3.5.1                |       h7f98852_1         1.5 MB  conda-forge\n","    sparqlwrapper-1.8.5        |py39hf3d152e_1006          40 KB  conda-forge\n","    threadpoolctl-3.0.0        |     pyh8a188c0_0          17 KB  conda-forge\n","    toml-0.10.2                |     pyhd8ed1ab_0          18 KB  conda-forge\n","    torch-scatter-2.0.9        |   py39hf400f99_0         6.8 MB  conda-forge\n","    typing_extensions-4.0.1    |     pyha770c72_0          26 KB  conda-forge\n","    webencodings-0.5.1         |             py_1          12 KB  conda-forge\n","    ------------------------------------------------------------\n","                                           Total:        3.18 GB\n","\n","The following NEW packages will be INSTALLED:\n","\n","  attrs              conda-forge/noarch::attrs-21.2.0-pyhd8ed1ab_0\n","  coverage           pkgs/main/linux-64::coverage-5.5-py39h27cfd23_2\n","  cudatoolkit        conda-forge/linux-64::cudatoolkit-11.1.1-h6406543_8\n","  cudnn              conda-forge/linux-64::cudnn-8.2.1.32-h86fa8c9_0\n","  future             conda-forge/linux-64::future-0.18.2-py39hf3d152e_4\n","  googledrivedownlo~ conda-forge/noarch::googledrivedownloader-0.4-pyhd3deb0d_1\n","  html5lib           conda-forge/noarch::html5lib-1.1-pyh9f0ad1d_0\n","  iniconfig          conda-forge/noarch::iniconfig-1.1.1-pyh9f0ad1d_0\n","  intel-openmp       pkgs/main/linux-64::intel-openmp-2021.4.0-h06a4308_3561\n","  isodate            conda-forge/noarch::isodate-0.6.1-pyhd8ed1ab_0\n","  jinja2             conda-forge/noarch::jinja2-3.0.3-pyhd8ed1ab_0\n","  joblib             conda-forge/noarch::joblib-1.1.0-pyhd8ed1ab_0\n","  keepalive          conda-forge/noarch::keepalive-0.5-pyhd8ed1ab_6\n","  libprotobuf        conda-forge/linux-64::libprotobuf-3.16.0-h780b84a_0\n","  magma              conda-forge/linux-64::magma-2.5.4-ha9b7cf9_2\n","  markupsafe         conda-forge/linux-64::markupsafe-2.0.1-py39h3811e60_0\n","  mkl                pkgs/main/linux-64::mkl-2021.4.0-h06a4308_640\n","  more-itertools     conda-forge/noarch::more-itertools-8.12.0-pyhd8ed1ab_0\n","  nccl               conda-forge/linux-64::nccl-2.11.4.1-h97a9cb7_0\n","  networkx           conda-forge/noarch::networkx-2.6.3-pyhd8ed1ab_1\n","  ninja              conda-forge/linux-64::ninja-1.10.2-h4bd325d_0\n","  packaging          conda-forge/noarch::packaging-21.3-pyhd8ed1ab_0\n","  pluggy             conda-forge/linux-64::pluggy-1.0.0-py39hf3d152e_2\n","  py                 conda-forge/noarch::py-1.11.0-pyh6c4a22f_0\n","  pytest             conda-forge/linux-64::pytest-6.2.5-py39hf3d152e_1\n","  pytest-cov         conda-forge/noarch::pytest-cov-3.0.0-pyhd8ed1ab_0\n","  python-louvain     conda-forge/noarch::python-louvain-0.15-pyhd3deb0d_0\n","  pytorch            conda-forge/linux-64::pytorch-1.9.0-cuda111py39hc274426_1\n","  pytorch-gpu        conda-forge/linux-64::pytorch-gpu-1.9.0-cuda111py39h788eb59_1\n","  pytorch_geometric  conda-forge/noarch::pytorch_geometric-2.0.1-pyh6c4a22f_0\n","  pytorch_scatter    conda-forge/linux-64::pytorch_scatter-2.0.7-py39ha2a3c8e_0\n","  pytorch_sparse     conda-forge/linux-64::pytorch_sparse-0.6.10-py39ha2a3c8e_1\n","  rdflib             conda-forge/linux-64::rdflib-6.0.2-py39hf3d152e_0\n","  scikit-learn       conda-forge/linux-64::scikit-learn-0.24.2-py39h4dfa638_0\n","  scipy              conda-forge/linux-64::scipy-1.5.3-py39hee8e79c_0\n","  sleef              conda-forge/linux-64::sleef-3.5.1-h7f98852_1\n","  sparqlwrapper      conda-forge/linux-64::sparqlwrapper-1.8.5-py39hf3d152e_1006\n","  threadpoolctl      conda-forge/noarch::threadpoolctl-3.0.0-pyh8a188c0_0\n","  toml               conda-forge/noarch::toml-0.10.2-pyhd8ed1ab_0\n","  torch-scatter      conda-forge/linux-64::torch-scatter-2.0.9-py39hf400f99_0\n","  typing_extensions  conda-forge/noarch::typing_extensions-4.0.1-pyha770c72_0\n","  webencodings       conda-forge/noarch::webencodings-0.5.1-py_1\n","\n","The following packages will be UPDATED:\n","\n","  libblas                         3.9.0-11_linux64_openblas --> 3.9.0-12_linux64_mkl\n","  libcblas                        3.9.0-11_linux64_openblas --> 3.9.0-12_linux64_mkl\n","  liblapack                       3.9.0-11_linux64_openblas --> 3.9.0-12_linux64_mkl\n","\n","\n","Proceed ([y]/n)? y\n","\n","\n","Downloading and Extracting Packages\n","cudnn-8.2.1.32       | 673.9 MB  | :  98% 0.9804910640601041/1 [00:04<00:00,  4.46s/it]\n","cudnn-8.2.1.32       | 673.9 MB  | : 100% 1.0/1 [01:23<00:00, 83.96s/it]               \n","attrs-21.2.0         | 44 KB     | : 100% 1.0/1 [00:00<00:00, 18.04it/s]\n","scipy-1.5.3          | 19.3 MB   | : 100% 1.0/1 [00:03<00:00,  3.11s/it]\n","python-louvain-0.15  | 12 KB     | : 100% 1.0/1 [00:00<00:00, 27.74it/s]\n","rdflib-6.0.2         | 584 KB    | : 100% 1.0/1 [00:00<00:00,  5.91it/s]\n","more-itertools-8.12. | 47 KB     | : 100% 1.0/1 [00:00<00:00, 23.28it/s]\n","pytest-6.2.5         | 433 KB    | : 100% 1.0/1 [00:00<00:00,  7.85it/s]\n","libcblas-3.9.0       | 12 KB     | : 100% 1.0/1 [00:00<00:00, 24.52it/s]\n","coverage-5.5         | 259 KB    | : 100% 1.0/1 [00:00<00:00,  6.38it/s]                \n","mkl-2021.4.0         | 142.6 MB  | : 100% 1.0/1 [00:04<00:00,  4.30s/it]               \n","webencodings-0.5.1   | 12 KB     | : 100% 1.0/1 [00:00<00:00, 19.51it/s]\n","networkx-2.6.3       | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  2.78it/s]\n","pytorch-1.9.0        | 871.6 MB  | : 100% 1.0/1 [01:50<00:00, 110.02s/it]              \n","isodate-0.6.1        | 28 KB     | : 100% 1.0/1 [00:00<00:00, 17.89it/s]\n","sparqlwrapper-1.8.5  | 40 KB     | : 100% 1.0/1 [00:00<00:00, 20.71it/s]\n","googledrivedownloade | 7 KB      | : 100% 1.0/1 [00:00<00:00, 17.00it/s]\n","nccl-2.11.4.1        | 174.2 MB  | : 100% 1.0/1 [00:20<00:00, 20.64s/it]               \n","packaging-21.3       | 36 KB     | : 100% 1.0/1 [00:00<00:00, 20.15it/s]\n","html5lib-1.1         | 89 KB     | : 100% 1.0/1 [00:00<00:00, 17.13it/s]\n","libblas-3.9.0        | 12 KB     | : 100% 1.0/1 [00:00<00:00, 21.71it/s]\n","jinja2-3.0.3         | 99 KB     | : 100% 1.0/1 [00:00<00:00, 17.49it/s]\n","pytorch_geometric-2. | 264 KB    | : 100% 1.0/1 [00:00<00:00,  8.43it/s]\n","pytorch_sparse-0.6.1 | 1.0 MB    | : 100% 1.0/1 [00:00<00:00,  4.78it/s]\n","liblapack-3.9.0      | 12 KB     | : 100% 1.0/1 [00:00<00:00, 22.30it/s]\n","ninja-1.10.2         | 2.4 MB    | : 100% 1.0/1 [00:00<00:00,  2.78it/s]\n","toml-0.10.2          | 18 KB     | : 100% 1.0/1 [00:00<00:00, 27.79it/s]\n","pluggy-1.0.0         | 25 KB     | : 100% 1.0/1 [00:00<00:00, 20.59it/s]\n","cudatoolkit-11.1.1   | 1.20 GB   | : 100% 1.0/1 [02:25<00:00, 145.27s/it]             \n","torch-scatter-2.0.9  | 6.8 MB    | : 100% 1.0/1 [00:02<00:00,  2.17s/it]               \n","libprotobuf-3.16.0   | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  2.25it/s]\n","threadpoolctl-3.0.0  | 17 KB     | : 100% 1.0/1 [00:00<00:00, 24.23it/s]\n","keepalive-0.5        | 22 KB     | : 100% 1.0/1 [00:00<00:00, 22.65it/s]\n","sleef-3.5.1          | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  3.15it/s]\n","future-0.18.2        | 715 KB    | : 100% 1.0/1 [00:00<00:00,  5.08it/s]\n","magma-2.5.4          | 104.7 MB  | :  61% 0.6062483465435038/1 [00:00<00:00,  1.19it/s] "]}],"source":["!conda install -y -c conda-forge rdkit\n","!conda install -y -c conda-forge pytorch_geometric torch-scatter pytorch_sparse \n","!conda install -y pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-W1nvQh4yYPm"},"outputs":[],"source":["!conda install -c conda-forge pytorch_sparse "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LF3cLgQGvkhp"},"outputs":[],"source":["!conda install -c conda-forge pytorch_scatter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93IiLSuGz70u"},"outputs":[],"source":["!conda install -c conda-forge pytorch_geometric"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mY0ElvSCyn3B"},"outputs":[],"source":["#pip install git+https://github.com/rusty1s/pytorch_geometric.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28982,"status":"ok","timestamp":1621632733346,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"CyBG7TUNz98M","outputId":"3068dbb5-797f-4a29-ee69-c8c5d9707c85"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'rdkit'...\n","remote: Enumerating objects: 73085, done.\u001b[K\n","remote: Counting objects: 100% (309/309), done.\u001b[K\n","remote: Compressing objects: 100% (216/216), done.\u001b[K\n","remote: Total 73085 (delta 130), reused 222 (delta 86), pack-reused 72776\u001b[K\n","Receiving objects: 100% (73085/73085), 185.70 MiB | 23.33 MiB/s, done.\n","Resolving deltas: 100% (55624/55624), done.\n","Checking out files: 100% (4027/4027), done.\n","/content/build/rdkit\n","/content/build/rdkit/build\n","-- The C compiler identification is GNU 7.5.0\n","-- The CXX compiler identification is GNU 7.5.0\n","-- Check for working C compiler: /usr/bin/cc\n","-- Check for working C compiler: /usr/bin/cc -- works\n","-- Detecting C compiler ABI info\n","-- Detecting C compiler ABI info - done\n","-- Detecting C compile features\n","-- Detecting C compile features - done\n","-- Check for working CXX compiler: /usr/bin/c++\n","-- Check for working CXX compiler: /usr/bin/c++ -- works\n","-- Detecting CXX compiler ABI info\n","-- Detecting CXX compiler ABI info - done\n","-- Detecting CXX compile features\n","-- Detecting CXX compile features - done\n","-- Check if the system is big endian\n","-- Searching 16 bit integer\n","-- Looking for sys/types.h\n","-- Looking for sys/types.h - found\n","-- Looking for stdint.h\n","-- Looking for stdint.h - found\n","-- Looking for stddef.h\n","-- Looking for stddef.h - found\n","-- Check size of unsigned short\n","-- Check size of unsigned short - done\n","-- Using unsigned short\n","-- Check if the system is big endian - little endian\n","-- Catch not found in /content/build/rdkit/External/catch/catch\n","Downloading https://github.com/catchorg/Catch2/archive/v2.12.4.tar.gz...\n","CATCH: /content/build/rdkit/External/catch/catch/single_include/catch2\n","-- Found PythonInterp: /usr/local/bin/python (found version \"3.8.5\") \n","-- Found PythonLibs: /usr/local/lib/libpython3.8.so (found version \"3.8.5\") \n","-- Boost 1.58.0 found.\n","-- Found Boost components:\n","   python3\n","PYTHON Py_ENABLE_SHARED: 0\n","PYTHON USING LINK LINE: -pthread -shared -B /usr/local/compiler_compat -L/usr/local/lib -Wl,-rpath=/usr/local/lib -Wl,--no-as-needed -Wl,--sysroot=/\n","nbval not found, disabling the jupyter tests\n","-- Could NOT find Eigen3 (missing: EIGEN3_INCLUDE_DIR EIGEN3_VERSION_OK) (Required is at least version \"2.91.0\")\n","Eigen3 not found, some Mol descriptors will not be built.\n","-- Looking for pthread.h\n","-- Looking for pthread.h - found\n","-- Looking for pthread_create\n","-- Looking for pthread_create - not found\n","-- Looking for pthread_create in pthreads\n","-- Looking for pthread_create in pthreads - not found\n","-- Looking for pthread_create in pthread\n","-- Looking for pthread_create in pthread - found\n","-- Found Threads: TRUE  \n","-- Boost 1.58.0 found.\n","-- Found Boost components:\n","   system;serialization;iostreams\n","== Using strict rotor definition\n","-- Boost 1.58.0 found.\n","-- Found Boost components:\n","   system;iostreams\n","-- maeparser include dir set as 'maeparser_INCLUDE_DIRS-NOTFOUND'\n","-- maeparser libraries set as 'maeparser_LIBRARIES-NOTFOUND'\n","-- Could NOT find maeparser (missing: maeparser_INCLUDE_DIRS maeparser_LIBRARIES) \n","Downloading https://github.com/schrodinger/maeparser/archive/v1.2.4.tar.gz...\n","-- coordgen include dir set as coordgen_INCLUDE_DIRS-NOTFOUND\n","-- coordgen libraries set as 'coordgen_LIBRARIES-NOTFOUND'\n","-- Could NOT find coordgen (missing: coordgen_INCLUDE_DIRS coordgen_LIBRARIES) \n","Downloading https://github.com/schrodinger/coordgenlibs/archive/v2.0.3.tar.gz...\n","Downloading https://github.com/rareylab/RingDecomposerLib/archive/v1.1.3_rdkit.tar.gz...\n","-- Boost 1.58.0 found.\n","-- Found Boost components:\n","   iostreams\n","-- Boost 1.58.0 found.\n","-- Found Boost components:\n","   system;iostreams\n","-- Found ZLIB: /usr/local/lib/libz.so (found version \"1.2.11\") \n","== Updating Filters.cpp from pains file\n","== Done updating pains files\n","Downloading https://fonts.google.com/download?family=Comic%20Neue...\n","-- Found Freetype: /usr/local/lib/libfreetype.so (found version \"2.10.4\") \n","-- Boost 1.58.0 found.\n","-- Found Boost components:\n","   program_options\n","Downloading https://github.com/Tencent/rapidjson/archive/v1.1.0.tar.gz...\n","-- Configuring done\n","-- Generating done\n","CMake Warning:\n","  Manually-specified variables were not used by the project:\n","\n","    BOOST_ROOT\n","\n","\n","-- Build files have been written to: /content/build/rdkit/build\n"]}],"source":["!git clone https://github.com/rdkit/rdkit.git\n","%cd rdkit\n","!mkdir build\n","%cd build\n","!cmake -DPy_ENABLE_SHARED=1 \\\n","  -DRDK_INSTALL_INTREE=ON \\\n","  -DRDK_INSTALL_STATIC_LIBS=OFF \\\n","  -DRDK_BUILD_CPP_TESTS=ON \\\n","  -DPYTHON_NUMPY_INCLUDE_PATH=\"$(python -c 'import numpy ; print(numpy.get_include())')\" \\\n","  -DBOOST_ROOT=\"$CONDA_PREFIX\" \\\n","  .."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xr6JwJAx1gZd","outputId":"2568037c-7c90-4173-d522-79962e040152"},"outputs":[{"name":"stdout","output_type":"stream","text":["make: *** No rule to make target '4,'.  Stop.\n","\u001b[35m\u001b[1mScanning dependencies of target catch\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target maeparser\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target coordgen_support\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target inchi_support\u001b[0m\n","[  0%] Built target catch\n","[  0%] Built target coordgen_support\n","\u001b[35m\u001b[1mScanning dependencies of target coordgen\u001b[0m\n","[  0%] Built target inchi_support\n","\u001b[35m\u001b[1mScanning dependencies of target RDGeneral\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target RingDecomposerLib\u001b[0m\n","[  0%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/coordgen.dir/coordgen/CoordgenFragmentBuilder.cpp.o\u001b[0m\n","[  0%] \u001b[32mBuilding CXX object Code/RDGeneral/CMakeFiles/RDGeneral.dir/Invariant.cpp.o\u001b[0m\n","[  0%] \u001b[32mBuilding C object External/RingFamilies/CMakeFiles/RingDecomposerLib.dir/RingDecomposerLib/src/RingDecomposerLib/RDLapsp.c.o\u001b[0m\n","[  0%] \u001b[32mBuilding C object External/RingFamilies/CMakeFiles/RingDecomposerLib.dir/RingDecomposerLib/src/RingDecomposerLib/RDLbitset.c.o\u001b[0m\n","[  0%] \u001b[32mBuilding C object External/RingFamilies/CMakeFiles/RingDecomposerLib.dir/RingDecomposerLib/src/RingDecomposerLib/RDLcycleFams.c.o\u001b[0m\n","[  0%] \u001b[32mBuilding C object External/RingFamilies/CMakeFiles/RingDecomposerLib.dir/RingDecomposerLib/src/RingDecomposerLib/RDLdimacs.c.o\u001b[0m\n","[  0%] \u001b[32mBuilding C object External/RingFamilies/CMakeFiles/RingDecomposerLib.dir/RingDecomposerLib/src/RingDecomposerLib/RDLgraph.c.o\u001b[0m\n","[  0%] \u001b[32mBuilding C object External/RingFamilies/CMakeFiles/RingDecomposerLib.dir/RingDecomposerLib/src/RingDecomposerLib/RDLhandler.c.o\u001b[0m\n","[  0%] \u001b[32mBuilding C object External/RingFamilies/CMakeFiles/RingDecomposerLib.dir/RingDecomposerLib/src/RingDecomposerLib/RDLinfo.c.o\u001b[0m\n","[  0%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/maeparser.dir/maeparser/Buffer.cpp.o\u001b[0m\n","[  1%] \u001b[32mBuilding C object External/RingFamilies/CMakeFiles/RingDecomposerLib.dir/RingDecomposerLib/src/RingDecomposerLib/RDLrelation.c.o\u001b[0m\n","[  1%] \u001b[32mBuilding C object External/RingFamilies/CMakeFiles/RingDecomposerLib.dir/RingDecomposerLib/src/RingDecomposerLib/RDLstack.c.o\u001b[0m\n","[  1%] \u001b[32mBuilding C object External/RingFamilies/CMakeFiles/RingDecomposerLib.dir/RingDecomposerLib/src/RingDecomposerLib/RDLtarjan.c.o\u001b[0m\n","[  1%] \u001b[32mBuilding C object External/RingFamilies/CMakeFiles/RingDecomposerLib.dir/RingDecomposerLib/src/RingDecomposerLib/RDLtesting.c.o\u001b[0m\n","[  1%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/maeparser.dir/maeparser/MaeBlock.cpp.o\u001b[0m\n","[  1%] \u001b[32mBuilding CXX object Code/RDGeneral/CMakeFiles/RDGeneral.dir/types.cpp.o\u001b[0m\n","[  1%] \u001b[32mBuilding C object External/RingFamilies/CMakeFiles/RingDecomposerLib.dir/RingDecomposerLib/src/RingDecomposerLib/RDLutility.c.o\u001b[0m\n","[  1%] \u001b[32mBuilding C object External/RingFamilies/CMakeFiles/RingDecomposerLib.dir/RingDecomposerLib/src/RingDecomposerLib/RingDecomposerLib.c.o\u001b[0m\n","[  1%] \u001b[32m\u001b[1mLinking C shared library ../../lib/libRDKitRingDecomposerLib.so\u001b[0m\n","[  1%] Built target RingDecomposerLib\n","[  1%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/maeparser.dir/maeparser/MaeParser.cpp.o\u001b[0m\n","[  1%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/coordgen.dir/coordgen/CoordgenFragmenter.cpp.o\u001b[0m\n","[  1%] \u001b[32mBuilding CXX object Code/RDGeneral/CMakeFiles/RDGeneral.dir/utils.cpp.o\u001b[0m\n","[  2%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/maeparser.dir/maeparser/Reader.cpp.o\u001b[0m\n","[  2%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/coordgen.dir/coordgen/CoordgenMacrocycleBuilder.cpp.o\u001b[0m\n","[  2%] \u001b[32mBuilding CXX object Code/RDGeneral/CMakeFiles/RDGeneral.dir/RDGeneralExceptions.cpp.o\u001b[0m\n","[  2%] \u001b[32mBuilding CXX object Code/RDGeneral/CMakeFiles/RDGeneral.dir/RDLog.cpp.o\u001b[0m\n","[  2%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/maeparser.dir/maeparser/Writer.cpp.o\u001b[0m\n","[  2%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/coordgen.dir/coordgen/CoordgenMinimizer.cpp.o\u001b[0m\n","[  2%] \u001b[32mBuilding CXX object Code/RDGeneral/CMakeFiles/RDGeneral.dir/LocaleSwitcher.cpp.o\u001b[0m\n","[  2%] \u001b[32mBuilding CXX object Code/RDGeneral/CMakeFiles/RDGeneral.dir/versions.cpp.o\u001b[0m\n","[  3%] \u001b[32m\u001b[1mLinking CXX shared library ../../lib/libRDKitRDGeneral.so\u001b[0m\n","[  3%] Built target RDGeneral\n","[  3%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/coordgen.dir/coordgen/CoordgenTemplates.cpp.o\u001b[0m\n","[  3%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/coordgen.dir/coordgen/sketcherMinimizer.cpp.o\u001b[0m\n","[  3%] \u001b[32m\u001b[1mLinking CXX shared library ../../lib/libRDKitmaeparser.so\u001b[0m\n","[  3%] Built target maeparser\n","[  3%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/coordgen.dir/coordgen/sketcherMinimizerAtom.cpp.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/coordgen.dir/coordgen/sketcherMinimizerBond.cpp.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/coordgen.dir/coordgen/sketcherMinimizerFragment.cpp.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/coordgen.dir/coordgen/sketcherMinimizerMarchingSquares.cpp.o\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target ringdecomposerlib_support\u001b[0m\n","[  4%] Built target ringdecomposerlib_support\n","\u001b[35m\u001b[1mScanning dependencies of target ga\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object External/GA/CMakeFiles/ga.dir/ga/StringChromosome.cpp.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/coordgen.dir/coordgen/sketcherMinimizerMolecule.cpp.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object External/GA/CMakeFiles/ga.dir/ga/Chromosome.cpp.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object External/GA/CMakeFiles/ga.dir/ga/IntegerStringChromosomePolicy.cpp.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object External/GA/CMakeFiles/ga.dir/ga/BinaryStringChromosomePolicy.cpp.o\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target testDict\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object Code/RDGeneral/CMakeFiles/testDict.dir/testDict.cpp.o\u001b[0m\n","[  4%] \u001b[32mBuilding CXX object External/GA/CMakeFiles/ga.dir/util/RandomUtil.cpp.o\u001b[0m\n","[  5%] \u001b[32mBuilding CXX object External/GA/CMakeFiles/ga.dir/util/Util.cpp.o\u001b[0m\n","[  5%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/coordgen.dir/coordgen/sketcherMinimizerResidue.cpp.o\u001b[0m\n","[  5%] \u001b[32m\u001b[1mLinking CXX shared library ../../lib/libRDKitga.so\u001b[0m\n","[  5%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/coordgen.dir/coordgen/sketcherMinimizerResidueInteraction.cpp.o\u001b[0m\n","[  5%] Built target ga\n","\u001b[35m\u001b[1mScanning dependencies of target testConcurrentQueue\u001b[0m\n","[  6%] \u001b[32mBuilding CXX object Code/RDGeneral/CMakeFiles/testConcurrentQueue.dir/testConcurrentQueue.cpp.o\u001b[0m\n","[  6%] \u001b[32mBuilding CXX object External/CoordGen/CMakeFiles/coordgen.dir/coordgen/sketcherMinimizerRing.cpp.o\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target testRDValue\u001b[0m\n","[  6%] \u001b[32mBuilding CXX object Code/RDGeneral/CMakeFiles/testRDValue.dir/testRDValue.cpp.o\u001b[0m\n","[  6%] \u001b[32m\u001b[1mLinking CXX shared library ../../lib/libRDKitcoordgen.so\u001b[0m\n","[  6%] Built target coordgen\n","\u001b[35m\u001b[1mScanning dependencies of target RDStreams\u001b[0m\n","[  6%] \u001b[32mBuilding CXX object Code/RDStreams/CMakeFiles/RDStreams.dir/streams.cpp.o\u001b[0m\n","[  6%] \u001b[32m\u001b[1mLinking CXX executable testConcurrentQueue\u001b[0m\n","[  6%] Built target testConcurrentQueue\n","\u001b[35m\u001b[1mScanning dependencies of target testMatrices\u001b[0m\n","[  6%] \u001b[32mBuilding CXX object Code/Numerics/CMakeFiles/testMatrices.dir/testMatrices.cpp.o\u001b[0m\n","[  7%] \u001b[32m\u001b[1mLinking CXX shared library ../../lib/libRDKitRDStreams.so\u001b[0m\n","[  7%] \u001b[32m\u001b[1mLinking CXX executable testDict\u001b[0m\n","[  7%] Built target RDStreams\n","\u001b[35m\u001b[1mScanning dependencies of target Catalogs\u001b[0m\n","[  7%] Built target testDict\n","[  7%] \u001b[32mBuilding CXX object Code/Catalogs/CMakeFiles/Catalogs.dir/Catalog.cpp.o\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target testQuery\u001b[0m\n","[  7%] \u001b[32mBuilding CXX object Code/Query/CMakeFiles/testQuery.dir/test.cpp.o\u001b[0m\n","[  7%] \u001b[32m\u001b[1mLinking CXX executable testRDValue\u001b[0m\n","[  7%] \u001b[32m\u001b[1mLinking CXX executable testMatrices\u001b[0m\n","[  7%] Built target testRDValue\n","\u001b[35m\u001b[1mScanning dependencies of target testMatCalc\u001b[0m\n","[  8%] \u001b[32mBuilding CXX object Code/DataManip/MetricMatrixCalc/CMakeFiles/testMatCalc.dir/testMatCalc.cpp.o\u001b[0m\n","[  8%] Built target testMatrices\n","[  8%] \u001b[32mBuilding CXX object Code/Catalogs/CMakeFiles/Catalogs.dir/CatalogParams.cpp.o\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target hc\u001b[0m\n","[  8%] \u001b[32mBuilding C object Code/ML/Cluster/Murtagh/CMakeFiles/hc.dir/hc.c.o\u001b[0m\n","[  8%] \u001b[32mBuilding C object Code/ML/Cluster/Murtagh/CMakeFiles/hc.dir/hcdriver.c.o\u001b[0m\n","[  8%] \u001b[32m\u001b[1mLinking C shared library ../../../../lib/libRDKithc.so\u001b[0m\n","[  8%] Built target hc\n","\u001b[35m\u001b[1mScanning dependencies of target DataStructs\u001b[0m\n","[  8%] \u001b[32mBuilding CXX object Code/DataStructs/CMakeFiles/DataStructs.dir/BitVect.cpp.o\u001b[0m\n","[  8%] \u001b[32mBuilding CXX object Code/Catalogs/CMakeFiles/Catalogs.dir/CatalogEntry.cpp.o\u001b[0m\n","[  8%] \u001b[32m\u001b[1mLinking CXX executable testMatCalc\u001b[0m\n","[  8%] Built target testMatCalc\n","[  8%] \u001b[32mBuilding CXX object Code/DataStructs/CMakeFiles/DataStructs.dir/SparseBitVect.cpp.o\u001b[0m\n","[  8%] \u001b[32m\u001b[1mLinking CXX shared library ../../lib/libRDKitCatalogs.so\u001b[0m\n","[  8%] Built target Catalogs\n","\u001b[35m\u001b[1mScanning dependencies of target EigenSolvers\u001b[0m\n","[  8%] \u001b[32mBuilding CXX object Code/Numerics/EigenSolvers/CMakeFiles/EigenSolvers.dir/PowerEigenSolver.cpp.o\u001b[0m\n","[  8%] \u001b[32mBuilding CXX object Code/DataStructs/CMakeFiles/DataStructs.dir/ExplicitBitVect.cpp.o\u001b[0m\n","[  9%] \u001b[32m\u001b[1mLinking CXX executable testQuery\u001b[0m\n","[  9%] Built target testQuery\n","[ 10%] \u001b[32mBuilding CXX object Code/DataStructs/CMakeFiles/DataStructs.dir/Utils.cpp.o\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object Code/DataStructs/CMakeFiles/DataStructs.dir/base64.cpp.o\u001b[0m\n","[ 10%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitEigenSolvers.so\u001b[0m\n","[ 10%] Built target EigenSolvers\n","[ 10%] \u001b[32mBuilding CXX object Code/DataStructs/CMakeFiles/DataStructs.dir/BitOps.cpp.o\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target RDBoost\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object Code/DataStructs/CMakeFiles/DataStructs.dir/DiscreteDistMat.cpp.o\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object Code/RDBoost/CMakeFiles/RDBoost.dir/Wrap.cpp.o\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object Code/DataStructs/CMakeFiles/DataStructs.dir/DiscreteValueVect.cpp.o\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object Code/DataStructs/CMakeFiles/DataStructs.dir/FPBReader.cpp.o\u001b[0m\n","[ 10%] \u001b[32mBuilding CXX object Code/DataStructs/CMakeFiles/DataStructs.dir/MultiFPBReader.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.cpp:15\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/object/iterator.hpp:28:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python/iterator.hpp:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:37\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.cpp:15\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/detail/iterator.hpp:13:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: This header is deprecated. Use <iterator> instead.\n"," BOOST_HEADER_DEPRECATED(\"<iterator>\"\u001b[01;36m\u001b[K)\u001b[m\u001b[K\n","                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[35m\u001b[1mScanning dependencies of target SimDivPickers\u001b[0m\n","[ 11%] \u001b[32mBuilding CXX object Code/SimDivPickers/CMakeFiles/SimDivPickers.dir/DistPicker.cpp.o\u001b[0m\n","[ 11%] \u001b[32mBuilding CXX object Code/SimDivPickers/CMakeFiles/SimDivPickers.dir/MaxMinPicker.cpp.o\u001b[0m\n","[ 12%] \u001b[32m\u001b[1mLinking CXX shared library ../../lib/libRDKitRDBoost.so\u001b[0m\n","[ 12%] Built target RDBoost\n","[ 12%] \u001b[32mBuilding CXX object Code/SimDivPickers/CMakeFiles/SimDivPickers.dir/HierarchicalClusterPicker.cpp.o\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target rdBase\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object Code/RDBoost/Wrap/CMakeFiles/rdBase.dir/RDBase.cpp.o\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target Clustering\u001b[0m\n","[ 13%] \u001b[32m\u001b[1mLinking CXX shared library ../../lib/libRDKitDataStructs.so\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object Code/ML/Cluster/Murtagh/CMakeFiles/Clustering.dir/Clustering.cpp.o\u001b[0m\n","[ 13%] Built target DataStructs\n","\u001b[35m\u001b[1mScanning dependencies of target RDGeometryLib\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object Code/Geometry/CMakeFiles/RDGeometryLib.dir/point.cpp.o\u001b[0m\n","[ 13%] \u001b[32m\u001b[1mLinking CXX shared library ../../lib/libRDKitSimDivPickers.so\u001b[0m\n","[ 13%] Built target SimDivPickers\n","[ 13%] \u001b[32mBuilding CXX object Code/Geometry/CMakeFiles/RDGeometryLib.dir/Transform2D.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap/RDBase.cpp:10\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 13%] \u001b[32mBuilding CXX object Code/Geometry/CMakeFiles/RDGeometryLib.dir/Transform3D.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/ML/Cluster/Murtagh/Clustering.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/object/iterator.hpp:28:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python/iterator.hpp:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:37\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/ML/Cluster/Murtagh/Clustering.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/detail/iterator.hpp:13:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: This header is deprecated. Use <iterator> instead.\n"," BOOST_HEADER_DEPRECATED(\"<iterator>\"\u001b[01;36m\u001b[K)\u001b[m\u001b[K\n","                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 13%] \u001b[32mBuilding CXX object Code/Geometry/CMakeFiles/RDGeometryLib.dir/UniformGrid3D.cpp.o\u001b[0m\n","[ 13%] \u001b[32m\u001b[1mLinking CXX shared module ../../../../rdkit/ML/Cluster/Clustering.so\u001b[0m\n","[ 13%] Built target Clustering\n","\u001b[35m\u001b[1mScanning dependencies of target testFPB\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object Code/DataStructs/CMakeFiles/testFPB.dir/testFPB.cpp.o\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object Code/Geometry/CMakeFiles/RDGeometryLib.dir/GridUtils.cpp.o\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target testMultiFPB\u001b[0m\n","[ 13%] \u001b[32mBuilding CXX object Code/DataStructs/CMakeFiles/testMultiFPB.dir/testMultiFPB.cpp.o\u001b[0m\n","[ 13%] \u001b[32m\u001b[1mLinking CXX shared library ../../lib/libRDKitRDGeometryLib.so\u001b[0m\n","[ 13%] Built target RDGeometryLib\n","\u001b[35m\u001b[1mScanning dependencies of target testDataStructs\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object Code/DataStructs/CMakeFiles/testDataStructs.dir/testDatastructs.cpp.o\u001b[0m\n","[ 14%] \u001b[32m\u001b[1mLinking CXX executable testFPB\u001b[0m\n","[ 14%] Built target testFPB\n","\u001b[35m\u001b[1mScanning dependencies of target cDataStructs\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object Code/DataStructs/Wrap/CMakeFiles/cDataStructs.dir/DataStructs.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/DataStructs/Wrap/DataStructs.cpp:13\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 14%] \u001b[32m\u001b[1mLinking CXX executable testMultiFPB\u001b[0m\n","[ 14%] Built target testMultiFPB\n","\u001b[35m\u001b[1mScanning dependencies of target testTransforms\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object Code/Geometry/CMakeFiles/testTransforms.dir/testTransforms.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object Code/DataStructs/Wrap/CMakeFiles/cDataStructs.dir/DiscreteValueVect.cpp.o\u001b[0m\n","[ 14%] \u001b[32m\u001b[1mLinking CXX executable testTransforms\u001b[0m\n","[ 14%] Built target testTransforms\n","\u001b[35m\u001b[1mScanning dependencies of target testGrid\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object Code/Geometry/CMakeFiles/testGrid.dir/testGrid.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/DataStructs/Wrap/DiscreteValueVect.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 14%] \u001b[32m\u001b[1mLinking CXX executable testDataStructs\u001b[0m\n","[ 14%] Built target testDataStructs\n","\u001b[35m\u001b[1mScanning dependencies of target geometryTestsCatch\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object Code/Geometry/CMakeFiles/geometryTestsCatch.dir/catch_tests.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object Code/DataStructs/Wrap/CMakeFiles/cDataStructs.dir/SparseIntVect.cpp.o\u001b[0m\n","[ 14%] \u001b[32m\u001b[1mLinking CXX executable testGrid\u001b[0m\n","[ 14%] Built target testGrid\n","\u001b[35m\u001b[1mScanning dependencies of target rdGeometry\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object Code/Geometry/Wrap/CMakeFiles/rdGeometry.dir/Point.cpp.o\u001b[0m\n","[ 14%] \u001b[32m\u001b[1mLinking CXX shared module ../../../rdkit/rdBase.so\u001b[0m\n","[ 14%] Built target rdBase\n","[ 14%] \u001b[32mBuilding CXX object Code/Geometry/Wrap/CMakeFiles/rdGeometry.dir/UniformGrid3D.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/DataStructs/Wrap/SparseIntVect.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/Geometry/Wrap/Point.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/Geometry/Wrap/UniformGrid3D.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 14%] \u001b[32mBuilding CXX object Code/Geometry/Wrap/CMakeFiles/rdGeometry.dir/rdGeometry.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object Code/DataStructs/Wrap/CMakeFiles/cDataStructs.dir/wrap_SparseBV.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/Geometry/Wrap/rdGeometry.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/object/iterator.hpp:28:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python/iterator.hpp:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:37\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/Geometry/Wrap/rdGeometry.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/detail/iterator.hpp:13:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: This header is deprecated. Use <iterator> instead.\n"," BOOST_HEADER_DEPRECATED(\"<iterator>\"\u001b[01;36m\u001b[K)\u001b[m\u001b[K\n","                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 14%] \u001b[32m\u001b[1mLinking CXX shared module ../../../rdkit/Geometry/rdGeometry.so\u001b[0m\n","[ 14%] Built target rdGeometry\n","\u001b[35m\u001b[1mScanning dependencies of target testConrec\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object Code/Numerics/CMakeFiles/testConrec.dir/testConrec.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/DataStructs/Wrap/wrap_SparseBV.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/object/iterator.hpp:28:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python/iterator.hpp:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:37\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/DataStructs/Wrap/wrap_SparseBV.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/detail/iterator.hpp:13:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: This header is deprecated. Use <iterator> instead.\n"," BOOST_HEADER_DEPRECATED(\"<iterator>\"\u001b[01;36m\u001b[K)\u001b[m\u001b[K\n","                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 14%] \u001b[32mBuilding CXX object Code/DataStructs/Wrap/CMakeFiles/cDataStructs.dir/wrap_ExplicitBV.cpp.o\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object Code/DataStructs/Wrap/CMakeFiles/cDataStructs.dir/wrap_BitOps.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/DataStructs/Wrap/wrap_ExplicitBV.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/object/iterator.hpp:28:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python/iterator.hpp:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:37\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/DataStructs/Wrap/wrap_ExplicitBV.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/detail/iterator.hpp:13:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: This header is deprecated. Use <iterator> instead.\n"," BOOST_HEADER_DEPRECATED(\"<iterator>\"\u001b[01;36m\u001b[K)\u001b[m\u001b[K\n","                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/DataStructs/Wrap/wrap_BitOps.cpp:10\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[35m\u001b[1mScanning dependencies of target rdMetricMatrixCalc\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object Code/DataManip/MetricMatrixCalc/Wrap/CMakeFiles/rdMetricMatrixCalc.dir/rdMetricMatrixCalc.cpp.o\u001b[0m\n","[ 14%] \u001b[32m\u001b[1mLinking CXX executable geometryTestsCatch\u001b[0m\n","[ 14%] Built target geometryTestsCatch\n","\u001b[35m\u001b[1mScanning dependencies of target testSimDivPickers\u001b[0m\n","[ 14%] \u001b[32mBuilding CXX object Code/SimDivPickers/CMakeFiles/testSimDivPickers.dir/testPickers.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/DataManip/MetricMatrixCalc/Wrap/rdMetricMatrixCalc.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 15%] \u001b[32m\u001b[1mLinking CXX executable testSimDivPickers\u001b[0m\n","[ 15%] Built target testSimDivPickers\n","\u001b[35m\u001b[1mScanning dependencies of target pickersTestsCatch\u001b[0m\n","[ 15%] \u001b[32mBuilding CXX object Code/SimDivPickers/CMakeFiles/pickersTestsCatch.dir/catch_tests.cpp.o\u001b[0m\n","[ 15%] \u001b[32m\u001b[1mLinking CXX shared module ../../../../rdkit/DataManip/Metric/rdMetricMatrixCalc.so\u001b[0m\n","[ 15%] Built target rdMetricMatrixCalc\n","\u001b[35m\u001b[1mScanning dependencies of target rdSimDivPickers\u001b[0m\n","[ 15%] \u001b[32mBuilding CXX object Code/SimDivPickers/Wrap/CMakeFiles/rdSimDivPickers.dir/MaxMinPicker.cpp.o\u001b[0m\n","[ 16%] \u001b[32mBuilding CXX object Code/DataStructs/Wrap/CMakeFiles/cDataStructs.dir/wrap_FPB.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/SimDivPickers/Wrap/MaxMinPicker.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/DataStructs/Wrap/wrap_FPB.cpp:10\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/object/iterator.hpp:28:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python/iterator.hpp:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:37\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/DataStructs/Wrap/wrap_FPB.cpp:10\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/detail/iterator.hpp:13:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: This header is deprecated. Use <iterator> instead.\n"," BOOST_HEADER_DEPRECATED(\"<iterator>\"\u001b[01;36m\u001b[K)\u001b[m\u001b[K\n","                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 17%] \u001b[32mBuilding CXX object Code/SimDivPickers/Wrap/CMakeFiles/rdSimDivPickers.dir/LeaderPicker.cpp.o\u001b[0m\n","[ 17%] \u001b[32mBuilding CXX object Code/DataStructs/Wrap/CMakeFiles/cDataStructs.dir/wrap_Utils.cpp.o\u001b[0m\n","[ 17%] \u001b[32m\u001b[1mLinking CXX executable testConrec\u001b[0m\n","[ 17%] Built target testConrec\n","\u001b[35m\u001b[1mScanning dependencies of target InfoTheory\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object Code/ML/InfoTheory/CMakeFiles/InfoTheory.dir/InfoBitRanker.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/SimDivPickers/Wrap/LeaderPicker.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/DataStructs/Wrap/wrap_Utils.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/object/iterator.hpp:28:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python/iterator.hpp:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:37\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/DataStructs/Wrap/wrap_Utils.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/detail/iterator.hpp:13:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: This header is deprecated. Use <iterator> instead.\n"," BOOST_HEADER_DEPRECATED(\"<iterator>\"\u001b[01;36m\u001b[K)\u001b[m\u001b[K\n","                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 18%] \u001b[32m\u001b[1mLinking CXX shared module ../../../rdkit/DataStructs/cDataStructs.so\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object Code/SimDivPickers/Wrap/CMakeFiles/rdSimDivPickers.dir/HierarchicalClusterPicker.cpp.o\u001b[0m\n","[ 18%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitInfoTheory.so\u001b[0m\n","[ 18%] Built target cDataStructs\n","[ 18%] \u001b[32mBuilding CXX object Code/SimDivPickers/Wrap/CMakeFiles/rdSimDivPickers.dir/rdSimDivPickers.cpp.o\u001b[0m\n","[ 18%] Built target InfoTheory\n","\u001b[35m\u001b[1mScanning dependencies of target ChemicalFeatures\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object Code/ChemicalFeatures/CMakeFiles/ChemicalFeatures.dir/FreeChemicalFeature.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/SimDivPickers/Wrap/HierarchicalClusterPicker.cpp:13\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 18%] \u001b[32m\u001b[1mLinking CXX shared library ../../lib/libRDKitChemicalFeatures.so\u001b[0m\n","[ 18%] Built target ChemicalFeatures\n","\u001b[35m\u001b[1mScanning dependencies of target GraphMol\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/Atom.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/SimDivPickers/Wrap/rdSimDivPickers.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/object/iterator.hpp:28:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python/iterator.hpp:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:37\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/SimDivPickers/Wrap/rdSimDivPickers.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/detail/iterator.hpp:13:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: This header is deprecated. Use <iterator> instead.\n"," BOOST_HEADER_DEPRECATED(\"<iterator>\"\u001b[01;36m\u001b[K)\u001b[m\u001b[K\n","                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 18%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/QueryAtom.cpp.o\u001b[0m\n","[ 18%] \u001b[32m\u001b[1mLinking CXX shared module ../../../rdkit/SimDivFilters/rdSimDivPickers.so\u001b[0m\n","[ 18%] Built target rdSimDivPickers\n","\u001b[35m\u001b[1mScanning dependencies of target Alignment\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object Code/Numerics/Alignment/CMakeFiles/Alignment.dir/AlignPoints.cpp.o\u001b[0m\n","[ 18%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitAlignment.so\u001b[0m\n","[ 18%] Built target Alignment\n","\u001b[35m\u001b[1mScanning dependencies of target rdInfoTheory\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object Code/ML/InfoTheory/Wrap/CMakeFiles/rdInfoTheory.dir/InfoBitRanker.cpp.o\u001b[0m\n","[ 18%] \u001b[32m\u001b[1mLinking CXX executable pickersTestsCatch\u001b[0m\n","[ 18%] Built target pickersTestsCatch\n","\u001b[35m\u001b[1mScanning dependencies of target cQuantize\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object Code/ML/Data/CMakeFiles/cQuantize.dir/cQuantize.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/QueryBond.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/Bond.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/ML/InfoTheory/Wrap/InfoBitRanker.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/ML/Data/cQuantize.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/object/iterator.hpp:28:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python/iterator.hpp:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:37\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/ML/Data/cQuantize.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/detail/iterator.hpp:13:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: This header is deprecated. Use <iterator> instead.\n"," BOOST_HEADER_DEPRECATED(\"<iterator>\"\u001b[01;36m\u001b[K)\u001b[m\u001b[K\n","                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 18%] \u001b[32m\u001b[1mLinking CXX shared module ../../../rdkit/ML/Data/cQuantize.so\u001b[0m\n","[ 18%] Built target cQuantize\n","\u001b[35m\u001b[1mScanning dependencies of target testChemicalFeatures\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object Code/ChemicalFeatures/CMakeFiles/testChemicalFeatures.dir/testChemicalFeatures.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object Code/ML/InfoTheory/Wrap/CMakeFiles/rdInfoTheory.dir/BitCorrMatGenerator.cpp.o\u001b[0m\n","[ 18%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/MolOps.cpp.o\u001b[0m\n","[ 19%] \u001b[32mBuilding CXX object Code/ML/InfoTheory/Wrap/CMakeFiles/rdInfoTheory.dir/rdInfoTheory.cpp.o\u001b[0m\n","[ 19%] \u001b[32m\u001b[1mLinking CXX executable testChemicalFeatures\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/ML/InfoTheory/Wrap/BitCorrMatGenerator.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 19%] Built target testChemicalFeatures\n","\u001b[35m\u001b[1mScanning dependencies of target testAlignment\u001b[0m\n","[ 19%] \u001b[32mBuilding CXX object Code/Numerics/Alignment/CMakeFiles/testAlignment.dir/testAlignment.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/ML/InfoTheory/Wrap/rdInfoTheory.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/object/iterator.hpp:28:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python/iterator.hpp:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:37\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/ML/InfoTheory/Wrap/rdInfoTheory.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/detail/iterator.hpp:13:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: This header is deprecated. Use <iterator> instead.\n"," BOOST_HEADER_DEPRECATED(\"<iterator>\"\u001b[01;36m\u001b[K)\u001b[m\u001b[K\n","                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[35m\u001b[1mScanning dependencies of target rdAlignment\u001b[0m\n","[ 19%] \u001b[32mBuilding CXX object Code/Numerics/Alignment/Wrap/CMakeFiles/rdAlignment.dir/rdAlignment.cpp.o\u001b[0m\n","[ 19%] \u001b[32m\u001b[1mLinking CXX shared module ../../../../rdkit/ML/InfoTheory/rdInfoTheory.so\u001b[0m\n","[ 19%] Built target rdInfoTheory\n","[ 19%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/FindRings.cpp.o\u001b[0m\n","[ 19%] \u001b[32m\u001b[1mLinking CXX executable testAlignment\u001b[0m\n","[ 19%] Built target testAlignment\n","[ 19%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/ROMol.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/Numerics/Alignment/Wrap/rdAlignment.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 20%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/RWMol.cpp.o\u001b[0m\n","[ 20%] \u001b[32m\u001b[1mLinking CXX shared module ../../../../rdkit/Numerics/rdAlignment.so\u001b[0m\n","[ 20%] Built target rdAlignment\n","[ 20%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/PeriodicTable.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/atomic_data.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/QueryOps.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/MolPickler.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/Canon.cpp.o\u001b[0m\n","[ 20%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/AtomIterators.cpp.o\u001b[0m\n","/content/build/rdkit/Code/GraphMol/MolPickler.cpp: In instantiation of ‘\u001b[01m\u001b[Kstatic void RDKit::MolPickler::_addRingInfoFromPickle(std::istream&, RDKit::ROMol*, int, bool) [with T = int; std::istream = std::basic_istream<char>]\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/MolPickler.cpp:1111:30:\u001b[m\u001b[K   required from ‘\u001b[01m\u001b[Kstatic void RDKit::MolPickler::_depickle(std::istream&, RDKit::ROMol*, int, int, unsigned int) [with T = int; std::istream = std::basic_istream<char>]\u001b[m\u001b[K’\n","\u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/MolPickler.cpp:848:74:\u001b[m\u001b[K   required from here\n","\u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/MolPickler.cpp:1932:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n","           if (atoms[j] < 0 || atoms[j] >= mol->getNumAtoms()) {\n","\u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/MolPickler.cpp:1944:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n","             if (bonds[j] < 0 || bonds[j] >= mol->getNumBonds()) {\n","/content/build/rdkit/Code/GraphMol/MolPickler.cpp: In instantiation of ‘\u001b[01m\u001b[Kstatic void RDKit::MolPickler::_addRingInfoFromPickle(std::istream&, RDKit::ROMol*, int, bool) [with T = unsigned char; std::istream = std::basic_istream<char>]\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/MolPickler.cpp:1111:30:\u001b[m\u001b[K   required from ‘\u001b[01m\u001b[Kstatic void RDKit::MolPickler::_depickle(std::istream&, RDKit::ROMol*, int, int, unsigned int) [with T = unsigned char; std::istream = std::basic_istream<char>]\u001b[m\u001b[K’\n","\u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/MolPickler.cpp:851:47:\u001b[m\u001b[K   required from here\n","\u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/MolPickler.cpp:1932:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n","           if (atoms[j] < 0 || atoms[j] >= mol->getNumAtoms()) {\n","\u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/MolPickler.cpp:1944:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n","             if (bonds[j] < 0 || bonds[j] >= mol->getNumBonds()) {\n","[ 20%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/BondIterators.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/Aromaticity.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/Kekulize.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/MolDiscriminators.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/ConjugHybrid.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/AddHs.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/Matrices.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/Chirality.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/RingInfo.cpp.o\u001b[0m\n","[ 21%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/Conformer.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/Renumber.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/AdjustQuery.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/Resonance.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/StereoGroup.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/new_canon.cpp.o\u001b[0m\n","[ 22%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/SubstanceGroup.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/property_tree/json_parser/detail/parser.hpp:7:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/property_tree/json_parser/detail/read.hpp:13\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/property_tree/json_parser.hpp:16\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/AdjustQuery.cpp:20\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 22%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/GraphMol.dir/FindStereo.cpp.o\u001b[0m\n","[ 22%] \u001b[32m\u001b[1mLinking CXX shared library ../../lib/libRDKitGraphMol.so\u001b[0m\n","[ 22%] Built target GraphMol\n","\u001b[35m\u001b[1mScanning dependencies of target MolTransforms\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target Trajectory\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target SubstructMatch\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target SmilesParse\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object Code/GraphMol/Trajectory/CMakeFiles/Trajectory.dir/Trajectory.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object Code/GraphMol/MolTransforms/CMakeFiles/MolTransforms.dir/MolTransforms.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object Code/GraphMol/Substruct/CMakeFiles/SubstructMatch.dir/SubstructMatch.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object Code/GraphMol/SmilesParse/CMakeFiles/SmilesParse.dir/SmilesParse.cpp.o\u001b[0m\n","[ 23%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitTrajectory.so\u001b[0m\n","[ 23%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitMolTransforms.so\u001b[0m\n","[ 23%] Built target MolTransforms\n","\u001b[35m\u001b[1mScanning dependencies of target Subgraphs\u001b[0m\n","[ 23%] Built target Trajectory\n","\u001b[35m\u001b[1mScanning dependencies of target PartialCharges\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object Code/GraphMol/Subgraphs/CMakeFiles/Subgraphs.dir/Subgraphs.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object Code/GraphMol/PartialCharges/CMakeFiles/PartialCharges.dir/GasteigerCharges.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object Code/GraphMol/SmilesParse/CMakeFiles/SmilesParse.dir/SmilesParseOps.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object Code/GraphMol/Substruct/CMakeFiles/SubstructMatch.dir/SubstructUtils.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object Code/GraphMol/PartialCharges/CMakeFiles/PartialCharges.dir/GasteigerParams.cpp.o\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object Code/GraphMol/Subgraphs/CMakeFiles/Subgraphs.dir/SubgraphUtils.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/property_tree/json_parser/detail/parser.hpp:7:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/property_tree/json_parser/detail/read.hpp:13\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/property_tree/json_parser.hpp:16\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/Substruct/SubstructUtils.cpp:19\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 23%] \u001b[32mBuilding CXX object Code/GraphMol/SmilesParse/CMakeFiles/SmilesParse.dir/SmilesWrite.cpp.o\u001b[0m\n","[ 23%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitPartialCharges.so\u001b[0m\n","[ 23%] Built target PartialCharges\n","\u001b[35m\u001b[1mScanning dependencies of target rdMolTransforms\u001b[0m\n","[ 23%] \u001b[32mBuilding CXX object Code/GraphMol/MolTransforms/Wrap/CMakeFiles/rdMolTransforms.dir/rdMolTransforms.cpp.o\u001b[0m\n","[ 23%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitSubstructMatch.so\u001b[0m\n","[ 23%] Built target SubstructMatch\n","[ 23%] \u001b[32mBuilding CXX object Code/GraphMol/SmilesParse/CMakeFiles/SmilesParse.dir/SmartsWrite.cpp.o\u001b[0m\n","[ 24%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitSubgraphs.so\u001b[0m\n","[ 24%] Built target Subgraphs\n","\u001b[35m\u001b[1mScanning dependencies of target ShapeHelpers\u001b[0m\n","[ 24%] \u001b[32mBuilding CXX object Code/GraphMol/ShapeHelpers/CMakeFiles/ShapeHelpers.dir/ShapeEncoder.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/MolTransforms/Wrap/rdMolTransforms.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 24%] \u001b[32mBuilding CXX object Code/GraphMol/ShapeHelpers/CMakeFiles/ShapeHelpers.dir/ShapeUtils.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object Code/GraphMol/SmilesParse/CMakeFiles/SmilesParse.dir/CXSmilesOps.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object Code/GraphMol/SmilesParse/CMakeFiles/SmilesParse.dir/smarts.tab.cpp.o\u001b[0m\n","[ 25%] \u001b[32m\u001b[1mLinking CXX shared module ../../../../rdkit/Chem/rdMolTransforms.so\u001b[0m\n","[ 25%] Built target rdMolTransforms\n","\u001b[35m\u001b[1mScanning dependencies of target MolCatalog\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object Code/GraphMol/MolCatalog/CMakeFiles/MolCatalog.dir/MolCatalogEntry.cpp.o\u001b[0m\n","[ 25%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitShapeHelpers.so\u001b[0m\n","[ 25%] Built target ShapeHelpers\n","\u001b[35m\u001b[1mScanning dependencies of target CIPLabeler\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/CIPMol.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object Code/GraphMol/MolCatalog/CMakeFiles/MolCatalog.dir/MolCatalogParams.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object Code/GraphMol/SmilesParse/CMakeFiles/SmilesParse.dir/smiles.tab.cpp.o\u001b[0m\n","[ 25%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/CIPLabeler.cpp.o\u001b[0m\n","[ 26%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitMolCatalog.so\u001b[0m\n","[ 26%] Built target MolCatalog\n","\u001b[35m\u001b[1mScanning dependencies of target MolInterchange\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object Code/GraphMol/MolInterchange/CMakeFiles/MolInterchange.dir/Parser.cpp.o\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object Code/GraphMol/SmilesParse/CMakeFiles/SmilesParse.dir/lex.yysmarts.cpp.o\u001b[0m\n","\u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/MolInterchange/Parser.cpp:38:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunknown option after ‘\u001b[01m\u001b[K#pragma GCC diagnostic\u001b[m\u001b[K’ kind [\u001b[01;35m\u001b[K-Wpragmas\u001b[m\u001b[K]\n"," #pragma GCC diagnostic ignored \u001b[01;35m\u001b[K\"-Wclass-memaccess\"\u001b[m\u001b[K\n","                                \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","[ 27%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/Mancude.cpp.o\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object Code/GraphMol/SmilesParse/CMakeFiles/SmilesParse.dir/lex.yysmiles.cpp.o\u001b[0m\n","[ 27%] \u001b[32mBuilding CXX object Code/GraphMol/MolInterchange/CMakeFiles/MolInterchange.dir/Writer.cpp.o\u001b[0m\n","[ 28%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/Digraph.cpp.o\u001b[0m\n","[ 28%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitSmilesParse.so\u001b[0m\n","[ 28%] Built target SmilesParse\n","\u001b[35m\u001b[1mScanning dependencies of target SLNParse\u001b[0m\n","[ 28%] \u001b[32mBuilding CXX object Code/GraphMol/SLNParse/CMakeFiles/SLNParse.dir/SLNParse.cpp.o\u001b[0m\n","[ 29%] \u001b[32mBuilding CXX object Code/GraphMol/SLNParse/CMakeFiles/SLNParse.dir/SLNAttribs.cpp.o\u001b[0m\n","[ 29%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/Node.cpp.o\u001b[0m\n","[ 29%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitMolInterchange.so\u001b[0m\n","[ 29%] Built target MolInterchange\n","\u001b[35m\u001b[1mScanning dependencies of target rdqueries\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object Code/GraphMol/Wrap/CMakeFiles/rdqueries.dir/rdqueries.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/Edge.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object Code/GraphMol/Wrap/CMakeFiles/rdqueries.dir/Queries.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/Sort.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/configs/Configuration.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/Wrap/rdqueries.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 30%] \u001b[32mBuilding CXX object Code/GraphMol/SLNParse/CMakeFiles/SLNParse.dir/sln.tab.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/Wrap/Queries.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[35m\u001b[1mScanning dependencies of target rdtrajectory\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object Code/GraphMol/Wrap/CMakeFiles/rdtrajectory.dir/Trajectory.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/configs/Sp2Bond.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/Wrap/Trajectory.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 30%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/configs/Tetrahedral.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object Code/GraphMol/SLNParse/CMakeFiles/SLNParse.dir/lex.yysln.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object Code/GraphMol/Wrap/CMakeFiles/rdtrajectory.dir/rdTrajectory.cpp.o\u001b[0m\n","[ 30%] \u001b[32m\u001b[1mLinking CXX shared module ../../../rdkit/Chem/rdqueries.so\u001b[0m\n","[ 30%] Built target rdqueries\n","\u001b[35m\u001b[1mScanning dependencies of target Abbreviations\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object Code/GraphMol/Abbreviations/CMakeFiles/Abbreviations.dir/Abbreviations.cpp.o\u001b[0m\n","[ 30%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/rules/Rule1a.cpp.o\u001b[0m\n","[ 30%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitSLNParse.so\u001b[0m\n","[ 31%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/rules/Rule1b.cpp.o\u001b[0m\n","[ 31%] Built target SLNParse\n","[ 31%] \u001b[32mBuilding CXX object Code/GraphMol/Abbreviations/CMakeFiles/Abbreviations.dir/AbbreviationsUtils.cpp.o\u001b[0m\n","[ 31%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/rules/Rule2.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/Wrap/rdTrajectory.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/object/iterator.hpp:28:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python/iterator.hpp:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:37\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/GraphMol/Wrap/rdTrajectory.cpp:11\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/detail/iterator.hpp:13:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: This header is deprecated. Use <iterator> instead.\n"," BOOST_HEADER_DEPRECATED(\"<iterator>\"\u001b[01;36m\u001b[K)\u001b[m\u001b[K\n","                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 31%] \u001b[32m\u001b[1mLinking CXX shared module ../../../rdkit/Chem/rdtrajectory.so\u001b[0m\n","[ 31%] Built target rdtrajectory\n","\u001b[35m\u001b[1mScanning dependencies of target rdChemicalFeatures\u001b[0m\n","[ 31%] \u001b[32mBuilding CXX object Code/ChemicalFeatures/Wrap/CMakeFiles/rdChemicalFeatures.dir/rdChemicalFeatures.cpp.o\u001b[0m\n","[ 31%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/rules/Rule3.cpp.o\u001b[0m\n","[ 32%] \u001b[32mBuilding CXX object Code/ChemicalFeatures/Wrap/CMakeFiles/rdChemicalFeatures.dir/FreeChemicalFeature.cpp.o\u001b[0m\n","[ 32%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/rules/Rule4a.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/ChemicalFeatures/Wrap/rdChemicalFeatures.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/object/iterator.hpp:28:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python/iterator.hpp:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:37\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/Wrap.h:21\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/ChemicalFeatures/Wrap/rdChemicalFeatures.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/detail/iterator.hpp:13:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: This header is deprecated. Use <iterator> instead.\n"," BOOST_HEADER_DEPRECATED(\"<iterator>\"\u001b[01;36m\u001b[K)\u001b[m\u001b[K\n","                                     \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 32%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitAbbreviations.so\u001b[0m\n","[ 32%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/rules/Rule4b.cpp.o\u001b[0m\n","[ 32%] Built target Abbreviations\n","\u001b[35m\u001b[1mScanning dependencies of target MolAlign\u001b[0m\n","[ 32%] \u001b[32mBuilding CXX object Code/GraphMol/MolAlign/CMakeFiles/MolAlign.dir/AlignMolecules.cpp.o\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target ChemTransforms\u001b[0m\n","[ 32%] \u001b[32mBuilding CXX object Code/GraphMol/ChemTransforms/CMakeFiles/ChemTransforms.dir/ChemTransforms.cpp.o\u001b[0m\n","In file included from \u001b[01m\u001b[K/usr/local/include/boost/python/exception_translator.hpp:10:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/include/boost/python.hpp:28\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/RDBoost/python.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/build/rdkit/Code/ChemicalFeatures/Wrap/FreeChemicalFeature.cpp:12\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/include/boost/bind.hpp:41:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K#pragma message: The practice of declaring the Bind placeholders (_1, _2, ...) in the global namespace is deprecated. Please use <boost/bind/bind.hpp> + using namespace boost::placeholders, or define BOOST_BIND_GLOBAL_PLACEHOLDERS to retain the current behavior.\n"," \u001b[01;36m\u001b[K)\u001b[m\u001b[K\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","[ 32%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/rules/Rule4c.cpp.o\u001b[0m\n","[ 32%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/rules/Rule5.cpp.o\u001b[0m\n","[ 32%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/rules/Rule5New.cpp.o\u001b[0m\n","[ 33%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/rules/Rule6.cpp.o\u001b[0m\n","[ 33%] \u001b[32m\u001b[1mLinking CXX shared module ../../../rdkit/Chem/rdChemicalFeatures.so\u001b[0m\n","[ 33%] Built target rdChemicalFeatures\n","[ 33%] \u001b[32mBuilding CXX object Code/GraphMol/CIPLabeler/CMakeFiles/CIPLabeler.dir/rules/SequenceRule.cpp.o\u001b[0m\n","[ 33%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitMolAlign.so\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target Optimizer\u001b[0m\n","[ 33%] \u001b[32mBuilding CXX object Code/Numerics/Optimizer/CMakeFiles/Optimizer.dir/BFGSOpt.cpp.o\u001b[0m\n","[ 33%] Built target MolAlign\n","[ 34%] \u001b[32mBuilding CXX object Code/GraphMol/ChemTransforms/CMakeFiles/ChemTransforms.dir/MolFragmenter.cpp.o\u001b[0m\n","[ 34%] \u001b[32mBuilding CXX object Code/Numerics/Optimizer/CMakeFiles/Optimizer.dir/LinearSearch.cpp.o\u001b[0m\n","\u001b[35m\u001b[1mScanning dependencies of target graphmolIterTest\u001b[0m\n","[ 34%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/graphmolIterTest.dir/itertest.cpp.o\u001b[0m\n","[ 34%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitCIPLabeler.so\u001b[0m\n","[ 34%] Built target CIPLabeler\n","\u001b[35m\u001b[1mScanning dependencies of target graphmolcpTest\u001b[0m\n","[ 34%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/graphmolcpTest.dir/cptest.cpp.o\u001b[0m\n","[ 34%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitOptimizer.so\u001b[0m\n","[ 34%] Built target Optimizer\n","\u001b[35m\u001b[1mScanning dependencies of target test-valgrind\u001b[0m\n","[ 34%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/test-valgrind.dir/test-valgrind.cpp.o\u001b[0m\n","[ 34%] \u001b[32m\u001b[1mLinking CXX executable test-valgrind\u001b[0m\n","[ 34%] \u001b[32m\u001b[1mLinking CXX executable graphmolIterTest\u001b[0m\n","[ 34%] Built target test-valgrind\n","\u001b[35m\u001b[1mScanning dependencies of target graphmolqueryTest\u001b[0m\n","[ 35%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/graphmolqueryTest.dir/querytest.cpp.o\u001b[0m\n","[ 35%] Built target graphmolIterTest\n","\u001b[35m\u001b[1mScanning dependencies of target graphmolMemTest1\u001b[0m\n","[ 35%] \u001b[32mBuilding CXX object Code/GraphMol/CMakeFiles/graphmolMemTest1.dir/memtest1.cpp.o\u001b[0m\n","[ 35%] \u001b[32m\u001b[1mLinking CXX executable graphmolcpTest\u001b[0m\n","[ 35%] Built target graphmolcpTest\n","\u001b[35m\u001b[1mScanning dependencies of target smaTest1\u001b[0m\n","[ 35%] \u001b[32mBuilding CXX object Code/GraphMol/SmilesParse/CMakeFiles/smaTest1.dir/smatest.cpp.o\u001b[0m\n","[ 35%] \u001b[32m\u001b[1mLinking CXX shared library ../../../lib/libRDKitChemTransforms.so\u001b[0m\n","[ 35%] Built target ChemTransforms\n","\u001b[35m\u001b[1mScanning dependencies of target smiTest2\u001b[0m\n","[ 36%] \u001b[32mBuilding CXX object Code/GraphMol/SmilesParse/CMakeFiles/smiTest2.dir/test2.cpp.o\u001b[0m\n","[ 36%] \u001b[32m\u001b[1mLinking CXX executable graphmolMemTest1\u001b[0m\n","[ 36%] Built target graphmolMemTest1\n","\u001b[35m\u001b[1mScanning dependencies of target Fingerprints\u001b[0m\n","[ 36%] \u001b[32mBuilding CXX object Code/GraphMol/Fingerprints/CMakeFiles/Fingerprints.dir/Fingerprints.cpp.o\u001b[0m\n","[ 36%] \u001b[32m\u001b[1mLinking CXX executable smiTest2\u001b[0m\n","[ 36%] Built target smiTest2\n","[ 36%] \u001b[32mBuilding CXX object Code/GraphMol/Fingerprints/CMakeFiles/Fingerprints.dir/PatternFingerprints.cpp.o\u001b[0m\n","[ 36%] \u001b[32m\u001b[1mLinking CXX executable graphmolqueryTest\u001b[0m\n","[ 36%] Built target graphmolqueryTest\n","\u001b[35m\u001b[1mScanning dependencies of target FilterCatalog\u001b[0m\n","[ 36%] \u001b[32mBuilding CXX object Code/GraphMol/FilterCatalog/CMakeFiles/FilterCatalog.dir/Filters.cpp.o\u001b[0m\n","[ 36%] \u001b[32mBuilding CXX object Code/GraphMol/Fingerprints/CMakeFiles/Fingerprints.dir/MorganFingerprints.cpp.o\u001b[0m\n"]}],"source":["!make -j 4, \n","!make install -j 4\n","!ctest -j 4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgGlMZcNPisL"},"outputs":[],"source":["# Install required packages.\n","\n","%matplotlib inline\n","import torch\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","\n","def visualize(h, color, epoch=None, loss=None):\n","    plt.figure(figsize=(7,7))\n","    plt.xticks([])\n","    plt.yticks([])\n","\n","    if torch.is_tensor(h):\n","        h = h.detach().cpu().numpy()\n","        plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n","        if epoch is not None and loss is not None:\n","            plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n","    else:\n","        nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n","                         node_color=color, cmap=\"Set2\")\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"zTZgGgRKCzjV"},"source":["# TOX21"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":376},"executionInfo":{"elapsed":490,"status":"error","timestamp":1640281055208,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"grVl0VjlsgX-","outputId":"45e82edf-1a5e-46d8-d140-00dcade1220c"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-16741f0f1a0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTUDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTUDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Tox21_p53_training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","\n","path = '.'\n","train_dataset = TUDataset(path, name='Tox21_p53_training').shuffle()\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","test_dataset = TUDataset(path, name='Tox21_p53_testing').shuffle()\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","eval_dataset = TUDataset(path, name='Tox21_p53_evaluation').shuffle()\n","print(f'Test Dataset: {eval_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(eval_dataset)}')\n","print(f'Number of features: {eval_dataset.num_features}')\n","print(f'Number of classes: {eval_dataset.num_classes}')\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)\n","eval_loader = DataLoader(eval_dataset, batch_size=64)\n","\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=-1)\n","        \n","def train(epoch):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    loss_all = 0\n","    for data in train_loader:\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output = model(data.x, data.edge_index, data.batch)\n","        loss = F.nll_loss(output, data.y)\n","        loss.backward()\n","        loss_all += loss.item() * data.num_graphs\n","        optimizer.step()\n","    return loss_all / len(train_dataset)\n","\n","\n","def test(loader):\n","    model.eval()\n","\n","    correct = 0\n","    for data in loader:\n","        data = data.to(device)\n","        output = model(data.x, data.edge_index, data.batch)\n","        pred = output.max(dim=1)[1]\n","        correct += pred.eq(data.y).sum().item()\n","    return correct / len(loader.dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(1, 500):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":410,"status":"ok","timestamp":1621638836658,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"PnQjo2mYsgvV","outputId":"86e83aba-59cd-4d29-9788-55daf80420ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Dataset: BBPB(1836):\n","======================\n","Number of graphs: 1836\n","Number of features: 9\n","Number of classes: 1\n","Test Dataset: BBPB(203):\n","======================\n","Number of graphs: 203\n","Number of features: 9\n","Number of classes: 1\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import MoleculeNet\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = MoleculeNet(path, name=\"bbbp\").shuffle()\n","test_dataset = dataset[:len(dataset) // 10]\n","train_dataset = dataset[len(dataset) // 10:]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)"]},{"cell_type":"markdown","metadata":{"id":"fh57LEUY2Pr-"},"source":["## PCBE\n","Binding affinities"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37083,"status":"ok","timestamp":1621936178464,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"1941ORRG2O9y","outputId":"796e7cb1-3c52-4280-a58f-0bb71e5a4166"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Dataset: PCBA(394137):\n","======================\n","Number of graphs: 394137\n","Number of features: 9\n","Number of classes: 128\n","Test Dataset: PCBA(43792):\n","======================\n","Number of graphs: 43792\n","Number of features: 9\n","Number of classes: 128\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 1. ... 0. 0. 0.]]\n","False\n","tensor([[0.0007, 0.0007, 0.0007,  ..., 0.0007, 0.0007, 0.0007],\n","        [0.0007, 0.0007, 0.0007,  ..., 0.0007, 0.0007, 0.0007],\n","        [0.0007, 0.0007, 0.0007,  ..., 0.0007, 0.0007, 0.0007],\n","        ...,\n","        [0.0007, 0.0007, 0.0007,  ..., 0.0007, 0.0007, 0.0007],\n","        [0.0007, 0.0007, 0.0007,  ..., 0.0007, 0.0007, 0.0007],\n","        [0.0007, 0.0007, 0.0106,  ..., 0.0007, 0.0007, 0.0007]])\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import MoleculeNet\n","import rdkit as rdkit\n","import torch\n","import numpy as np \n","torch.manual_seed(43)\n","path = '.'\n","dataset = MoleculeNet(path, name=\"pcba\").shuffle()\n","test_dataset = dataset[:len(dataset) // 10]\n","train_dataset = dataset[len(dataset) // 10:]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","weights = [1/1384, 1/94]\n","\n","#sampler_train = torch.utils.data.sampler.WeightedRandomSampler(weights, num_samples=len(train_dataset))\n","\n","#sampler_test = torch.utils.data.sampler.WeightedRandomSampler(weights, num_samples=len(test_dataset))\n","y = np.zeros((len(train_dataset), dataset.num_classes))\n","\n","for i in range(len(train_dataset)):\n","  y[i, :] = torch.nan_to_num(train_dataset[i].y)\n","target_list = torch.tensor(y).type(torch.LongTensor)\n","#target_list = target_list[torch.randperm(len(target_list))].type(torch.LongTensor)\n","print(y)\n","print(target_list==y)\n","class_weights = 1./torch.tensor([1384, 94], dtype=torch.float) \n","class_weights_all = class_weights[target_list]\n","print(class_weights_all)\n","weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(\n","    weights=class_weights_all,\n","    num_samples=len(class_weights_all),\n","    replacement=True\n",")\n","\n","test_loader = DataLoader(test_dataset,batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I00aCa-82PIb"},"outputs":[],"source":["import numpy as np\n","import torch.nn.functional as F\n","y = np.zeros((len(dataset),1, 12))\n","for i in range(len(dataset)):\n","  y[i, :, :] = dataset[i].y\n","factor = np.zeros((1,1,12))\n","add = np.zeros((1,1,12))\n","std = np.zeros((1,1,12))\n","for i in range(12): \n","  norm = np.linalg.norm(y[:,0,i], ord=2)\n","  factor[:,:,i] =  norm\n","  add[:,:,i] =   np.mean(y[:,0,i])\n","  std[:,:,i] = np.std(y[:,0,i])\n","print(np.mean(add))\n","print(factor)\n","print(np.mean(std))\n","print(y/factor)\n","#y_2=F.normalize(torch.from_numpy(y), p=2, dim=2)\n","#factor = y/y_2\n","#print(y/y_2)\n","#factor = factor[0]\n","print(dataset[789].y/factor[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c649l4bx2PRc"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"wRSlIPJ9VB1_"},"source":["## HIV"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":609,"status":"ok","timestamp":1621929382138,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"7HxmZcxfyY00","outputId":"463f4fde-b99c-439e-ea3f-5c77dd870618"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Dataset: HIV(37015):\n","======================\n","Number of graphs: 37015\n","Number of features: 9\n","Number of classes: 1\n","Test Dataset: HIV(4112):\n","======================\n","Number of graphs: 4112\n","Number of features: 9\n","Number of classes: 1\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import MoleculeNet\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = MoleculeNet(path, name=\"hiv\").shuffle()\n","test_dataset = dataset[:len(dataset) // 10]\n","train_dataset = dataset[len(dataset) // 10:]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=128)\n","train_loader = DataLoader(train_dataset, batch_size=128)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"elapsed":3038,"status":"error","timestamp":1621929400230,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"ROBPWO7lyZDt","outputId":"640b8084-c0c4-4629-cbf1-d9e7c8c282b1"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-011caeaa8536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-011caeaa8536>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0moutput_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-011caeaa8536>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, batch, edge_weight)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_add_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/glob/glob.py\u001b[0m in \u001b[0;36mglobal_add_pool\u001b[0;34m(x, batch, size)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \"\"\"\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'add'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6, heads = 12)\n","        self.conv5 = GraphConv(dim*12, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, 1)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return torch.sigmoid(x)\n","def train(epoch):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    loss_all = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output = model(data.x, data.edge_index, data.batch)\n","        output_pred = (output > 0.5).float()\n","        loss = torch.nn.BCEWithLogitsLoss(pos_weight= torch.Tensor([400]).to(device))\n","        loss = loss(output, data.y)\n","        loss.backward()\n","        loss_all += loss.item() * data.num_graphs\n","        optimizer.step()\n","    return loss_all / len(train_dataset)\n","\n","\n","def test(loader,  epoch, test=False):\n","    model.eval()\n","\n","    correct = 0\n","    auc = np.zeros(dataset.num_classes)\n","    if test:\n","      outs =[]\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.5).float()\n","        if test:\n","          outs.append(output_probs.cpu().detach().numpy())\n","        correct += (output == data.y).float().sum()\n","    if test: \n","      outputs =np.concatenate(outs, axis=0 ).astype(float)\n","      np.savetxt(\"HIV_epoch\"+str(epoch)+\".csv\", outputs)\n","    return correct / len(loader.dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(1, 500):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader, epoch)\n","    test_acc = test(test_loader, epoch, True)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0oShGbfG1pGn"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Qiz7oi04VFYy"},"source":["## SIDER "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2534,"status":"ok","timestamp":1621716140587,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"0gBiFIBqfiQE","outputId":"47aaf519-e26a-4294-d5cf-bf27cb6969d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing...\n","Done!\n","Train Dataset: SIDER(1285):\n","======================\n","Number of graphs: 1285\n","Number of features: 9\n","Number of classes: 27\n","Test Dataset: SIDER(142):\n","======================\n","Number of graphs: 142\n","Number of features: 9\n","Number of classes: 27\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import MoleculeNet\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = MoleculeNet(path, name=\"sider\").shuffle()\n","test_dataset = dataset[:len(dataset) // 10]\n","train_dataset = dataset[len(dataset) // 10:]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":108315,"status":"error","timestamp":1621716252403,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"FK_W7sMFfiS5","outputId":"4a7756c8-dec6-4bbd-e892-66cbf2903ce8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 001, Train Loss: 20.9759265, Train Acc: 0.5284047, Test Acc: 0.5211268\n","Epoch: 002, Train Loss: 2.1344892, Train Acc: 0.5221790, Test Acc: 0.5140845\n","Epoch: 003, Train Loss: 0.8315162, Train Acc: 0.4350195, Test Acc: 0.4577465\n","Epoch: 004, Train Loss: 0.7107426, Train Acc: 0.5276265, Test Acc: 0.5281690\n","Epoch: 005, Train Loss: 0.7045599, Train Acc: 0.5478599, Test Acc: 0.5492958\n","Epoch: 006, Train Loss: 0.7118828, Train Acc: 0.4684825, Test Acc: 0.4929577\n","Epoch: 007, Train Loss: 0.7082243, Train Acc: 0.5610895, Test Acc: 0.5774648\n","Epoch: 008, Train Loss: 0.7053720, Train Acc: 0.5400778, Test Acc: 0.5704225\n","Epoch: 009, Train Loss: 0.6983605, Train Acc: 0.5229572, Test Acc: 0.5774648\n","Epoch: 010, Train Loss: 0.6980576, Train Acc: 0.5540856, Test Acc: 0.6408451\n","Epoch: 011, Train Loss: 0.7021216, Train Acc: 0.4801556, Test Acc: 0.4929577\n","Epoch: 012, Train Loss: 0.6960352, Train Acc: 0.4568093, Test Acc: 0.4788732\n","Epoch: 013, Train Loss: 0.6949527, Train Acc: 0.5579767, Test Acc: 0.5985915\n","Epoch: 014, Train Loss: 0.6966548, Train Acc: 0.5649805, Test Acc: 0.6126761\n","Epoch: 015, Train Loss: 0.6871581, Train Acc: 0.5509728, Test Acc: 0.5915493\n","Epoch: 016, Train Loss: 0.6903764, Train Acc: 0.4778210, Test Acc: 0.4859155\n","Epoch: 017, Train Loss: 0.6857747, Train Acc: 0.5322957, Test Acc: 0.5281690\n","Epoch: 018, Train Loss: 0.6892736, Train Acc: 0.5120623, Test Acc: 0.5000000\n","Epoch: 019, Train Loss: 0.6876506, Train Acc: 0.5042802, Test Acc: 0.5070423\n","Epoch: 020, Train Loss: 0.6955366, Train Acc: 0.4785992, Test Acc: 0.4859155\n","Epoch: 021, Train Loss: 0.6776062, Train Acc: 0.4902724, Test Acc: 0.5070423\n","Epoch: 022, Train Loss: 0.6864733, Train Acc: 0.4614786, Test Acc: 0.4507042\n","Epoch: 023, Train Loss: 0.6845052, Train Acc: 0.4785992, Test Acc: 0.4859155\n","Epoch: 024, Train Loss: 0.6839986, Train Acc: 0.5813230, Test Acc: 0.6056338\n","Epoch: 025, Train Loss: 0.6891344, Train Acc: 0.4856031, Test Acc: 0.4859155\n","Epoch: 026, Train Loss: 0.6781869, Train Acc: 0.4809339, Test Acc: 0.4859155\n","Epoch: 027, Train Loss: 0.6760366, Train Acc: 0.4809339, Test Acc: 0.4859155\n","Epoch: 028, Train Loss: 0.6748720, Train Acc: 0.4793774, Test Acc: 0.4859155\n","Epoch: 029, Train Loss: 0.6783514, Train Acc: 0.4941634, Test Acc: 0.4859155\n","Epoch: 030, Train Loss: 0.6780384, Train Acc: 0.4824903, Test Acc: 0.4859155\n","Epoch: 031, Train Loss: 0.6808298, Train Acc: 0.5143969, Test Acc: 0.5352113\n","Epoch: 032, Train Loss: 0.6716203, Train Acc: 0.4926070, Test Acc: 0.4859155\n","Epoch: 033, Train Loss: 0.6738112, Train Acc: 0.4926070, Test Acc: 0.4859155\n","Epoch: 034, Train Loss: 0.6748251, Train Acc: 0.5214008, Test Acc: 0.5492958\n","Epoch: 035, Train Loss: 0.6720553, Train Acc: 0.4801556, Test Acc: 0.4859155\n","Epoch: 036, Train Loss: 0.6750160, Train Acc: 0.4785992, Test Acc: 0.4507042\n","Epoch: 037, Train Loss: 0.6615506, Train Acc: 0.4785992, Test Acc: 0.4859155\n","Epoch: 038, Train Loss: 0.6732318, Train Acc: 0.5027237, Test Acc: 0.4859155\n","Epoch: 039, Train Loss: 0.6604839, Train Acc: 0.5081712, Test Acc: 0.5070423\n","Epoch: 040, Train Loss: 0.6775874, Train Acc: 0.4817121, Test Acc: 0.4859155\n","Epoch: 041, Train Loss: 0.6724582, Train Acc: 0.4902724, Test Acc: 0.4859155\n","Epoch: 042, Train Loss: 0.6782447, Train Acc: 0.4863813, Test Acc: 0.4859155\n","Epoch: 043, Train Loss: 0.6883494, Train Acc: 0.5027237, Test Acc: 0.4929577\n","Epoch: 044, Train Loss: 0.6756899, Train Acc: 0.4902724, Test Acc: 0.4929577\n","Epoch: 045, Train Loss: 0.6678655, Train Acc: 0.4918288, Test Acc: 0.4929577\n","Epoch: 046, Train Loss: 0.6628785, Train Acc: 0.4817121, Test Acc: 0.4859155\n","Epoch: 047, Train Loss: 0.6639233, Train Acc: 0.4894942, Test Acc: 0.4788732\n","Epoch: 048, Train Loss: 0.6654435, Train Acc: 0.4840467, Test Acc: 0.4788732\n","Epoch: 049, Train Loss: 0.6780446, Train Acc: 0.4809339, Test Acc: 0.4859155\n","Epoch: 050, Train Loss: 0.6689537, Train Acc: 0.5377432, Test Acc: 0.5704225\n","Epoch: 051, Train Loss: 0.6647991, Train Acc: 0.4824903, Test Acc: 0.4859155\n","Epoch: 052, Train Loss: 0.6682578, Train Acc: 0.4910506, Test Acc: 0.4859155\n","Epoch: 053, Train Loss: 0.6582736, Train Acc: 0.4902724, Test Acc: 0.4929577\n","Epoch: 054, Train Loss: 0.6511904, Train Acc: 0.4918288, Test Acc: 0.4929577\n","Epoch: 055, Train Loss: 0.6588135, Train Acc: 0.4879377, Test Acc: 0.4859155\n","Epoch: 056, Train Loss: 0.6677703, Train Acc: 0.4809339, Test Acc: 0.4859155\n","Epoch: 057, Train Loss: 0.6578041, Train Acc: 0.4809339, Test Acc: 0.4859155\n","Epoch: 058, Train Loss: 0.6604927, Train Acc: 0.4817121, Test Acc: 0.4859155\n","Epoch: 059, Train Loss: 0.6603449, Train Acc: 0.4817121, Test Acc: 0.4859155\n","Epoch: 060, Train Loss: 0.6680155, Train Acc: 0.4949416, Test Acc: 0.4929577\n","Epoch: 061, Train Loss: 0.6579795, Train Acc: 0.4887160, Test Acc: 0.4859155\n","Epoch: 062, Train Loss: 0.6669578, Train Acc: 0.4817121, Test Acc: 0.4859155\n","Epoch: 063, Train Loss: 0.6584680, Train Acc: 0.5019455, Test Acc: 0.4859155\n","Epoch: 064, Train Loss: 0.6657685, Train Acc: 0.4824903, Test Acc: 0.4859155\n","Epoch: 065, Train Loss: 0.6609309, Train Acc: 0.4910506, Test Acc: 0.4859155\n","Epoch: 066, Train Loss: 0.6598197, Train Acc: 0.4848249, Test Acc: 0.4859155\n","Epoch: 067, Train Loss: 0.6660325, Train Acc: 0.4840467, Test Acc: 0.4859155\n","Epoch: 068, Train Loss: 0.6666800, Train Acc: 0.4879377, Test Acc: 0.4859155\n","Epoch: 069, Train Loss: 0.6548857, Train Acc: 0.4887160, Test Acc: 0.4859155\n","Epoch: 070, Train Loss: 0.6610087, Train Acc: 0.4856031, Test Acc: 0.4859155\n","Epoch: 071, Train Loss: 0.6617605, Train Acc: 0.4840467, Test Acc: 0.4859155\n","Epoch: 072, Train Loss: 0.6605249, Train Acc: 0.4856031, Test Acc: 0.4859155\n","Epoch: 073, Train Loss: 0.6579012, Train Acc: 0.4832685, Test Acc: 0.4859155\n","Epoch: 074, Train Loss: 0.6603609, Train Acc: 0.4809339, Test Acc: 0.4859155\n","Epoch: 075, Train Loss: 0.6561672, Train Acc: 0.4949416, Test Acc: 0.4859155\n","Epoch: 076, Train Loss: 0.6566794, Train Acc: 0.4840467, Test Acc: 0.4859155\n","Epoch: 077, Train Loss: 0.6609839, Train Acc: 0.4926070, Test Acc: 0.4929577\n","Epoch: 078, Train Loss: 0.6641395, Train Acc: 0.4941634, Test Acc: 0.4859155\n","Epoch: 079, Train Loss: 0.6604207, Train Acc: 0.4894942, Test Acc: 0.4929577\n","Epoch: 080, Train Loss: 0.6577907, Train Acc: 0.5011673, Test Acc: 0.5000000\n","Epoch: 081, Train Loss: 0.6614185, Train Acc: 0.4910506, Test Acc: 0.4929577\n","Epoch: 082, Train Loss: 0.6552619, Train Acc: 0.4972763, Test Acc: 0.4929577\n","Epoch: 083, Train Loss: 0.6567005, Train Acc: 0.5089494, Test Acc: 0.5140845\n","Epoch: 084, Train Loss: 0.6614882, Train Acc: 0.4871595, Test Acc: 0.4859155\n","Epoch: 085, Train Loss: 0.6566228, Train Acc: 0.4848249, Test Acc: 0.4859155\n","Epoch: 086, Train Loss: 0.6563435, Train Acc: 0.4902724, Test Acc: 0.4929577\n","Epoch: 087, Train Loss: 0.6549896, Train Acc: 0.4840467, Test Acc: 0.4859155\n","Epoch: 088, Train Loss: 0.6602069, Train Acc: 0.4879377, Test Acc: 0.4859155\n","Epoch: 089, Train Loss: 0.6639719, Train Acc: 0.4918288, Test Acc: 0.4929577\n","Epoch: 090, Train Loss: 0.6589651, Train Acc: 0.4824903, Test Acc: 0.4859155\n","Epoch: 091, Train Loss: 0.6563528, Train Acc: 0.4871595, Test Acc: 0.4929577\n","Epoch: 092, Train Loss: 0.6613690, Train Acc: 0.4840467, Test Acc: 0.4859155\n","Epoch: 093, Train Loss: 0.6580217, Train Acc: 0.4949416, Test Acc: 0.4929577\n","Epoch: 094, Train Loss: 0.6488114, Train Acc: 0.4887160, Test Acc: 0.4859155\n","Epoch: 095, Train Loss: 0.6524438, Train Acc: 0.5338521, Test Acc: 0.5633803\n","Epoch: 096, Train Loss: 0.6567888, Train Acc: 0.4871595, Test Acc: 0.4859155\n","Epoch: 097, Train Loss: 0.6573740, Train Acc: 0.4972763, Test Acc: 0.5000000\n","Epoch: 098, Train Loss: 0.6562938, Train Acc: 0.5019455, Test Acc: 0.5000000\n","Epoch: 099, Train Loss: 0.6616926, Train Acc: 0.4856031, Test Acc: 0.4859155\n","Epoch: 100, Train Loss: 0.6495423, Train Acc: 0.4957198, Test Acc: 0.4929577\n","Epoch: 101, Train Loss: 0.6587033, Train Acc: 0.4887160, Test Acc: 0.4859155\n","Epoch: 102, Train Loss: 0.6574061, Train Acc: 0.4832685, Test Acc: 0.4859155\n","Epoch: 103, Train Loss: 0.6609002, Train Acc: 0.5066148, Test Acc: 0.5211268\n","Epoch: 104, Train Loss: 0.6613522, Train Acc: 0.4957198, Test Acc: 0.4929577\n","Epoch: 105, Train Loss: 0.6642224, Train Acc: 0.4988327, Test Acc: 0.4929577\n","Epoch: 106, Train Loss: 0.6569315, Train Acc: 0.5027237, Test Acc: 0.5281690\n","Epoch: 107, Train Loss: 0.6605295, Train Acc: 0.5027237, Test Acc: 0.5140845\n","Epoch: 108, Train Loss: 0.6484863, Train Acc: 0.5089494, Test Acc: 0.5211268\n","Epoch: 109, Train Loss: 0.6576358, Train Acc: 0.5120623, Test Acc: 0.5211268\n","Epoch: 110, Train Loss: 0.6646493, Train Acc: 0.5229572, Test Acc: 0.5422535\n","Epoch: 111, Train Loss: 0.6610658, Train Acc: 0.5050584, Test Acc: 0.5211268\n","Epoch: 112, Train Loss: 0.6579161, Train Acc: 0.5128405, Test Acc: 0.5281690\n","Epoch: 113, Train Loss: 0.6502375, Train Acc: 0.5525292, Test Acc: 0.6056338\n","Epoch: 114, Train Loss: 0.6550738, Train Acc: 0.5408560, Test Acc: 0.5915493\n","Epoch: 115, Train Loss: 0.6588435, Train Acc: 0.5097276, Test Acc: 0.5211268\n","Epoch: 116, Train Loss: 0.6569427, Train Acc: 0.5136187, Test Acc: 0.5281690\n","Epoch: 117, Train Loss: 0.6534244, Train Acc: 0.5143969, Test Acc: 0.5352113\n","Epoch: 118, Train Loss: 0.6551357, Train Acc: 0.5011673, Test Acc: 0.5000000\n","Epoch: 119, Train Loss: 0.6513140, Train Acc: 0.5245136, Test Acc: 0.5563380\n","Epoch: 120, Train Loss: 0.6561523, Train Acc: 0.5743191, Test Acc: 0.6056338\n","Epoch: 121, Train Loss: 0.6581142, Train Acc: 0.5182879, Test Acc: 0.5422535\n","Epoch: 122, Train Loss: 0.6511892, Train Acc: 0.5898833, Test Acc: 0.6267606\n","Epoch: 123, Train Loss: 0.6552484, Train Acc: 0.5081712, Test Acc: 0.5140845\n","Epoch: 124, Train Loss: 0.6516614, Train Acc: 0.5089494, Test Acc: 0.5281690\n","Epoch: 125, Train Loss: 0.6481012, Train Acc: 0.5073930, Test Acc: 0.5211268\n","Epoch: 126, Train Loss: 0.6469974, Train Acc: 0.5712062, Test Acc: 0.5915493\n","Epoch: 127, Train Loss: 0.6556164, Train Acc: 0.6163424, Test Acc: 0.6619718\n","Epoch: 128, Train Loss: 0.6502674, Train Acc: 0.6163424, Test Acc: 0.6408451\n","Epoch: 129, Train Loss: 0.6539888, Train Acc: 0.5906615, Test Acc: 0.6338028\n","Epoch: 130, Train Loss: 0.6622551, Train Acc: 0.5836576, Test Acc: 0.6267606\n","Epoch: 131, Train Loss: 0.6541383, Train Acc: 0.5634241, Test Acc: 0.6197183\n","Epoch: 132, Train Loss: 0.6444865, Train Acc: 0.5338521, Test Acc: 0.5633803\n","Epoch: 133, Train Loss: 0.6564826, Train Acc: 0.5634241, Test Acc: 0.5985915\n","Epoch: 134, Train Loss: 0.6607390, Train Acc: 0.5704280, Test Acc: 0.6126761\n","Epoch: 135, Train Loss: 0.6493503, Train Acc: 0.5836576, Test Acc: 0.6197183\n","Epoch: 136, Train Loss: 0.6514456, Train Acc: 0.5914397, Test Acc: 0.6267606\n","Epoch: 137, Train Loss: 0.6487864, Train Acc: 0.5750973, Test Acc: 0.6126761\n","Epoch: 138, Train Loss: 0.6551491, Train Acc: 0.6311284, Test Acc: 0.6760563\n","Epoch: 139, Train Loss: 0.6497657, Train Acc: 0.5424125, Test Acc: 0.6197183\n","Epoch: 140, Train Loss: 0.6489121, Train Acc: 0.5206226, Test Acc: 0.5352113\n","Epoch: 141, Train Loss: 0.6589558, Train Acc: 0.5696498, Test Acc: 0.6549296\n","Epoch: 142, Train Loss: 0.6555001, Train Acc: 0.5836576, Test Acc: 0.6056338\n","Epoch: 143, Train Loss: 0.6545195, Train Acc: 0.5992218, Test Acc: 0.6267606\n","Epoch: 144, Train Loss: 0.6462021, Train Acc: 0.5805447, Test Acc: 0.6267606\n","Epoch: 145, Train Loss: 0.6412413, Train Acc: 0.5813230, Test Acc: 0.6408451\n","Epoch: 146, Train Loss: 0.6556372, Train Acc: 0.6093385, Test Acc: 0.6126761\n","Epoch: 147, Train Loss: 0.6532139, Train Acc: 0.6194553, Test Acc: 0.6267606\n","Epoch: 148, Train Loss: 0.6523439, Train Acc: 0.6023346, Test Acc: 0.6478873\n","Epoch: 149, Train Loss: 0.6567005, Train Acc: 0.5821012, Test Acc: 0.6267606\n","Epoch: 150, Train Loss: 0.6552527, Train Acc: 0.6256809, Test Acc: 0.6619718\n","Epoch: 151, Train Loss: 0.6565985, Train Acc: 0.5883268, Test Acc: 0.6267606\n","Epoch: 152, Train Loss: 0.6471748, Train Acc: 0.5712062, Test Acc: 0.6408451\n","Epoch: 153, Train Loss: 0.6519834, Train Acc: 0.5704280, Test Acc: 0.6126761\n","Epoch: 154, Train Loss: 0.6436955, Train Acc: 0.5782101, Test Acc: 0.6338028\n","Epoch: 155, Train Loss: 0.6458561, Train Acc: 0.6241245, Test Acc: 0.6408451\n","Epoch: 156, Train Loss: 0.6540960, Train Acc: 0.6070039, Test Acc: 0.6338028\n","Epoch: 157, Train Loss: 0.6423925, Train Acc: 0.6062257, Test Acc: 0.6478873\n","Epoch: 158, Train Loss: 0.6380830, Train Acc: 0.5953307, Test Acc: 0.6267606\n","Epoch: 159, Train Loss: 0.6463782, Train Acc: 0.5883268, Test Acc: 0.6338028\n","Epoch: 160, Train Loss: 0.6528529, Train Acc: 0.6038911, Test Acc: 0.6197183\n","Epoch: 161, Train Loss: 0.6563452, Train Acc: 0.6062257, Test Acc: 0.5985915\n","Epoch: 162, Train Loss: 0.6458238, Train Acc: 0.5976654, Test Acc: 0.6056338\n","Epoch: 163, Train Loss: 0.6546918, Train Acc: 0.6155642, Test Acc: 0.6338028\n","Epoch: 164, Train Loss: 0.6474516, Train Acc: 0.6093385, Test Acc: 0.6126761\n","Epoch: 165, Train Loss: 0.6454682, Train Acc: 0.6171206, Test Acc: 0.6267606\n","Epoch: 166, Train Loss: 0.6467312, Train Acc: 0.6171206, Test Acc: 0.6267606\n","Epoch: 167, Train Loss: 0.6453098, Train Acc: 0.6062257, Test Acc: 0.6267606\n","Epoch: 168, Train Loss: 0.6444704, Train Acc: 0.6132296, Test Acc: 0.6126761\n","Epoch: 169, Train Loss: 0.6471345, Train Acc: 0.6085603, Test Acc: 0.6338028\n","Epoch: 170, Train Loss: 0.6556076, Train Acc: 0.5992218, Test Acc: 0.6126761\n","Epoch: 171, Train Loss: 0.6474235, Train Acc: 0.6038911, Test Acc: 0.6197183\n","Epoch: 172, Train Loss: 0.6528140, Train Acc: 0.5961089, Test Acc: 0.6056338\n","Epoch: 173, Train Loss: 0.6464849, Train Acc: 0.5976654, Test Acc: 0.6267606\n","Epoch: 174, Train Loss: 0.6503112, Train Acc: 0.6000000, Test Acc: 0.6126761\n","Epoch: 175, Train Loss: 0.6472961, Train Acc: 0.5929961, Test Acc: 0.6408451\n","Epoch: 176, Train Loss: 0.6370570, Train Acc: 0.6194553, Test Acc: 0.6408451\n","Epoch: 177, Train Loss: 0.6559489, Train Acc: 0.6381323, Test Acc: 0.6549296\n","Epoch: 178, Train Loss: 0.6454027, Train Acc: 0.6350195, Test Acc: 0.6619718\n","Epoch: 179, Train Loss: 0.6537175, Train Acc: 0.6241245, Test Acc: 0.6408451\n","Epoch: 180, Train Loss: 0.6576555, Train Acc: 0.6272374, Test Acc: 0.6478873\n","Epoch: 181, Train Loss: 0.6497489, Train Acc: 0.6280156, Test Acc: 0.6338028\n","Epoch: 182, Train Loss: 0.6477732, Train Acc: 0.6225681, Test Acc: 0.6619718\n","Epoch: 183, Train Loss: 0.6489706, Train Acc: 0.6264591, Test Acc: 0.6549296\n","Epoch: 184, Train Loss: 0.6494560, Train Acc: 0.6466926, Test Acc: 0.6760563\n","Epoch: 185, Train Loss: 0.6483089, Train Acc: 0.6443580, Test Acc: 0.6830986\n","Epoch: 186, Train Loss: 0.6397505, Train Acc: 0.6225681, Test Acc: 0.6338028\n","Epoch: 187, Train Loss: 0.6470537, Train Acc: 0.6443580, Test Acc: 0.6690141\n","Epoch: 188, Train Loss: 0.6500592, Train Acc: 0.6295720, Test Acc: 0.6549296\n","Epoch: 189, Train Loss: 0.6550496, Train Acc: 0.5595331, Test Acc: 0.6056338\n","Epoch: 190, Train Loss: 0.6514295, Train Acc: 0.6295720, Test Acc: 0.6690141\n","Epoch: 191, Train Loss: 0.6480465, Train Acc: 0.5813230, Test Acc: 0.6338028\n","Epoch: 192, Train Loss: 0.6475748, Train Acc: 0.5844358, Test Acc: 0.5915493\n","Epoch: 193, Train Loss: 0.6497567, Train Acc: 0.5478599, Test Acc: 0.6056338\n","Epoch: 194, Train Loss: 0.6496372, Train Acc: 0.5828794, Test Acc: 0.6197183\n","Epoch: 195, Train Loss: 0.6500321, Train Acc: 0.6381323, Test Acc: 0.6830986\n","Epoch: 196, Train Loss: 0.6541283, Train Acc: 0.6147860, Test Acc: 0.6408451\n","Epoch: 197, Train Loss: 0.6446290, Train Acc: 0.6140078, Test Acc: 0.6478873\n","Epoch: 198, Train Loss: 0.6490238, Train Acc: 0.6202335, Test Acc: 0.6549296\n","Epoch: 199, Train Loss: 0.6364110, Train Acc: 0.6093385, Test Acc: 0.6267606\n","Epoch: 200, Train Loss: 0.6390244, Train Acc: 0.6108949, Test Acc: 0.6408451\n","Epoch: 201, Train Loss: 0.6449764, Train Acc: 0.6070039, Test Acc: 0.6197183\n","Epoch: 202, Train Loss: 0.6455722, Train Acc: 0.6132296, Test Acc: 0.6267606\n","Epoch: 203, Train Loss: 0.6536999, Train Acc: 0.5665370, Test Acc: 0.6338028\n","Epoch: 204, Train Loss: 0.6495623, Train Acc: 0.6093385, Test Acc: 0.6267606\n","Epoch: 205, Train Loss: 0.6438850, Train Acc: 0.6077821, Test Acc: 0.6338028\n","Epoch: 206, Train Loss: 0.6465585, Train Acc: 0.6396887, Test Acc: 0.6619718\n","Epoch: 207, Train Loss: 0.6459715, Train Acc: 0.5914397, Test Acc: 0.6338028\n","Epoch: 208, Train Loss: 0.6529770, Train Acc: 0.6038911, Test Acc: 0.6338028\n","Epoch: 209, Train Loss: 0.6449782, Train Acc: 0.6093385, Test Acc: 0.6478873\n","Epoch: 210, Train Loss: 0.6372839, Train Acc: 0.6217899, Test Acc: 0.6549296\n","Epoch: 211, Train Loss: 0.6470650, Train Acc: 0.6054475, Test Acc: 0.6267606\n","Epoch: 212, Train Loss: 0.6485532, Train Acc: 0.6334630, Test Acc: 0.6830986\n","Epoch: 213, Train Loss: 0.6455672, Train Acc: 0.6225681, Test Acc: 0.6056338\n","Epoch: 214, Train Loss: 0.6510897, Train Acc: 0.6000000, Test Acc: 0.6056338\n","Epoch: 215, Train Loss: 0.6423790, Train Acc: 0.6031128, Test Acc: 0.6338028\n","Epoch: 216, Train Loss: 0.6484256, Train Acc: 0.6093385, Test Acc: 0.6267606\n","Epoch: 217, Train Loss: 0.6521777, Train Acc: 0.6241245, Test Acc: 0.6619718\n","Epoch: 218, Train Loss: 0.6412471, Train Acc: 0.6264591, Test Acc: 0.6408451\n","Epoch: 219, Train Loss: 0.6540066, Train Acc: 0.6428016, Test Acc: 0.6690141\n","Epoch: 220, Train Loss: 0.6461267, Train Acc: 0.6443580, Test Acc: 0.6478873\n","Epoch: 221, Train Loss: 0.6466822, Train Acc: 0.6132296, Test Acc: 0.6338028\n","Epoch: 222, Train Loss: 0.6423668, Train Acc: 0.6085603, Test Acc: 0.6197183\n","Epoch: 223, Train Loss: 0.6443280, Train Acc: 0.6396887, Test Acc: 0.6408451\n","Epoch: 224, Train Loss: 0.6358442, Train Acc: 0.6311284, Test Acc: 0.6056338\n","Epoch: 225, Train Loss: 0.6463715, Train Acc: 0.6303502, Test Acc: 0.6126761\n","Epoch: 226, Train Loss: 0.6410040, Train Acc: 0.6202335, Test Acc: 0.6197183\n","Epoch: 227, Train Loss: 0.6462047, Train Acc: 0.6108949, Test Acc: 0.6056338\n","Epoch: 228, Train Loss: 0.6439533, Train Acc: 0.6085603, Test Acc: 0.6267606\n","Epoch: 229, Train Loss: 0.6337266, Train Acc: 0.6155642, Test Acc: 0.6267606\n","Epoch: 230, Train Loss: 0.6434758, Train Acc: 0.6116732, Test Acc: 0.6267606\n","Epoch: 231, Train Loss: 0.6472207, Train Acc: 0.6303502, Test Acc: 0.6549296\n","Epoch: 232, Train Loss: 0.6315813, Train Acc: 0.6412451, Test Acc: 0.6901408\n","Epoch: 233, Train Loss: 0.6325414, Train Acc: 0.6272374, Test Acc: 0.6478873\n","Epoch: 234, Train Loss: 0.6445058, Train Acc: 0.6404669, Test Acc: 0.6690141\n","Epoch: 235, Train Loss: 0.6418688, Train Acc: 0.6365759, Test Acc: 0.6549296\n","Epoch: 236, Train Loss: 0.6494050, Train Acc: 0.6396887, Test Acc: 0.6197183\n","Epoch: 237, Train Loss: 0.6413076, Train Acc: 0.6287938, Test Acc: 0.6197183\n","Epoch: 238, Train Loss: 0.6413861, Train Acc: 0.6163424, Test Acc: 0.6126761\n","Epoch: 239, Train Loss: 0.6370912, Train Acc: 0.6280156, Test Acc: 0.6830986\n","Epoch: 240, Train Loss: 0.6421911, Train Acc: 0.6272374, Test Acc: 0.6478873\n","Epoch: 241, Train Loss: 0.6545136, Train Acc: 0.6085603, Test Acc: 0.6126761\n","Epoch: 242, Train Loss: 0.6471274, Train Acc: 0.6070039, Test Acc: 0.6197183\n","Epoch: 243, Train Loss: 0.6452916, Train Acc: 0.6163424, Test Acc: 0.6126761\n","Epoch: 244, Train Loss: 0.6413155, Train Acc: 0.6326848, Test Acc: 0.6549296\n","Epoch: 245, Train Loss: 0.6426171, Train Acc: 0.5968872, Test Acc: 0.5845070\n","Epoch: 246, Train Loss: 0.6365956, Train Acc: 0.6194553, Test Acc: 0.6197183\n","Epoch: 247, Train Loss: 0.6454946, Train Acc: 0.6311284, Test Acc: 0.6338028\n","Epoch: 248, Train Loss: 0.6353862, Train Acc: 0.6350195, Test Acc: 0.6408451\n","Epoch: 249, Train Loss: 0.6458726, Train Acc: 0.6451362, Test Acc: 0.6478873\n","Epoch: 250, Train Loss: 0.6316526, Train Acc: 0.6241245, Test Acc: 0.6056338\n","Epoch: 251, Train Loss: 0.6396439, Train Acc: 0.6108949, Test Acc: 0.6056338\n","Epoch: 252, Train Loss: 0.6390116, Train Acc: 0.6280156, Test Acc: 0.6549296\n","Epoch: 253, Train Loss: 0.6505942, Train Acc: 0.6070039, Test Acc: 0.6126761\n","Epoch: 254, Train Loss: 0.6427869, Train Acc: 0.6186770, Test Acc: 0.5915493\n","Epoch: 255, Train Loss: 0.6358067, Train Acc: 0.6000000, Test Acc: 0.5985915\n","Epoch: 256, Train Loss: 0.6401913, Train Acc: 0.6163424, Test Acc: 0.6197183\n","Epoch: 257, Train Loss: 0.6404669, Train Acc: 0.6249027, Test Acc: 0.5915493\n","Epoch: 258, Train Loss: 0.6339951, Train Acc: 0.6381323, Test Acc: 0.6338028\n","Epoch: 259, Train Loss: 0.6476150, Train Acc: 0.6062257, Test Acc: 0.6408451\n","Epoch: 260, Train Loss: 0.6493373, Train Acc: 0.6365759, Test Acc: 0.6338028\n","Epoch: 261, Train Loss: 0.6295242, Train Acc: 0.6326848, Test Acc: 0.6197183\n","Epoch: 262, Train Loss: 0.6343213, Train Acc: 0.6295720, Test Acc: 0.6126761\n","Epoch: 263, Train Loss: 0.6414607, Train Acc: 0.6303502, Test Acc: 0.6267606\n","Epoch: 264, Train Loss: 0.6366442, Train Acc: 0.6272374, Test Acc: 0.6267606\n","Epoch: 265, Train Loss: 0.6354286, Train Acc: 0.6365759, Test Acc: 0.6197183\n","Epoch: 266, Train Loss: 0.6359867, Train Acc: 0.6451362, Test Acc: 0.6478873\n","Epoch: 267, Train Loss: 0.6342762, Train Acc: 0.6256809, Test Acc: 0.6126761\n","Epoch: 268, Train Loss: 0.6361088, Train Acc: 0.6295720, Test Acc: 0.6197183\n","Epoch: 269, Train Loss: 0.6418012, Train Acc: 0.6241245, Test Acc: 0.6056338\n","Epoch: 270, Train Loss: 0.6384764, Train Acc: 0.6334630, Test Acc: 0.6197183\n","Epoch: 271, Train Loss: 0.6364807, Train Acc: 0.6054475, Test Acc: 0.6549296\n","Epoch: 272, Train Loss: 0.6389255, Train Acc: 0.6482490, Test Acc: 0.6338028\n","Epoch: 273, Train Loss: 0.6356789, Train Acc: 0.6396887, Test Acc: 0.6197183\n","Epoch: 274, Train Loss: 0.6371616, Train Acc: 0.6350195, Test Acc: 0.6197183\n","Epoch: 275, Train Loss: 0.6371141, Train Acc: 0.5929961, Test Acc: 0.5774648\n","Epoch: 276, Train Loss: 0.6422308, Train Acc: 0.6046693, Test Acc: 0.5915493\n","Epoch: 277, Train Loss: 0.6551262, Train Acc: 0.6280156, Test Acc: 0.6408451\n","Epoch: 278, Train Loss: 0.6355615, Train Acc: 0.6428016, Test Acc: 0.6619718\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-85-56d6161c9c91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-85-56d6161c9c91>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mloss_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_all\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    group['eps'])\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, 2)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=-1)\n","\n","def train(epoch):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    loss_all = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        \n","        optimizer.zero_grad()\n","        output = model(data.x, data.edge_index, data.batch)\n","        y = data.y[:, 0].type(torch.LongTensor)\n","        y = y.to(device)\n","        loss = F.nll_loss(output, y)\n","        loss.backward()\n","        loss_all += loss.item() * data.num_graphs\n","        optimizer.step()\n","    return loss_all / len(train_dataset)\n","\n","\n","def test(loader):\n","    model.eval()\n","\n","    correct = 0\n","    if test: \n","      outs = []\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        y = data.y[:, 0].type(torch.LongTensor)\n","        y = y.to(device)\n","        data = data.to(device)\n","        output = model(data.x, data.edge_index, data.batch)\n","        pred = output.max(dim=1)[1]\n","        correct += pred.eq(y).sum().item()\n","        if test: \n","          outs.append(output.cpu().detach().numpy())\n","    if test: \n","        outputs =np.concatenate(outs, axis=0 ).astype(float)\n","        np.savetxt(\"Sider_epoch\"+str(epoch)+\".csv\", outputs)\n","\n","    return correct / len(loader.dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(1, 500):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tFPM8BW2fiVQ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rkvs1kp8fiX7"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"uDC-nMBeVH1Y"},"source":["## BBBP"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":410},"executionInfo":{"elapsed":317,"status":"error","timestamp":1621769352406,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"tUmOy3pwfaIn","outputId":"25602695-f10e-453a-f8d4-8e3478faa177"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Dataset: BBPB(1836):\n","======================\n","Number of graphs: 1836\n","Number of features: 9\n","Number of classes: 1\n","Test Dataset: BBPB(203):\n","======================\n","Number of graphs: 203\n","Number of features: 9\n","Number of classes: 1\n"]},{"ename":"IndexError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-151-bde70191e5c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mcount\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 1 with size 1"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import MoleculeNet\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = MoleculeNet(path, name=\"bbbp\").shuffle()\n","test_dataset = dataset[:len(dataset) // 10]\n","train_dataset = dataset[len(dataset) // 10:]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","count = 0\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":207,"status":"ok","timestamp":1621769432414,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"tw-5FIPt_I2H","outputId":"a9bcf9ed-3078-46c1-8e58-a88892230478"},"outputs":[{"name":"stdout","output_type":"stream","text":["count\n","2.2908496732026142\n","1836\n","-1.2908496732026145\n","torch.Size([1])\n"]}],"source":["for i in range(len(train_dataset)):\n","  if train_dataset[i].y[0] == 1: \n","    count+=1\n","print(\"count\")\n","print(count/len(train_dataset))\n","print(len(train_dataset))\n","print((len(train_dataset)-count)/len(train_dataset))\n","print(train_dataset[i].y[0].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":782},"executionInfo":{"elapsed":17023,"status":"error","timestamp":1621770064190,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"a46-Oi12faXm","outputId":"ef62bce6-b638-4586-c021-4ab4ceaeb905"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 001, Train Loss: 8.4716774, Train Acc: 0.7647059, Test Acc: 0.7684729\n","Epoch: 002, Train Loss: 0.6772530, Train Acc: 0.7647059, Test Acc: 0.7684729\n","Epoch: 003, Train Loss: 0.6008534, Train Acc: 0.7647059, Test Acc: 0.7684729\n","Epoch: 004, Train Loss: 0.5906292, Train Acc: 0.7647059, Test Acc: 0.7684729\n","Epoch: 005, Train Loss: 0.5781767, Train Acc: 0.7647059, Test Acc: 0.7684729\n","Epoch: 006, Train Loss: 0.5635467, Train Acc: 0.7647059, Test Acc: 0.7684729\n","Epoch: 007, Train Loss: 0.5623611, Train Acc: 0.7647059, Test Acc: 0.7684729\n","Epoch: 008, Train Loss: 0.5539443, Train Acc: 0.7647059, Test Acc: 0.7684729\n","Epoch: 009, Train Loss: 0.5407049, Train Acc: 0.7647059, Test Acc: 0.7684729\n","Epoch: 010, Train Loss: 0.5328917, Train Acc: 0.7647059, Test Acc: 0.7684729\n","Epoch: 011, Train Loss: 0.5273293, Train Acc: 0.7647059, Test Acc: 0.7684729\n","Epoch: 012, Train Loss: 0.5264424, Train Acc: 0.7647059, Test Acc: 0.7684729\n","Epoch: 013, Train Loss: 0.5292502, Train Acc: 0.7647059, Test Acc: 0.7684729\n","Epoch: 014, Train Loss: 0.5289267, Train Acc: 0.7712418, Test Acc: 0.7783251\n","Epoch: 015, Train Loss: 0.5171433, Train Acc: 0.7777778, Test Acc: 0.8029557\n","Epoch: 016, Train Loss: 0.5059986, Train Acc: 0.7647059, Test Acc: 0.7684729\n","Epoch: 017, Train Loss: 0.5074491, Train Acc: 0.7717865, Test Acc: 0.7832512\n","Epoch: 018, Train Loss: 0.4953782, Train Acc: 0.8044662, Test Acc: 0.8078818\n","Epoch: 019, Train Loss: 0.5045446, Train Acc: 0.7657952, Test Acc: 0.7684729\n","Epoch: 020, Train Loss: 0.4704343, Train Acc: 0.7957516, Test Acc: 0.7931034\n","Epoch: 021, Train Loss: 0.4732262, Train Acc: 0.8371460, Test Acc: 0.8620690\n","Epoch: 022, Train Loss: 0.4848028, Train Acc: 0.8376906, Test Acc: 0.8571429\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-165-bde8778d4594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-165-bde8778d4594>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mloss_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, 2)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=-1)\n","\n","def train(epoch):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    loss_all = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        \n","        optimizer.zero_grad()\n","        output = model(data.x, data.edge_index, data.batch)\n","        y = data.y[:, 0].type(torch.LongTensor)\n","        y = y.to(device)\n","        loss = F.nll_loss(output, y)\n","        loss.backward()\n","        loss_all += loss.item() * data.num_graphs\n","        optimizer.step()\n","    return loss_all / len(train_dataset)\n","\n","\n","def test(loader):\n","    model.eval()\n","\n","    correct = 0\n","    if test: \n","      outs = []\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        y = data.y[:, 0].type(torch.LongTensor)\n","        y = y.to(device)\n","        data = data.to(device)\n","        output = model(data.x, data.edge_index, data.batch)\n","        pred = output.max(dim=1)[1]\n","        correct += pred.eq(y).sum().item()\n","        if test: \n","          outs.append(output.cpu().detach().numpy())\n","    if test: \n","        outputs =np.concatenate(outs, axis=0 ).astype(float)\n","        np.savetxt(\"BPPP_epoch\"+str(epoch)+\".csv\", outputs)\n","\n","    return correct / len(loader.dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(1, 500):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dYJVFemGfalE"},"outputs":[],"source":["from sklearn import metrics\n","y = np.zeros((len(test_dataset), dataset.num_classes))\n","x = np.loadtxt(\"BPPP_epoch499.csv\")\n","for i in range(len(test_dataset)):\n","  y[i, :] = torch.nan_to_num(test_dataset[i].y)\n","print(y.shape)\n","for i in range(len(test_dataset)): \n","   if y[i, 0]<y[i, 1]:\n","     print(\"class2\")\n","   else: \n","     print(\"class1\")\n","print(x==y)\n","auch =metrics.roc_auc_score(y, x)\n","print(auch) "]},{"cell_type":"markdown","metadata":{"id":"1bG1u46KVKsv"},"source":["## Clintox\n","have to gunzip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3921,"status":"ok","timestamp":1621929456566,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"2HHHeS-kXKJ9","outputId":"62ab8aac-c69c-4a6f-8f30-a07c31fa0158"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing...\n","Done!\n","Train Dataset: ClinTox(1331):\n","======================\n","Number of graphs: 1331\n","Number of features: 9\n","Number of classes: 2\n","Test Dataset: ClinTox(147):\n","======================\n","Number of graphs: 147\n","Number of features: 9\n","Number of classes: 2\n","[[1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," ...\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]]\n","False\n","tensor([[0.0106, 0.0007],\n","        [0.0106, 0.0007],\n","        [0.0106, 0.0007],\n","        ...,\n","        [0.0106, 0.0007],\n","        [0.0106, 0.0007],\n","        [0.0106, 0.0007]])\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import MoleculeNet\n","import rdkit as rdkit\n","torch.manual_seed(43)\n","path = '.'\n","dataset = MoleculeNet(path, name=\"clintox\").shuffle()\n","test_dataset = dataset[:len(dataset) // 10]\n","train_dataset = dataset[len(dataset) // 10:]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","weights = [1/1384, 1/94]\n","\n","#sampler_train = torch.utils.data.sampler.WeightedRandomSampler(weights, num_samples=len(train_dataset))\n","\n","#sampler_test = torch.utils.data.sampler.WeightedRandomSampler(weights, num_samples=len(test_dataset))\n","y = np.zeros((len(train_dataset), dataset.num_classes))\n","\n","for i in range(len(train_dataset)):\n","  y[i, :] = torch.nan_to_num(train_dataset[i].y)\n","target_list = torch.tensor(y).type(torch.LongTensor)\n","#target_list = target_list[torch.randperm(len(target_list))].type(torch.LongTensor)\n","print(y)\n","print(target_list==y)\n","class_weights = 1./torch.tensor([1384, 94], dtype=torch.float) \n","class_weights_all = class_weights[target_list]\n","print(class_weights_all)\n","weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(\n","    weights=class_weights_all,\n","    num_samples=len(class_weights_all),\n","    replacement=True\n",")\n","\n","test_loader = DataLoader(test_dataset,batch_size=15)\n","train_loader = DataLoader(train_dataset, batch_size=15)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":856,"status":"ok","timestamp":1621929459124,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"2TLjr5RNCMI1","outputId":"684452f5-950a-458a-ab26-4901b542fc6f"},"outputs":[{"name":"stdout","output_type":"stream","text":["1384\n","0.9364005412719891\n","1478\n","94\n"]}],"source":["count = 0\n","for i in range(len(dataset)):\n","  if dataset[i].y[0,0] == 1: \n","    count+=1\n","print(count)\n","print(count/len(dataset))\n","print(len(dataset))\n","print((len(dataset)-count))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1621929459127,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"wUSAwiihMF3m","outputId":"4b601ca6-76f3-4493-9c63-18b4ee4f5ff9"},"outputs":[{"name":"stdout","output_type":"stream","text":["yeah\n","yeah\n","yeah\n","yeah\n","yeah\n","yeah\n","yeah\n","yeah\n","yeah\n","yeah\n","yeah\n","yeah\n","yeah\n","yeah\n","yeah\n","yeah\n","yeah\n","count\n","0.07888805409466566\n","1331\n","0.9211119459053343\n"]}],"source":["count = 0\n","for i in range(len(train_dataset)):\n","  if train_dataset[i].y[0,1] == 1: \n","    count+=1\n","  if train_dataset[i].y[0,1] == 1 and train_dataset[i].y[0,0] == 1: \n","    print(\"yeah\")\n","print(\"count\")\n","print(count/len(train_dataset))\n","print(len(train_dataset))\n","print((len(train_dataset)-count)/len(train_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":219013,"status":"error","timestamp":1621929697923,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"voOWpbeJXKQt","outputId":"34f7c109-94b7-4a6e-c81f-c114b1edcf81"},"outputs":[{"name":"stdout","output_type":"stream","text":["in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 001, Train Loss: 0.9229619, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.40686061658706035\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 002, Train Loss: 0.9184403, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4215552178318136\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 003, Train Loss: 0.9179198, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4288898538138659\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 004, Train Loss: 0.9195240, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4242726877985237\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 005, Train Loss: 0.9179834, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.42808655377044436\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 006, Train Loss: 0.9179474, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4423722680561586\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 007, Train Loss: 0.9179744, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4125126646403242\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 008, Train Loss: 0.9194230, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4321555217831814\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 009, Train Loss: 0.9177436, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.45179837892603847\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 010, Train Loss: 0.9177838, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4607269503546099\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 011, Train Loss: 0.9190410, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.46251266464032426\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 012, Train Loss: 0.9193402, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.46429837892603854\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 013, Train Loss: 0.9179869, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4660840932117528\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 014, Train Loss: 0.9181522, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4660840932117528\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 015, Train Loss: 0.9193445, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.46785714285714286\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 016, Train Loss: 0.9193914, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.48214285714285715\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 017, Train Loss: 0.9190578, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4857142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 018, Train Loss: 0.9193045, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4875\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 019, Train Loss: 0.9178090, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4910714285714286\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 020, Train Loss: 0.9182021, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4910714285714286\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 021, Train Loss: 0.9193248, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4928571428571429\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 022, Train Loss: 0.9183209, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49464285714285716\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 023, Train Loss: 0.9180263, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4928571428571429\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 024, Train Loss: 0.9177417, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49464285714285716\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 025, Train Loss: 0.9181206, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49464285714285716\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 026, Train Loss: 0.9177533, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49464285714285716\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 027, Train Loss: 0.9178015, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49464285714285716\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 028, Train Loss: 0.9177544, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49464285714285716\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 029, Train Loss: 0.9177277, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49642857142857144\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 030, Train Loss: 0.9193612, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49642857142857144\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 031, Train Loss: 0.9179631, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49642857142857144\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 032, Train Loss: 0.9192043, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49642857142857144\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 033, Train Loss: 0.9175490, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49642857142857144\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 034, Train Loss: 0.9193635, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49642857142857144\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 035, Train Loss: 0.9178286, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49642857142857144\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 036, Train Loss: 0.9175484, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49642857142857144\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 037, Train Loss: 0.9178506, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.49642857142857144\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 038, Train Loss: 0.9190835, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 039, Train Loss: 0.9174299, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 040, Train Loss: 0.9190295, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 041, Train Loss: 0.9196735, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 042, Train Loss: 0.9178720, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 043, Train Loss: 0.9176768, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 044, Train Loss: 0.9176558, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 045, Train Loss: 0.9174647, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 046, Train Loss: 0.9175137, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 047, Train Loss: 0.9175056, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 048, Train Loss: 0.9178278, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 049, Train Loss: 0.9177516, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 050, Train Loss: 0.9192046, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 051, Train Loss: 0.9190295, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 052, Train Loss: 0.9173758, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 053, Train Loss: 0.9172771, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n","in Epoch\n","Correct predictions epoch:  281\n","Num_predictions 294\n","Epoch: 054, Train Loss: 0.9173328, Train Acc: 0.9274981, Test Acc: 0.9557823\n","AUC is: 0.4982142857142857\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-8af5b2c8da78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","\u001b[0;32m<ipython-input-18-8af5b2c8da78>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader, epoch, test)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20000.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m        \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m        \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             return Batch.from_data_list(batch, self.follow_batch,\n\u001b[0;32m---> 17\u001b[0;31m                                         self.exclude_keys)\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Append item to the attribute list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mslices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;34mr\"\"\"Gets the data of the attribute :obj:`key`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","from sklearn import metrics\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        #self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv1 = GATConv(num_features, dim, dropout = 0.6, heads = 12)\n","        self.conv3 = GATConv(12*dim, dim, dropout = 0.6)\n","        #self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, 2)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return torch.sigmoid(x)\n","\n","def train(loader):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","  \n","    loss_all = 0\n","    weight = torch.tensor([100, 1]).type(torch.FloatTensor).to(device)\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output = model(data.x, data.edge_index, data.batch)\n","        #print(output)\n","        #y = torch.reshape(data.y[:, 1].type(torch.FloatTensor), (len(data.y),1))\n","        #y = y.to(device)\n","        #print(data.y)\n","        #print((data.y[:,1]==1).sum().item())\n","        #print(output)\n","        #print(output)\n","        loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([1.0, 15.0]))\n","        loss = loss(output, data.y)\n","        loss.backward()\n","        loss_all += loss.item() * data.num_graphs\n","        optimizer.step()\n","    return loss_all / len(train_dataset)\n","\n","\n","def test(loader, epoch, test=False):\n","    model.eval()\n","\n","    correct = 0\n","    if test: \n","      outs = []\n","    class_weights = torch.tensor([1.0, 20000.0]).to(device)\n","    for data in loader:\n","       data.x = data.x.type(torch.FloatTensor)\n","       data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","       data = data.to(device)\n","        \n","       optimizer.zero_grad()\n","       output = model(data.x, data.edge_index, data.batch)\n","       #y = torch.reshape(data.y[:, 1].type(torch.FloatTensor), (len(data.y),1))\n","       #y = y.to(device)\n","       #print(y)\n","       pred = (output>0.5).float()\n","       #print(pred)\n","       #pred = output.max(dim=1)[1]\n","       #pred = (output>0.4).float().to(device)\n","       #print(data.y)\n","       #print(pred)\n","       correct += (data.y[:,0] == pred[:,0]).sum().item()\n","       correct += (data.y[:,1] == pred[:,1]).sum().item()\n","       if test: \n","          outs.append(output.cpu().detach().numpy())\n","    if test: \n","      outputs =np.concatenate(outs, axis=0 ).astype(float)\n","      np.savetxt(\"ClinTox_epoch\"+str(epoch)+\".csv\", outputs)\n","      print(\"in Epoch\")\n","      print(\"Correct predictions epoch: \",correct)\n","      print(\"Num_predictions\",  len(loader.dataset)*2)\n","    #print(\"pred was\", pred)\n","    #print(\"correct was: \", y)\n","    return correct / (2*len(loader.dataset))\n","device =(\"cpu\")\n","#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=64).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(1, 500):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader, epoch)\n","    test_acc = test(test_loader, epoch, test=True)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))\n","    y = np.zeros((len(test_dataset), dataset.num_classes))\n","    x = np.loadtxt(\"ClinTox_epoch\"+str(epoch)+\".csv\")\n","    for i in range(len(test_dataset)):\n","      y[i, :] = torch.nan_to_num(test_dataset[i].y)\n","    auc = metrics.roc_auc_score(y, x)\n","    print(\"AUC is:\", auc)\n","#print(y.shape)\n","    if auc >=0.9:\n","      break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGDHPoXtXKp0"},"outputs":[],"source":["from sklearn import metrics\n","y = np.zeros((len(test_dataset), dataset.num_classes))\n","x = np.loadtxt(\"ClinTox_epoch240.csv\")\n","print(x)\n","for i in range(len(test_dataset)):\n","  y[i, :] = torch.nan_to_num(test_dataset[i].y)\n","#print(y.shape)\n","#for i in range(len(test_dataset)): \n","   #if y[i, 0]<y[i, 1]:\n","     #print(\"class2\")\n","   #else: \n","     #print(\"class1\")\n","print(x==y)\n","auch =metrics.roc_auc_score(y, x)\n","print(auch) "]},{"cell_type":"markdown","metadata":{"id":"fpLzti-WnLOh"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BxMzJCTnMVu"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":428,"status":"ok","timestamp":1621711257977,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"BwWZwOR6g2TN","outputId":"522cd1a2-1ab9-4c8f-8315-e5a261573053"},"outputs":[{"name":"stdout","output_type":"stream","text":["not conditional counts 0\n","conditional 1460\n"]}],"source":["counter_equal = 0\n","counter_neq = 0\n","for i in range(len(dataset)): \n","  if dataset[i].y[0, 0] == dataset[i].y[0, 1]:\n","    counter_equal += 0\n","  else: \n","    counter_neq +=1\n","print(\"conditional counts\", counter_equal)\n","print(\"non conditional\", counter_neq)"]},{"cell_type":"markdown","metadata":{"id":"4n3Mze8zPr-l"},"source":["##Tox21 Molecule Net\n","have to gununzip on first download"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Qbs6HFrPu5m"},"outputs":[],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import MoleculeNet\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = MoleculeNet(path, name=\"Tox21\").shuffle()\n","test_dataset = dataset[:len(dataset) // 10]\n","train_dataset = dataset[len(dataset) // 10:]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bdZLEKSUQf5Y"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","from sklearn import metrics\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return torch.sigmoid(x)\n","\n","def train(epoch):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    correct = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.5).float()\n","        loss = torch.nn.BCELoss()\n","        loss = loss(output_probs, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        correct += (output == data.y).float().sum()/12\n","    return correct / len(train_loader.dataset)\n","\n","\n","def test(loader,  epoch, test=False):\n","    model.eval()\n","\n","    correct = 0\n","    auc = np.zeros(dataset.num_classes)\n","    if test:\n","      outs =[]\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.5).float()\n","        if test:\n","          outs.append(output_probs.cpu().detach().numpy())\n","        correct += (output == data.y).float().sum()/12\n","    if test: \n","      outputs =np.concatenate(outs, axis=0 ).astype(float)\n","      np.savetxt(\"Tox21_epoch\"+str(epoch)+\".csv\", outputs)\n","    return correct / len(loader.dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n","\n","for epoch in range(1, 500):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader, epoch)\n","    test_acc = test(test_loader, test=True, epoch=epoch)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":406,"status":"ok","timestamp":1621708497572,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"lozZ7UCJIvcO","outputId":"4d53622a-a431-4651-ccf8-b2eb1b1992c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["(783, 12)\n","(783, 12)\n","0.8196557682164346\n"]}],"source":["y = np.zeros((len(test_dataset), dataset.num_classes))\n","x = np.loadtxt(\"Tox21_epoch499.csv\")\n","for i in range(len(test_dataset)):\n","  y[i, :] = torch.nan_to_num(test_dataset[i].y)\n","print(y.shape)\n","print(x.shape)\n","auch =metrics.roc_auc_score(y, x)\n","print(auch) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PdMp-mP8EFLo"},"outputs":[],"source":["import sklearn.metrics\n","metrics.roc_auc_score()"]},{"cell_type":"markdown","metadata":{"id":"Bk6KNixwaf4W"},"source":["## Single Class "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":12784,"status":"error","timestamp":1621676066847,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"EVGmz_zjahy_","outputId":"8032260f-a326-4535-b6d5-3a80d2424da8"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.])\n","tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","Epoch: 001, Train Loss: 11.1417427, Train Acc: 0.9378667, Test Acc: 0.9353980\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.])\n","tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","Epoch: 002, Train Loss: 11.2543993, Train Acc: 0.9378667, Test Acc: 0.9353980\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.])\n","tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","Epoch: 003, Train Loss: 11.2525549, Train Acc: 0.9378667, Test Acc: 0.9353980\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.])\n","tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","Epoch: 004, Train Loss: 11.2539730, Train Acc: 0.9378667, Test Acc: 0.9353980\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.])\n","tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","Epoch: 005, Train Loss: 11.2538319, Train Acc: 0.9378667, Test Acc: 0.9353980\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.])\n","tensor([1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","Epoch: 006, Train Loss: 11.2536898, Train Acc: 0.9378667, Test Acc: 0.9353980\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-2adc2ddb8718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","\u001b[0;32m<ipython-input-13-2adc2ddb8718>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             return Batch.from_data_list(batch, self.follow_batch,\n\u001b[0;32m---> 17\u001b[0;31m                                         self.exclude_keys)\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnum_nodes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 item = torch.full((num_nodes, ), i, dtype=torch.long,\n\u001b[0;32m--> 133\u001b[0;31m                                   device=device)\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return torch.sigmoid(x)\n","\n","def train(epoch):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    correct = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.6).float()\n","        loss = torch.nn.BCELoss()\n","        loss = loss(output_probs, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        correct += (output == data.y).float().sum()\n","    return correct / len(train_loader.dataset)\n","\n","\n","def test(loader):\n","    model.eval()\n","\n","    correct = 0\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        print(data.y[:][0])\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.5).float()\n","        correct += (output == data.y).float().sum()/12\n","    return correct / len(loader.dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(1, 5000):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuHULYXBaxDt"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"hqS65xm-beWg"},"source":["# Yeast"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26921,"status":"ok","timestamp":1621757295655,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"RjyFskjxbjE7","outputId":"89e73161-cc00-4f9d-b903-a96cce416990"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/Yeast.zip\n","Extracting ./Yeast/Yeast.zip\n","Processing...\n","Done!\n","Train Dataset: Yeast(71641):\n","======================\n","Number of graphs: 71641\n","Number of features: 74\n","Number of classes: 2\n","Test Dataset: Yeast(7960):\n","======================\n","Number of graphs: 7960\n","Number of features: 74\n","Number of classes: 2\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"Yeast\").shuffle()\n","\n","train_dataset = dataset[len(dataset) // 10:]\n","test_dataset = dataset[:len(dataset) // 10]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8582,"status":"ok","timestamp":1621757325152,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"UyqGc622Q8Rm","outputId":"9b2345a9-32b8-4efe-9477-e93183c693ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["9568\n","0.12019949498121883\n","79601\n","70033\n"]}],"source":["count = 0\n","for i in range(len(dataset)):\n","  if dataset[i].y == 1: \n","    count+=1\n","print(count)\n","print(count/len(dataset))\n","print(len(dataset))\n","print((len(dataset)-count))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RfjGT3FOQ8e6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":990},"executionInfo":{"elapsed":735142,"status":"error","timestamp":1621677269972,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"B9Q20LW8czJN","outputId":"6e39c1fd-e559-4a2e-d53d-aa59aa02a1f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 001, Train Loss: 0.3835490, Train Acc: 0.8802641, Test Acc: 0.8802641\n","Epoch: 002, Train Loss: 0.3473937, Train Acc: 0.8811993, Test Acc: 0.8811993\n","Epoch: 003, Train Loss: 0.3425290, Train Acc: 0.8820229, Test Acc: 0.8820229\n","Epoch: 004, Train Loss: 0.3401429, Train Acc: 0.8821624, Test Acc: 0.8821624\n","Epoch: 005, Train Loss: 0.3385379, Train Acc: 0.8821624, Test Acc: 0.8821624\n","Epoch: 006, Train Loss: 0.3377563, Train Acc: 0.8820647, Test Acc: 0.8820647\n","Epoch: 007, Train Loss: 0.3373184, Train Acc: 0.8817297, Test Acc: 0.8817297\n","Epoch: 008, Train Loss: 0.3376292, Train Acc: 0.8821066, Test Acc: 0.8821066\n","Epoch: 009, Train Loss: 0.3364518, Train Acc: 0.8822043, Test Acc: 0.8822043\n","Epoch: 010, Train Loss: 0.3360891, Train Acc: 0.8822881, Test Acc: 0.8822881\n","Epoch: 011, Train Loss: 0.3353057, Train Acc: 0.8810737, Test Acc: 0.8810737\n","Epoch: 012, Train Loss: 0.3354000, Train Acc: 0.8821345, Test Acc: 0.8821345\n","Epoch: 013, Train Loss: 0.3341412, Train Acc: 0.8824277, Test Acc: 0.8824277\n","Epoch: 014, Train Loss: 0.3344192, Train Acc: 0.8821764, Test Acc: 0.8821764\n","Epoch: 015, Train Loss: 0.3346963, Train Acc: 0.8824277, Test Acc: 0.8824277\n","Epoch: 016, Train Loss: 0.3343543, Train Acc: 0.8819112, Test Acc: 0.8819112\n","Epoch: 017, Train Loss: 0.3339003, Train Acc: 0.8822881, Test Acc: 0.8822881\n","Epoch: 018, Train Loss: 0.3336401, Train Acc: 0.8820368, Test Acc: 0.8820368\n","Epoch: 019, Train Loss: 0.3340470, Train Acc: 0.8820927, Test Acc: 0.8820927\n","Epoch: 020, Train Loss: 0.3329264, Train Acc: 0.8822183, Test Acc: 0.8822183\n","Epoch: 021, Train Loss: 0.3344221, Train Acc: 0.8823579, Test Acc: 0.8823579\n","Epoch: 022, Train Loss: 0.3333719, Train Acc: 0.8821066, Test Acc: 0.8821066\n","Epoch: 023, Train Loss: 0.3334058, Train Acc: 0.8823718, Test Acc: 0.8823718\n","Epoch: 024, Train Loss: 0.3335834, Train Acc: 0.8826789, Test Acc: 0.8826789\n","Epoch: 025, Train Loss: 0.3332497, Train Acc: 0.8824556, Test Acc: 0.8824556\n","Epoch: 026, Train Loss: 0.3329860, Train Acc: 0.8826789, Test Acc: 0.8826789\n","Epoch: 027, Train Loss: 0.3329121, Train Acc: 0.8824556, Test Acc: 0.8824556\n","Epoch: 028, Train Loss: 0.3328968, Train Acc: 0.8823300, Test Acc: 0.8823300\n","Epoch: 029, Train Loss: 0.3323423, Train Acc: 0.8821206, Test Acc: 0.8821206\n","Epoch: 030, Train Loss: 0.3333283, Train Acc: 0.8827208, Test Acc: 0.8827208\n","Epoch: 031, Train Loss: 0.3324008, Train Acc: 0.8829302, Test Acc: 0.8829302\n","Epoch: 032, Train Loss: 0.3325583, Train Acc: 0.8825952, Test Acc: 0.8825952\n","Epoch: 033, Train Loss: 0.3320040, Train Acc: 0.8824556, Test Acc: 0.8824556\n","Epoch: 034, Train Loss: 0.3323651, Train Acc: 0.8824416, Test Acc: 0.8824416\n","Epoch: 035, Train Loss: 0.3320448, Train Acc: 0.8828883, Test Acc: 0.8828883\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-d798aaf67304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-d798aaf67304>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mloss_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             return Batch.from_data_list(batch, self.follow_batch,\n\u001b[0;32m---> 17\u001b[0;31m                                         self.exclude_keys)\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;31m# Gather the size of the `cat` dimension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mcat_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cat_dim__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0;31m# 0-dimensional tensors have no dimension along which to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;31m# concatenate, so we set `cat_dim` to `None`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__cat_dim__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \"\"\"\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# Concatenate `*index*` and `*face*` attributes in the last dimension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(index|face)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# By default, concatenate sparse matrices diagonally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[1;32m    184\u001b[0m     a Match object, or None if no match was found.\"\"\"\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=-1)\n","\n","def train(epoch):\n","    model.train()\n","\n","    if epoch%51 == 0:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    loss_all = 0\n","    for data in train_loader:\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output = model(data.x, data.edge_index, data.batch)\n","        loss = F.nll_loss(output, data.y)\n","        loss.backward()\n","        loss_all += loss.item() * data.num_graphs\n","        optimizer.step()\n","    return loss_all / len(train_dataset)\n","\n","\n","def test(loader):\n","    model.eval()\n","\n","    correct = 0\n","    for data in loader:\n","        data = data.to(device)\n","        output = model(data.x, data.edge_index, data.batch)\n","        pred = output.max(dim=1)[1]\n","        correct += pred.eq(data.y).sum().item()\n","    return correct / len(loader.dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=64).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n","\n","for epoch in range(1, 500):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X096hXVPfEAX"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"7wf53nbjbfVk"},"source":["#YeatsH"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":660},"executionInfo":{"elapsed":39966,"status":"error","timestamp":1621676240576,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"YysvKTzpbvUv","outputId":"d8fc60c5-d93c-4dff-80dc-2c2a5bea80df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/YeastH.zip\n","Extracting ./YeastH/YeastH.zip\n","Processing...\n","Done!\n","Train Dataset: YeastH(71641):\n","======================\n","Number of graphs: 71641\n","Number of features: 75\n","Number of classes: 2\n","Test Dataset: Tox21(783):\n","======================\n","Number of graphs: 783\n","Number of features: 9\n","Number of classes: 12\n"]},{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-8b7815633aca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-2adc2ddb8718>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput_probs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2753\u001b[0m         raise ValueError(\n\u001b[1;32m   2754\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2755\u001b[0;31m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2756\u001b[0m         )\n\u001b[1;32m   2757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 2])) is deprecated. Please ensure they have the same size."]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"YeastH\").shuffle()\n","\n","train_dataset = dataset[len(dataset) // 10:]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=-1)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(1, 1001):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5Tz9Cj-fFtO"},"outputs":[],"source":["# Enzymes"]},{"cell_type":"markdown","metadata":{"id":"STtDUucufHBY"},"source":["#Enzymes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6574,"status":"ok","timestamp":1621888648812,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"SiHeNKvcgHFu","outputId":"8d624b4b-02e5-492a-a91d-b1198fbfc37d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n","Extracting ./ENZYMES/ENZYMES.zip\n","Processing...\n","Done!\n","Train Dataset: ENZYMES(540):\n","======================\n","Number of graphs: 540\n","Number of features: 3\n","Number of classes: 6\n","Test Dataset: ENZYMES(60):\n","======================\n","Number of graphs: 60\n","Number of features: 3\n","Number of classes: 6\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"ENZYMES\").shuffle()\n","\n","train_dataset = dataset[len(dataset) // 10:]\n","test_dataset = dataset[:len(dataset) // 10]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":286022,"status":"ok","timestamp":1621889225428,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"XK6bcdKLfImK","outputId":"52859242-6eb2-4ad5-ea81-be49c36eda84"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 001, Train Loss: 0.7453703, Train Acc: 0.1685185, Test Acc: 0.1500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5\n","Epoch: 002, Train Loss: 0.8222223, Train Acc: 0.1685185, Test Acc: 0.1500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5\n","Epoch: 003, Train Loss: 0.8302469, Train Acc: 0.1685185, Test Acc: 0.1500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5\n","Epoch: 004, Train Loss: 0.8280864, Train Acc: 0.1685185, Test Acc: 0.1500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5\n","Epoch: 005, Train Loss: 0.8296297, Train Acc: 0.1685185, Test Acc: 0.1500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5\n","Epoch: 006, Train Loss: 0.8123457, Train Acc: 0.1685185, Test Acc: 0.1500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5\n","Epoch: 007, Train Loss: 0.8157407, Train Acc: 0.1685185, Test Acc: 0.1500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5\n","Epoch: 008, Train Loss: 0.7990741, Train Acc: 0.1703704, Test Acc: 0.1500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5204081632653061\n","AUC of 3is: 0.5\n","AUC of 4is: 0.514423076923077\n","AUC of 5is: 0.5\n","Average auc 0.5058052066980638\n","Epoch: 009, Train Loss: 0.7509258, Train Acc: 0.1703704, Test Acc: 0.1500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5\n","Epoch: 010, Train Loss: 0.8271605, Train Acc: 0.1703704, Test Acc: 0.1500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5\n","Epoch: 011, Train Loss: 0.8320987, Train Acc: 0.1740741, Test Acc: 0.1666667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5454545454545454\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5075757575757576\n","Epoch: 012, Train Loss: 0.8320988, Train Acc: 0.1777778, Test Acc: 0.1666667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5454545454545454\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5075757575757576\n","Epoch: 013, Train Loss: 0.8333333, Train Acc: 0.1796296, Test Acc: 0.1666667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5454545454545454\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5075757575757576\n","Epoch: 014, Train Loss: 0.8342593, Train Acc: 0.1796296, Test Acc: 0.1666667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5454545454545454\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5075757575757576\n","Epoch: 015, Train Loss: 0.8339506, Train Acc: 0.1722222, Test Acc: 0.1666667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5454545454545454\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5075757575757576\n","Epoch: 016, Train Loss: 0.8330247, Train Acc: 0.1833333, Test Acc: 0.1833333\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5909090909090909\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5151515151515151\n","Epoch: 017, Train Loss: 0.8342593, Train Acc: 0.1777778, Test Acc: 0.1666667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5454545454545454\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5075757575757576\n","Epoch: 018, Train Loss: 0.8320988, Train Acc: 0.1925926, Test Acc: 0.2000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6363636363636364\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5227272727272727\n","Epoch: 019, Train Loss: 0.8354938, Train Acc: 0.1944444, Test Acc: 0.2000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6363636363636364\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5227272727272727\n","Epoch: 020, Train Loss: 0.8345679, Train Acc: 0.1981481, Test Acc: 0.2000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6363636363636364\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5227272727272727\n","Epoch: 021, Train Loss: 0.8345678, Train Acc: 0.1907407, Test Acc: 0.2000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6363636363636364\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5227272727272727\n","Epoch: 022, Train Loss: 0.8314815, Train Acc: 0.1851852, Test Acc: 0.1833333\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.5909090909090909\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5151515151515151\n","Epoch: 023, Train Loss: 0.8376544, Train Acc: 0.2018518, Test Acc: 0.2000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6363636363636364\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5227272727272727\n","Epoch: 024, Train Loss: 0.8351852, Train Acc: 0.2055556, Test Acc: 0.2000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6363636363636364\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5227272727272727\n","Epoch: 025, Train Loss: 0.8382716, Train Acc: 0.2111111, Test Acc: 0.2000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6363636363636364\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5210932857991681\n","Epoch: 026, Train Loss: 0.8376544, Train Acc: 0.2037037, Test Acc: 0.2000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6363636363636364\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5227272727272727\n","Epoch: 027, Train Loss: 0.8376543, Train Acc: 0.2092593, Test Acc: 0.2000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6363636363636364\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5227272727272727\n","Epoch: 028, Train Loss: 0.8391975, Train Acc: 0.2185185, Test Acc: 0.2166667\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6818181818181819\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5270350564468211\n","Epoch: 029, Train Loss: 0.8345679, Train Acc: 0.2129630, Test Acc: 0.2166667\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6818181818181819\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5270350564468211\n","Epoch: 030, Train Loss: 0.8425927, Train Acc: 0.2148148, Test Acc: 0.2166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6818181818181819\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5303030303030303\n","Epoch: 031, Train Loss: 0.8376544, Train Acc: 0.2203704, Test Acc: 0.2166667\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6818181818181819\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5270350564468211\n","Epoch: 032, Train Loss: 0.8358026, Train Acc: 0.2277778, Test Acc: 0.2166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6818181818181819\n","AUC of 3is: 0.4803921568627451\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5270350564468211\n","Epoch: 033, Train Loss: 0.8373456, Train Acc: 0.2203704, Test Acc: 0.2166667\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6818181818181819\n","AUC of 3is: 0.5\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5286690433749257\n","Epoch: 034, Train Loss: 0.8388889, Train Acc: 0.2333333, Test Acc: 0.2166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6818181818181819\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5286690433749257\n","Epoch: 035, Train Loss: 0.8379629, Train Acc: 0.2370370, Test Acc: 0.2333333\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.7272727272727273\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5362448009506833\n","Epoch: 036, Train Loss: 0.8385803, Train Acc: 0.2296296, Test Acc: 0.2166667\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6818181818181819\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5270350564468211\n","Epoch: 037, Train Loss: 0.8361111, Train Acc: 0.2277778, Test Acc: 0.2166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6818181818181819\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5286690433749257\n","Epoch: 038, Train Loss: 0.8416667, Train Acc: 0.2407407, Test Acc: 0.2500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.7272727272727273\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5714285714285714\n","Average auc 0.5481495628554452\n","Epoch: 039, Train Loss: 0.8407407, Train Acc: 0.2537037, Test Acc: 0.2333333\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6818181818181819\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5619946091644205\n","Average auc 0.5390014782356625\n","Epoch: 040, Train Loss: 0.8438272, Train Acc: 0.2870370, Test Acc: 0.2333333\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.7272727272727273\n","AUC of 3is: 0.4803921568627451\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5525606469002695\n","Average auc 0.5433709218392903\n","Epoch: 041, Train Loss: 0.8432099, Train Acc: 0.3092593, Test Acc: 0.2166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6818181818181819\n","AUC of 3is: 0.4803921568627451\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5525606469002695\n","Average auc 0.5357951642635327\n","Epoch: 042, Train Loss: 0.8419753, Train Acc: 0.2814815, Test Acc: 0.2500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.7272727272727273\n","AUC of 3is: 0.5359477124183007\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5525606469002695\n","Average auc 0.5526301810985496\n","Epoch: 043, Train Loss: 0.8416666, Train Acc: 0.2500000, Test Acc: 0.2333333\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.5\n","AUC of 2is: 0.7272727272727273\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5\n","Average auc 0.5346108140225787\n","Epoch: 044, Train Loss: 0.8435185, Train Acc: 0.3018518, Test Acc: 0.2333333\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.5\n","AUC of 2is: 0.7170686456400742\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.49038461538461536\n","AUC of 5is: 0.6239892183288409\n","Average auc 0.5519724393693792\n","Epoch: 045, Train Loss: 0.8475309, Train Acc: 0.3370370, Test Acc: 0.2666667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.7625231910946196\n","AUC of 3is: 0.47058823529411764\n","AUC of 4is: 0.5\n","AUC of 5is: 0.6239892183288409\n","Average auc 0.5595167741195963\n","Epoch: 046, Train Loss: 0.8459877, Train Acc: 0.3388889, Test Acc: 0.2833334\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.4803921568627451\n","AUC of 4is: 0.5\n","AUC of 5is: 0.6239892183288409\n","Average auc 0.5687265186234586\n","Epoch: 047, Train Loss: 0.8385803, Train Acc: 0.3314815, Test Acc: 0.3000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.7625231910946196\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.625\n","AUC of 5is: 0.6239892183288409\n","Average auc 0.5836180813091388\n","Epoch: 048, Train Loss: 0.8456790, Train Acc: 0.3222222, Test Acc: 0.2166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.6818181818181819\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5336927223719676\n","Average auc 0.534284497103587\n","Epoch: 049, Train Loss: 0.8459877, Train Acc: 0.3518519, Test Acc: 0.2666667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.7625231910946196\n","AUC of 3is: 0.4803921568627451\n","AUC of 4is: 0.5\n","AUC of 5is: 0.6239892183288409\n","Average auc 0.5611507610477009\n","Epoch: 050, Train Loss: 0.8484567, Train Acc: 0.3703704, Test Acc: 0.3333333\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.625\n","AUC of 5is: 0.6859838274932615\n","Average auc 0.6015262737456332\n","Epoch: 051, Train Loss: 0.8496914, Train Acc: 0.3537037, Test Acc: 0.3000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.7625231910946196\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5625\n","AUC of 5is: 0.6239892183288409\n","Average auc 0.5784097479758055\n","Epoch: 052, Train Loss: 0.8503087, Train Acc: 0.3851852, Test Acc: 0.3000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.7625231910946196\n","AUC of 3is: 0.4803921568627451\n","AUC of 4is: 0.5625\n","AUC of 5is: 0.61455525606469\n","Average auc 0.5752034340036758\n","Epoch: 053, Train Loss: 0.8543209, Train Acc: 0.3537037, Test Acc: 0.3000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5\n","AUC of 5is: 0.5956873315363881\n","Average auc 0.5708518577528209\n","Epoch: 054, Train Loss: 0.8493827, Train Acc: 0.3962963, Test Acc: 0.3166667\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5625\n","AUC of 5is: 0.61455525606469\n","Average auc 0.5827791915794334\n","Epoch: 055, Train Loss: 0.8527778, Train Acc: 0.3925926, Test Acc: 0.3166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5625\n","AUC of 5is: 0.5956873315363881\n","Average auc 0.5812685244194876\n","Epoch: 056, Train Loss: 0.8537037, Train Acc: 0.3981481, Test Acc: 0.3333333\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.4803921568627451\n","AUC of 4is: 0.5\n","AUC of 5is: 0.738544474393531\n","Average auc 0.5930273946342401\n","Epoch: 057, Train Loss: 0.8530865, Train Acc: 0.4055555, Test Acc: 0.3166667\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5625\n","AUC of 5is: 0.605121293800539\n","Average auc 0.5812068645354082\n","Epoch: 058, Train Loss: 0.8521605, Train Acc: 0.3925926, Test Acc: 0.3166667\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.7625231910946196\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5625\n","AUC of 5is: 0.5956873315363881\n","Average auc 0.5772671132489587\n","Epoch: 059, Train Loss: 0.8546297, Train Acc: 0.4000000, Test Acc: 0.3000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.7625231910946196\n","AUC of 3is: 0.47058823529411764\n","AUC of 4is: 0.5\n","AUC of 5is: 0.6671159029649596\n","Average auc 0.5719128882256161\n","Epoch: 060, Train Loss: 0.8564814, Train Acc: 0.4092593, Test Acc: 0.3166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5625\n","AUC of 5is: 0.605121293800539\n","Average auc 0.5828408514635127\n","Epoch: 061, Train Loss: 0.8583333, Train Acc: 0.4314815, Test Acc: 0.3500000\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.625\n","AUC of 5is: 0.61455525606469\n","Average auc 0.5984041915794334\n","Epoch: 062, Train Loss: 0.8617284, Train Acc: 0.4425926, Test Acc: 0.3500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5625\n","AUC of 5is: 0.6671159029649596\n","Average auc 0.5983816196575829\n","Epoch: 063, Train Loss: 0.8608025, Train Acc: 0.4333333, Test Acc: 0.3166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.4803921568627451\n","AUC of 4is: 0.5625\n","AUC of 5is: 0.6671159029649596\n","Average auc 0.5915392993961449\n","Epoch: 064, Train Loss: 0.8589506, Train Acc: 0.4259259, Test Acc: 0.3333333\n","AUC of 0is: 0.4803921568627451\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.5625\n","AUC of 5is: 0.6859838274932615\n","Average auc 0.5930499665560908\n","Epoch: 065, Train Loss: 0.8611112, Train Acc: 0.4500000, Test Acc: 0.3666667\n","AUC of 0is: 0.4803921568627451\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.545751633986928\n","AUC of 4is: 0.5625\n","AUC of 5is: 0.6765498652291105\n","Average auc 0.6083126563470824\n","Epoch: 066, Train Loss: 0.8586419, Train Acc: 0.4444444, Test Acc: 0.3333333\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.5261437908496732\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.6765498652291105\n","Average auc 0.6079170144073228\n","Epoch: 067, Train Loss: 0.8645062, Train Acc: 0.4185185, Test Acc: 0.3500000\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.7625231910946196\n","AUC of 3is: 0.4803921568627451\n","AUC of 4is: 0.5\n","AUC of 5is: 0.871967654986523\n","Average auc 0.6060548468958767\n","Epoch: 068, Train Loss: 0.8688271, Train Acc: 0.4407407, Test Acc: 0.3500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.5261437908496732\n","AUC of 4is: 0.5625\n","AUC of 5is: 0.6765498652291105\n","Average auc 0.6007368987713247\n","Epoch: 069, Train Loss: 0.8608025, Train Acc: 0.4814815, Test Acc: 0.3833334\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.6013071895424837\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.6765498652291105\n","Average auc 0.6296539920266534\n","Epoch: 070, Train Loss: 0.8641976, Train Acc: 0.4629630, Test Acc: 0.3833334\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.625\n","AUC of 5is: 0.72911051212938\n","Average auc 0.6214981454274106\n","Epoch: 071, Train Loss: 0.8645062, Train Acc: 0.4500000, Test Acc: 0.3833334\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.625\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.6258271497564148\n","Epoch: 072, Train Loss: 0.8709877, Train Acc: 0.4833333, Test Acc: 0.4166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.6013071895424837\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.72911051212938\n","Average auc 0.6436224331766983\n","Epoch: 073, Train Loss: 0.8663580, Train Acc: 0.4740741, Test Acc: 0.3500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.5359477124183007\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.6671159029649596\n","Average auc 0.626002521359367\n","Epoch: 074, Train Loss: 0.8719136, Train Acc: 0.4870370, Test Acc: 0.3833334\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.545751633986928\n","AUC of 4is: 0.625\n","AUC of 5is: 0.6576819407008087\n","Average auc 0.6188526427819079\n","Epoch: 075, Train Loss: 0.8669752, Train Acc: 0.4759259, Test Acc: 0.3666667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.6576819407008087\n","Average auc 0.6131991527534179\n","Epoch: 076, Train Loss: 0.8675926, Train Acc: 0.5129629, Test Acc: 0.4166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.6765498652291105\n","Average auc 0.6408536107630368\n","Epoch: 077, Train Loss: 0.8654321, Train Acc: 0.4648148, Test Acc: 0.4000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.545751633986928\n","AUC of 4is: 0.625\n","AUC of 5is: 0.72911051212938\n","Average auc 0.6307574046866699\n","Epoch: 078, Train Loss: 0.8654321, Train Acc: 0.5074074, Test Acc: 0.4000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.5915032679738562\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.6576819407008087\n","Average auc 0.6405003510104984\n","Epoch: 079, Train Loss: 0.8712963, Train Acc: 0.5203704, Test Acc: 0.4000000\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.5359477124183007\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.738544474393531\n","Average auc 0.6326675271052551\n","Epoch: 080, Train Loss: 0.8719136, Train Acc: 0.5074074, Test Acc: 0.3833334\n","AUC of 0is: 0.47058823529411764\n","AUC of 1is: 0.53125\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.545751633986928\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.6226805527557668\n","Epoch: 081, Train Loss: 0.8753086, Train Acc: 0.5203704, Test Acc: 0.3666667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8079777365491649\n","AUC of 3is: 0.5359477124183007\n","AUC of 4is: 0.6057692307692307\n","AUC of 5is: 0.72911051212938\n","Average auc 0.6235508653110128\n","Epoch: 082, Train Loss: 0.8675926, Train Acc: 0.4981481, Test Acc: 0.4000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.6013071895424837\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.6420501061326731\n","Epoch: 083, Train Loss: 0.8716049, Train Acc: 0.5240741, Test Acc: 0.3833334\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.4803921568627451\n","AUC of 4is: 0.6057692307692307\n","AUC of 5is: 0.72911051212938\n","Average auc 0.6202333766994065\n","Epoch: 084, Train Loss: 0.8694445, Train Acc: 0.5277778, Test Acc: 0.3833334\n","AUC of 0is: 0.47058823529411764\n","AUC of 1is: 0.59375\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.7102425876010782\n","Average auc 0.6222656331191491\n","Epoch: 085, Train Loss: 0.8793211, Train Acc: 0.5240741, Test Acc: 0.4166667\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.59375\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.6830065359477124\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.72911051212938\n","Average auc 0.6608133373161319\n","Epoch: 086, Train Loss: 0.8780864, Train Acc: 0.5148148, Test Acc: 0.4166667\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.59375\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.545751633986928\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.6363651932786426\n","Epoch: 087, Train Loss: 0.8712962, Train Acc: 0.5592592, Test Acc: 0.4333334\n","AUC of 0is: 0.4803921568627451\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.6057692307692307\n","AUC of 5is: 0.6859838274932615\n","Average auc 0.6577079052949119\n","Epoch: 088, Train Loss: 0.8749999, Train Acc: 0.5407407, Test Acc: 0.4000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.59375\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.6057692307692307\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.6271373568449238\n","Epoch: 089, Train Loss: 0.8808643, Train Acc: 0.5444444, Test Acc: 0.4166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.59375\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.6671159029649596\n","Average auc 0.6553828632397088\n","Epoch: 090, Train Loss: 0.8793210, Train Acc: 0.5333333, Test Acc: 0.4000000\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.59375\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.545751633986928\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.7102425876010782\n","Average auc 0.6347928662346175\n","Epoch: 091, Train Loss: 0.8811728, Train Acc: 0.5777777, Test Acc: 0.4166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.5915032679738562\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.6482479784366577\n","Average auc 0.64934469063314\n","Epoch: 092, Train Loss: 0.8765432, Train Acc: 0.5648148, Test Acc: 0.4000000\n","AUC of 0is: 0.4803921568627451\n","AUC of 1is: 0.59375\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.5359477124183007\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7102425876010782\n","Average auc 0.641941559045075\n","Epoch: 093, Train Loss: 0.8796296, Train Acc: 0.5611111, Test Acc: 0.4500000\n","AUC of 0is: 0.4803921568627451\n","AUC of 1is: 0.59375\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.72911051212938\n","Average auc 0.6728639909109031\n","Epoch: 094, Train Loss: 0.8774691, Train Acc: 0.5629629, Test Acc: 0.4166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.59375\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.6470588235294117\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.6548837117971611\n","Epoch: 095, Train Loss: 0.8858024, Train Acc: 0.5722222, Test Acc: 0.4500000\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.7124183006535947\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.6693513043897538\n","Epoch: 096, Train Loss: 0.8811729, Train Acc: 0.5944445, Test Acc: 0.4166667\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.49019607843137253\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.6388140161725068\n","Average auc 0.6489297709965223\n","Epoch: 097, Train Loss: 0.8787037, Train Acc: 0.6055555, Test Acc: 0.4000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.5816993464052288\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.6475962348405665\n","Epoch: 098, Train Loss: 0.8858024, Train Acc: 0.5907407, Test Acc: 0.4333334\n","AUC of 0is: 0.5\n","AUC of 1is: 0.59375\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.6470588235294117\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.72911051212938\n","Average auc 0.6668727055078528\n","Epoch: 099, Train Loss: 0.8879630, Train Acc: 0.5888889, Test Acc: 0.4500000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.65625\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.5359477124183007\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7102425876010782\n","Average auc 0.6615012768715995\n","Epoch: 100, Train Loss: 0.8814815, Train Acc: 0.5814815, Test Acc: 0.4333334\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.7124183006535947\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.6692670725838239\n","Epoch: 101, Train Loss: 0.8830247, Train Acc: 0.6092592, Test Acc: 0.4500000\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.667240737940952\n","Epoch: 102, Train Loss: 0.8839506, Train Acc: 0.6092592, Test Acc: 0.5166667\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.6482479784366577\n","Average auc 0.6761693093695235\n","Epoch: 103, Train Loss: 0.8879629, Train Acc: 0.6000000, Test Acc: 0.4666667\n","AUC of 0is: 0.5718954248366014\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.6830065359477124\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.6930850802739181\n","Epoch: 104, Train Loss: 0.8824074, Train Acc: 0.5925926, Test Acc: 0.4500000\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.6671565061350221\n","Epoch: 105, Train Loss: 0.8898148, Train Acc: 0.6000000, Test Acc: 0.4000000\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.5625\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.5816993464052288\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.6482479784366577\n","Average auc 0.6416332435834576\n","Epoch: 106, Train Loss: 0.8851852, Train Acc: 0.5962963, Test Acc: 0.4166667\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.59375\n","AUC of 2is: 0.8432282003710575\n","AUC of 3is: 0.5359477124183007\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.6553519546498577\n","Epoch: 107, Train Loss: 0.8876543, Train Acc: 0.6222222, Test Acc: 0.4333334\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.5915032679738562\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.6596154656097973\n","Epoch: 108, Train Loss: 0.8910494, Train Acc: 0.6296296, Test Acc: 0.5000000\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.65625\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.6830065359477124\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.6903765414076378\n","Epoch: 109, Train Loss: 0.8848765, Train Acc: 0.6148148, Test Acc: 0.5166667\n","AUC of 0is: 0.5555555555555556\n","AUC of 1is: 0.6875\n","AUC of 2is: 0.8534322820037106\n","AUC of 3is: 0.6470588235294117\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7052340537158993\n","Epoch: 110, Train Loss: 0.8839506, Train Acc: 0.6277778, Test Acc: 0.5500000\n","AUC of 0is: 0.5816993464052288\n","AUC of 1is: 0.6875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6830065359477124\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7231583951696526\n","Epoch: 111, Train Loss: 0.8867283, Train Acc: 0.6203704, Test Acc: 0.5000000\n","AUC of 0is: 0.5555555555555556\n","AUC of 1is: 0.71875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.72911051212938\n","Average auc 0.6924904020814319\n","Epoch: 112, Train Loss: 0.8864198, Train Acc: 0.6296296, Test Acc: 0.5166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.65625\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7722371967654987\n","Average auc 0.6997096056796589\n","Epoch: 113, Train Loss: 0.8882716, Train Acc: 0.6407408, Test Acc: 0.5333334\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.65625\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7287581699346405\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.728843308023683\n","Epoch: 114, Train Loss: 0.8925925, Train Acc: 0.6388889, Test Acc: 0.5166667\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.6875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6013071895424837\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7722371967654987\n","Average auc 0.6863994204944737\n","Epoch: 115, Train Loss: 0.8888890, Train Acc: 0.6444444, Test Acc: 0.5333334\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.6875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7287581699346405\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7139607957944727\n","Epoch: 116, Train Loss: 0.8941358, Train Acc: 0.6555555, Test Acc: 0.5166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.6875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6470588235294117\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.697231006797758\n","Epoch: 117, Train Loss: 0.8904321, Train Acc: 0.6611111, Test Acc: 0.4833333\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.65625\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.5816993464052288\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.6870540193361068\n","Epoch: 118, Train Loss: 0.8941358, Train Acc: 0.6462963, Test Acc: 0.5333334\n","AUC of 0is: 0.5359477124183007\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6470588235294117\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.7101174214426355\n","Epoch: 119, Train Loss: 0.8990740, Train Acc: 0.6462963, Test Acc: 0.5000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.6875\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.5915032679738562\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.6894459584129792\n","Epoch: 120, Train Loss: 0.8984569, Train Acc: 0.6666666, Test Acc: 0.5333334\n","AUC of 0is: 0.5718954248366014\n","AUC of 1is: 0.65625\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.714805407748269\n","Epoch: 121, Train Loss: 0.8898147, Train Acc: 0.6759259, Test Acc: 0.5166667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.5816993464052288\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.72911051212938\n","Average auc 0.6879943194603494\n","Epoch: 122, Train Loss: 0.9006173, Train Acc: 0.6537037, Test Acc: 0.5166667\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.6875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6568627450980391\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7628032345013478\n","Average auc 0.703345611968967\n","Epoch: 123, Train Loss: 0.8956790, Train Acc: 0.6870371, Test Acc: 0.5666667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.6057692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7116369395062713\n","Epoch: 124, Train Loss: 0.8907408, Train Acc: 0.6592593, Test Acc: 0.4833333\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.625\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6568627450980391\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.6976761634929147\n","Epoch: 125, Train Loss: 0.9006173, Train Acc: 0.6851852, Test Acc: 0.4833333\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.625\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6470588235294117\n","AUC of 4is: 0.6586538461538461\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7036686346629665\n","Epoch: 126, Train Loss: 0.8947530, Train Acc: 0.6777778, Test Acc: 0.5666667\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.5816993464052288\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7296788785040925\n","Epoch: 127, Train Loss: 0.8969136, Train Acc: 0.6925926, Test Acc: 0.5500000\n","AUC of 0is: 0.5555555555555556\n","AUC of 1is: 0.71875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6830065359477124\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.720834538881451\n","Epoch: 128, Train Loss: 0.8978395, Train Acc: 0.6722222, Test Acc: 0.5333334\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.6875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6470588235294117\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7172904295347613\n","Epoch: 129, Train Loss: 0.9077160, Train Acc: 0.7018518, Test Acc: 0.5666667\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7722371967654987\n","Average auc 0.7229598780108136\n","Epoch: 130, Train Loss: 0.8993827, Train Acc: 0.6962963, Test Acc: 0.5333334\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.6875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7052937706873811\n","Epoch: 131, Train Loss: 0.8996913, Train Acc: 0.6870371, Test Acc: 0.5333334\n","AUC of 0is: 0.5\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6470588235294117\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.6765498652291105\n","Average auc 0.6901274578310015\n","Epoch: 132, Train Loss: 0.8984568, Train Acc: 0.7129629, Test Acc: 0.5833334\n","AUC of 0is: 0.5359477124183007\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7244628800340708\n","Epoch: 133, Train Loss: 0.8978395, Train Acc: 0.6888888, Test Acc: 0.4666667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.6875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.5718954248366014\n","AUC of 4is: 0.6153846153846153\n","AUC of 5is: 0.7722371967654987\n","Average auc 0.674317344074162\n","Epoch: 134, Train Loss: 0.9024692, Train Acc: 0.7037037, Test Acc: 0.5666667\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6470588235294117\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.714199770194102\n","Epoch: 135, Train Loss: 0.9061729, Train Acc: 0.7111111, Test Acc: 0.5666667\n","AUC of 0is: 0.5\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.6586538461538461\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7136703816930153\n","Epoch: 136, Train Loss: 0.9012346, Train Acc: 0.7055556, Test Acc: 0.5500000\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.71875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6470588235294117\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7208961987655305\n","Epoch: 137, Train Loss: 0.9043210, Train Acc: 0.7333333, Test Acc: 0.5666667\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6830065359477124\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7244088852866798\n","Epoch: 138, Train Loss: 0.9058642, Train Acc: 0.7203704, Test Acc: 0.5500000\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.71875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7100029525781667\n","Epoch: 139, Train Loss: 0.9089506, Train Acc: 0.7222222, Test Acc: 0.6000000\n","AUC of 0is: 0.6666666666666666\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.738562091503268\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7502991125677229\n","Epoch: 140, Train Loss: 0.9033950, Train Acc: 0.7351851, Test Acc: 0.5666667\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.71875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7280763144015285\n","Epoch: 141, Train Loss: 0.9083333, Train Acc: 0.7333333, Test Acc: 0.5833334\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.738562091503268\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7341672959884868\n","Epoch: 142, Train Loss: 0.9058642, Train Acc: 0.7351851, Test Acc: 0.5666667\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7168138500140641\n","Epoch: 143, Train Loss: 0.9043211, Train Acc: 0.7333333, Test Acc: 0.5666667\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.5915032679738562\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7204498563033722\n","Epoch: 144, Train Loss: 0.9080247, Train Acc: 0.7462963, Test Acc: 0.5666667\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7261045320988638\n","Epoch: 145, Train Loss: 0.9104939, Train Acc: 0.7351851, Test Acc: 0.5500000\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.5915032679738562\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7040644761555059\n","Epoch: 146, Train Loss: 0.9024691, Train Acc: 0.7500000, Test Acc: 0.5333334\n","AUC of 0is: 0.49019607843137253\n","AUC of 1is: 0.71875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.7008581621833763\n","Epoch: 147, Train Loss: 0.9083334, Train Acc: 0.7500000, Test Acc: 0.6000000\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7124183006535947\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7346034112102567\n","Epoch: 148, Train Loss: 0.9123456, Train Acc: 0.7500000, Test Acc: 0.6000000\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7394058663803591\n","Epoch: 149, Train Loss: 0.9086420, Train Acc: 0.7314815, Test Acc: 0.5666667\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6470588235294117\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7722371967654987\n","Average auc 0.7229598780108136\n","Epoch: 150, Train Loss: 0.9089506, Train Acc: 0.7777778, Test Acc: 0.6000000\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.7362926351178493\n","Epoch: 151, Train Loss: 0.9222222, Train Acc: 0.7629629, Test Acc: 0.5833334\n","AUC of 0is: 0.6111111111111112\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7425454870084844\n","Epoch: 152, Train Loss: 0.9126543, Train Acc: 0.7685185, Test Acc: 0.6166667\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7570417366452528\n","Epoch: 153, Train Loss: 0.9111111, Train Acc: 0.7203704, Test Acc: 0.5166667\n","AUC of 0is: 0.562091503267974\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.6671159029649596\n","Average auc 0.708131551098691\n","Epoch: 154, Train Loss: 0.9172840, Train Acc: 0.7759259, Test Acc: 0.6166667\n","AUC of 0is: 0.6111111111111112\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.738562091503268\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7550082944585085\n","Epoch: 155, Train Loss: 0.9058641, Train Acc: 0.7611111, Test Acc: 0.5333334\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7102425876010782\n","Average auc 0.7125960203245363\n","Epoch: 156, Train Loss: 0.9148148, Train Acc: 0.7740741, Test Acc: 0.6000000\n","AUC of 0is: 0.6666666666666666\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6830065359477124\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7498237188140272\n","Epoch: 157, Train Loss: 0.9135802, Train Acc: 0.7555556, Test Acc: 0.5666667\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.605121293800539\n","Average auc 0.7079408331811416\n","Epoch: 158, Train Loss: 0.9166667, Train Acc: 0.7962963, Test Acc: 0.6333334\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7513882466167626\n","Epoch: 159, Train Loss: 0.9126543, Train Acc: 0.7759259, Test Acc: 0.5666667\n","AUC of 0is: 0.6372549019607843\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.6765498652291105\n","Average auc 0.7350961397482129\n","Epoch: 160, Train Loss: 0.9169754, Train Acc: 0.7796296, Test Acc: 0.5666667\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.6293800539083558\n","Average auc 0.7119839598657777\n","Epoch: 161, Train Loss: 0.9148148, Train Acc: 0.7944444, Test Acc: 0.6166667\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.6576819407008087\n","Average auc 0.747270113111143\n","Epoch: 162, Train Loss: 0.9179013, Train Acc: 0.7814814, Test Acc: 0.6333334\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.7483432887126206\n","Epoch: 163, Train Loss: 0.9212963, Train Acc: 0.7944444, Test Acc: 0.6166667\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.7438512141049994\n","Epoch: 164, Train Loss: 0.9166667, Train Acc: 0.7907407, Test Acc: 0.5833334\n","AUC of 0is: 0.4803921568627451\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.6482479784366577\n","Average auc 0.7054241979994121\n","Epoch: 165, Train Loss: 0.9120370, Train Acc: 0.8055555, Test Acc: 0.6500000\n","AUC of 0is: 0.5359477124183007\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7565189616184543\n","Epoch: 166, Train Loss: 0.9222222, Train Acc: 0.8037037, Test Acc: 0.6333334\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7498539558725662\n","Epoch: 167, Train Loss: 0.9228395, Train Acc: 0.7962963, Test Acc: 0.6000000\n","AUC of 0is: 0.6666666666666666\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.6671159029649596\n","Average auc 0.7343748475625755\n","Epoch: 168, Train Loss: 0.9194444, Train Acc: 0.7814814, Test Acc: 0.5666667\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7152955177174299\n","Epoch: 169, Train Loss: 0.9197531, Train Acc: 0.8129629, Test Acc: 0.6333334\n","AUC of 0is: 0.6111111111111112\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7577694517354816\n","Epoch: 170, Train Loss: 0.9138889, Train Acc: 0.8000000, Test Acc: 0.5666667\n","AUC of 0is: 0.6111111111111112\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6568627450980391\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7346110763469452\n","Epoch: 171, Train Loss: 0.9172840, Train Acc: 0.7814814, Test Acc: 0.5833334\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.71875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7388764778792725\n","Epoch: 172, Train Loss: 0.9225309, Train Acc: 0.8277777, Test Acc: 0.6333334\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7561668876329174\n","Epoch: 173, Train Loss: 0.9216049, Train Acc: 0.7962963, Test Acc: 0.6166667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.738562091503268\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.6671159029649596\n","Average auc 0.7423379152682902\n","Epoch: 174, Train Loss: 0.9250000, Train Acc: 0.8203704, Test Acc: 0.6166667\n","AUC of 0is: 0.6111111111111112\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7494478871396385\n","Epoch: 175, Train Loss: 0.9277778, Train Acc: 0.8203704, Test Acc: 0.6000000\n","AUC of 0is: 0.5359477124183007\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.6859838274932615\n","Average auc 0.722575329537336\n","Epoch: 176, Train Loss: 0.9237654, Train Acc: 0.8333333, Test Acc: 0.6000000\n","AUC of 0is: 0.5261437908496732\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7722371967654987\n","Average auc 0.7372886864572689\n","Epoch: 177, Train Loss: 0.9296296, Train Acc: 0.8111111, Test Acc: 0.6166667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.6859838274932615\n","Average auc 0.7543726104154994\n","Epoch: 178, Train Loss: 0.9188272, Train Acc: 0.8259259, Test Acc: 0.6166667\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7941176470588235\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.72911051212938\n","Average auc 0.741439308567103\n","Epoch: 179, Train Loss: 0.9216049, Train Acc: 0.8129629, Test Acc: 0.6166667\n","AUC of 0is: 0.5359477124183007\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.7410558117560259\n","Epoch: 180, Train Loss: 0.9237654, Train Acc: 0.8314815, Test Acc: 0.6333334\n","AUC of 0is: 0.6111111111111112\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7610259692271741\n","Epoch: 181, Train Loss: 0.9228395, Train Acc: 0.8314815, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.7728845154597295\n","Epoch: 182, Train Loss: 0.9324074, Train Acc: 0.8333333, Test Acc: 0.6166667\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7102425876010782\n","Average auc 0.7494590026969723\n","Epoch: 183, Train Loss: 0.9237654, Train Acc: 0.8314815, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.6671159029649596\n","Average auc 0.7785920002356105\n","Epoch: 184, Train Loss: 0.9271605, Train Acc: 0.8370370, Test Acc: 0.6333334\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7554391725426886\n","Epoch: 185, Train Loss: 0.9222223, Train Acc: 0.8259259, Test Acc: 0.5833334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.738562091503268\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.6671159029649596\n","Average auc 0.7444170588915515\n","Epoch: 186, Train Loss: 0.9290123, Train Acc: 0.8518518, Test Acc: 0.6500000\n","AUC of 0is: 0.5555555555555556\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7574123989218329\n","Average auc 0.7530300327861569\n","Epoch: 187, Train Loss: 0.9225309, Train Acc: 0.8296296, Test Acc: 0.6500000\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7694456499925622\n","Epoch: 188, Train Loss: 0.9228395, Train Acc: 0.8703703, Test Acc: 0.6500000\n","AUC of 0is: 0.5359477124183007\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7518257381752308\n","Epoch: 189, Train Loss: 0.9305556, Train Acc: 0.8592592, Test Acc: 0.6333334\n","AUC of 0is: 0.545751633986928\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7406261194388474\n","Epoch: 190, Train Loss: 0.9311729, Train Acc: 0.8666667, Test Acc: 0.6500000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7941176470588235\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.7670700636106137\n","Epoch: 191, Train Loss: 0.9311729, Train Acc: 0.8555555, Test Acc: 0.6500000\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.7594447912794591\n","Epoch: 192, Train Loss: 0.9342593, Train Acc: 0.8555555, Test Acc: 0.6333334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.6954177897574124\n","Average auc 0.759582129515834\n","Epoch: 193, Train Loss: 0.9274691, Train Acc: 0.8574074, Test Acc: 0.6500000\n","AUC of 0is: 0.5555555555555556\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7593720158380456\n","Epoch: 194, Train Loss: 0.9317901, Train Acc: 0.8388889, Test Acc: 0.6166667\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.6859838274932615\n","Average auc 0.7318345887965955\n","Epoch: 195, Train Loss: 0.9290124, Train Acc: 0.8592592, Test Acc: 0.6000000\n","AUC of 0is: 0.5\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.732531932723684\n","Epoch: 196, Train Loss: 0.9317902, Train Acc: 0.8648148, Test Acc: 0.6166667\n","AUC of 0is: 0.5359477124183007\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7400653081122203\n","Epoch: 197, Train Loss: 0.9333334, Train Acc: 0.8740740, Test Acc: 0.6333334\n","AUC of 0is: 0.6666666666666666\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7683801395277731\n","Epoch: 198, Train Loss: 0.9348765, Train Acc: 0.8500000, Test Acc: 0.6500000\n","AUC of 0is: 0.6372549019607843\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7738960311771276\n","Epoch: 199, Train Loss: 0.9345679, Train Acc: 0.8777778, Test Acc: 0.6333334\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7554391725426886\n","Epoch: 200, Train Loss: 0.9317902, Train Acc: 0.8685185, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.7619912692723657\n","Epoch: 201, Train Loss: 0.9311729, Train Acc: 0.8648148, Test Acc: 0.6166667\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7679738562091504\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.7668932300566794\n","Epoch: 202, Train Loss: 0.9290123, Train Acc: 0.8759259, Test Acc: 0.6666667\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7828400669836771\n","Epoch: 203, Train Loss: 0.9327160, Train Acc: 0.8722222, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7722371967654987\n","Average auc 0.7816446232764411\n","Epoch: 204, Train Loss: 0.9367284, Train Acc: 0.8759259, Test Acc: 0.6500000\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7559383239852361\n","Epoch: 205, Train Loss: 0.9373456, Train Acc: 0.8722222, Test Acc: 0.6166667\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7722371967654987\n","Average auc 0.7647286688604867\n","Epoch: 206, Train Loss: 0.9351851, Train Acc: 0.8759259, Test Acc: 0.6500000\n","AUC of 0is: 0.6111111111111112\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7731747389914903\n","Epoch: 207, Train Loss: 0.9271604, Train Acc: 0.8740740, Test Acc: 0.6833334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7574123989218329\n","Average auc 0.7876187079998321\n","Epoch: 208, Train Loss: 0.9364198, Train Acc: 0.8666667, Test Acc: 0.6166667\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7738909977172025\n","Epoch: 209, Train Loss: 0.9376543, Train Acc: 0.8796296, Test Acc: 0.6500000\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7719782436218537\n","Epoch: 210, Train Loss: 0.9361111, Train Acc: 0.8851852, Test Acc: 0.6166667\n","AUC of 0is: 0.5359477124183007\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7509271314740437\n","Epoch: 211, Train Loss: 0.9345679, Train Acc: 0.8888889, Test Acc: 0.6166667\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.6682692307692307\n","AUC of 5is: 0.6765498652291105\n","Average auc 0.7399981005325266\n","Epoch: 212, Train Loss: 0.9290124, Train Acc: 0.8833333, Test Acc: 0.5833334\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6470588235294117\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7722371967654987\n","Average auc 0.7369508910827091\n","Epoch: 213, Train Loss: 0.9385803, Train Acc: 0.9018518, Test Acc: 0.6500000\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.6859838274932615\n","Average auc 0.7571640047510112\n","Epoch: 214, Train Loss: 0.9364198, Train Acc: 0.8777778, Test Acc: 0.6333334\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.6671159029649596\n","Average auc 0.7423026447498264\n","Epoch: 215, Train Loss: 0.9327160, Train Acc: 0.8648148, Test Acc: 0.6166667\n","AUC of 0is: 0.5816993464052288\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7481583090603823\n","Epoch: 216, Train Loss: 0.9330248, Train Acc: 0.9018518, Test Acc: 0.6333334\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.701923076923077\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7503162567822866\n","Epoch: 217, Train Loss: 0.9330247, Train Acc: 0.8907408, Test Acc: 0.6500000\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7607169650013911\n","Epoch: 218, Train Loss: 0.9385803, Train Acc: 0.8777778, Test Acc: 0.6166667\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7775952773648785\n","Epoch: 219, Train Loss: 0.9438272, Train Acc: 0.9129630, Test Acc: 0.6500000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7760908294318591\n","Epoch: 220, Train Loss: 0.9450617, Train Acc: 0.8870370, Test Acc: 0.6333334\n","AUC of 0is: 0.6928104575163399\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7830936305523073\n","Epoch: 221, Train Loss: 0.9314816, Train Acc: 0.9055555, Test Acc: 0.6833334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7932039246699544\n","Epoch: 222, Train Loss: 0.9472222, Train Acc: 0.8981481, Test Acc: 0.6666667\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7838767862996893\n","Epoch: 223, Train Loss: 0.9419753, Train Acc: 0.8925925, Test Acc: 0.6333334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.6671159029649596\n","Average auc 0.7524482093859373\n","Epoch: 224, Train Loss: 0.9416667, Train Acc: 0.9055555, Test Acc: 0.6666667\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7964090528750827\n","Epoch: 225, Train Loss: 0.9401234, Train Acc: 0.8777778, Test Acc: 0.6500000\n","AUC of 0is: 0.6928104575163399\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7711888686475454\n","Epoch: 226, Train Loss: 0.9422839, Train Acc: 0.9055555, Test Acc: 0.6500000\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7869526527936825\n","Epoch: 227, Train Loss: 0.9404321, Train Acc: 0.8870370, Test Acc: 0.6833334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7829017268677566\n","Epoch: 228, Train Loss: 0.9422839, Train Acc: 0.9092593, Test Acc: 0.6833334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7839446654106951\n","Epoch: 229, Train Loss: 0.9438272, Train Acc: 0.9000000, Test Acc: 0.6666667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7828703040422162\n","Epoch: 230, Train Loss: 0.9456789, Train Acc: 0.9074074, Test Acc: 0.6500000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.78237233836667\n","Epoch: 231, Train Loss: 0.9475308, Train Acc: 0.9018518, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7828400669836774\n","Epoch: 232, Train Loss: 0.9475308, Train Acc: 0.9185185, Test Acc: 0.6500000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7916315976259293\n","Epoch: 233, Train Loss: 0.9422839, Train Acc: 0.9092593, Test Acc: 0.5833334\n","AUC of 0is: 0.6928104575163399\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7543043370571315\n","Epoch: 234, Train Loss: 0.9481481, Train Acc: 0.8907408, Test Acc: 0.6166667\n","AUC of 0is: 0.7483660130718954\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7683410515655442\n","Epoch: 235, Train Loss: 0.9490740, Train Acc: 0.9148148, Test Acc: 0.6333334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7607169650013911\n","Epoch: 236, Train Loss: 0.9487654, Train Acc: 0.9129630, Test Acc: 0.6166667\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7554089354841497\n","Epoch: 237, Train Loss: 0.9466049, Train Acc: 0.9074074, Test Acc: 0.6500000\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7558099707571523\n","Epoch: 238, Train Loss: 0.9515432, Train Acc: 0.9240741, Test Acc: 0.6833334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.7870276596146661\n","Epoch: 239, Train Loss: 0.9469136, Train Acc: 0.9166666, Test Acc: 0.6166667\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7534899621618744\n","Epoch: 240, Train Loss: 0.9432099, Train Acc: 0.9185185, Test Acc: 0.6500000\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7895981554391853\n","Epoch: 241, Train Loss: 0.9478395, Train Acc: 0.9351852, Test Acc: 0.6166667\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7607169650013911\n","Epoch: 242, Train Loss: 0.9441358, Train Acc: 0.9333333, Test Acc: 0.6333334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.6765498652291105\n","Average auc 0.7632797956892216\n","Epoch: 243, Train Loss: 0.9459876, Train Acc: 0.9259259, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7722371967654987\n","Average auc 0.7868529566097745\n","Epoch: 244, Train Loss: 0.9515433, Train Acc: 0.9296296, Test Acc: 0.6666667\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7668463611859838\n","Average auc 0.780679457335851\n","Epoch: 245, Train Loss: 0.9487654, Train Acc: 0.9351852, Test Acc: 0.6500000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7879339314525416\n","Epoch: 246, Train Loss: 0.9469136, Train Acc: 0.9314815, Test Acc: 0.6666667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.785455332570641\n","Epoch: 247, Train Loss: 0.9490740, Train Acc: 0.9296296, Test Acc: 0.6666667\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7972850876544193\n","Epoch: 248, Train Loss: 0.9469136, Train Acc: 0.9351852, Test Acc: 0.6500000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7770709223237168\n","Epoch: 249, Train Loss: 0.9462963, Train Acc: 0.9203703, Test Acc: 0.6333334\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7602166277918418\n","Epoch: 250, Train Loss: 0.9478396, Train Acc: 0.9351852, Test Acc: 0.6500000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7746237462673565\n","Epoch: 251, Train Loss: 0.9469136, Train Acc: 0.9351852, Test Acc: 0.6833334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7963788158165438\n","Epoch: 252, Train Loss: 0.9512346, Train Acc: 0.9129630, Test Acc: 0.6166667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.7527320100131064\n","Epoch: 253, Train Loss: 0.9453704, Train Acc: 0.9259259, Test Acc: 0.6333334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.7698863636363636\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7556481344608624\n","Epoch: 254, Train Loss: 0.9506173, Train Acc: 0.9333333, Test Acc: 0.6166667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7522720806373892\n","Epoch: 255, Train Loss: 0.9512346, Train Acc: 0.9351852, Test Acc: 0.6500000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7755602551637711\n","Epoch: 256, Train Loss: 0.9472222, Train Acc: 0.9333333, Test Acc: 0.6166667\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7695073098766416\n","Epoch: 257, Train Loss: 0.9543210, Train Acc: 0.9425926, Test Acc: 0.6833334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7979511428605689\n","Epoch: 258, Train Loss: 0.9608026, Train Acc: 0.9277778, Test Acc: 0.6833334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.787057896673205\n","Epoch: 259, Train Loss: 0.9500000, Train Acc: 0.9314815, Test Acc: 0.6500000\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7818131070544063\n","Epoch: 260, Train Loss: 0.9555556, Train Acc: 0.9518518, Test Acc: 0.6166667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.768590767441251\n","Epoch: 261, Train Loss: 0.9472222, Train Acc: 0.9407407, Test Acc: 0.6666667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7719782436218537\n","Epoch: 262, Train Loss: 0.9524692, Train Acc: 0.9537037, Test Acc: 0.6500000\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7645398415153251\n","Epoch: 263, Train Loss: 0.9493827, Train Acc: 0.9296296, Test Acc: 0.6833334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7887221206598486\n","Epoch: 264, Train Loss: 0.9577159, Train Acc: 0.9462963, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7722570107890979\n","Epoch: 265, Train Loss: 0.9543210, Train Acc: 0.9388888, Test Acc: 0.6333334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7771337679747977\n","Epoch: 266, Train Loss: 0.9540124, Train Acc: 0.9407407, Test Acc: 0.6333334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7735884728611064\n","Epoch: 267, Train Loss: 0.9506173, Train Acc: 0.9592593, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7703216847718989\n","Epoch: 268, Train Loss: 0.9475309, Train Acc: 0.9462963, Test Acc: 0.6166667\n","AUC of 0is: 0.5816993464052288\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.6859838274932615\n","Average auc 0.7471165562844452\n","Epoch: 269, Train Loss: 0.9481481, Train Acc: 0.9240741, Test Acc: 0.6333334\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7626649896152037\n","Epoch: 270, Train Loss: 0.9570988, Train Acc: 0.9574074, Test Acc: 0.6333334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7647981279858559\n","Epoch: 271, Train Loss: 0.9561729, Train Acc: 0.9555556, Test Acc: 0.6000000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7594900984686145\n","Epoch: 272, Train Loss: 0.9472222, Train Acc: 0.9481481, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7703519218304379\n","Epoch: 273, Train Loss: 0.9564815, Train Acc: 0.9574074, Test Acc: 0.6333334\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.6954177897574124\n","Average auc 0.7450164207536968\n","Epoch: 274, Train Loss: 0.9555556, Train Acc: 0.9333333, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7718940118159239\n","Epoch: 275, Train Loss: 0.9614198, Train Acc: 0.9444444, Test Acc: 0.6833334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7574123989218329\n","Average auc 0.7876187079998321\n","Epoch: 276, Train Loss: 0.9503087, Train Acc: 0.9481481, Test Acc: 0.6333334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7722371967654987\n","Average auc 0.768811017611953\n","Epoch: 277, Train Loss: 0.9533951, Train Acc: 0.9351852, Test Acc: 0.6666667\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7834835502679763\n","Epoch: 278, Train Loss: 0.9620371, Train Acc: 0.9555556, Test Acc: 0.6666667\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7679047457740774\n","Epoch: 279, Train Loss: 0.9586420, Train Acc: 0.9592593, Test Acc: 0.6500000\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7776933935344233\n","Epoch: 280, Train Loss: 0.9583333, Train Acc: 0.9722222, Test Acc: 0.6666667\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7678128488314592\n","Epoch: 281, Train Loss: 0.9580246, Train Acc: 0.9462963, Test Acc: 0.6166667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7610321884541006\n","Epoch: 282, Train Loss: 0.9533951, Train Acc: 0.9685185, Test Acc: 0.6333334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7726519639646919\n","Epoch: 283, Train Loss: 0.9577160, Train Acc: 0.9648148, Test Acc: 0.6500000\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7710493998621278\n","Epoch: 284, Train Loss: 0.9577160, Train Acc: 0.9648148, Test Acc: 0.6666667\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7746854061514359\n","Epoch: 285, Train Loss: 0.9580246, Train Acc: 0.9537037, Test Acc: 0.6166667\n","AUC of 0is: 0.6928104575163399\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7770709223237168\n","Epoch: 286, Train Loss: 0.9583333, Train Acc: 0.9685185, Test Acc: 0.6333334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7803388961799259\n","Epoch: 287, Train Loss: 0.9546296, Train Acc: 0.9703704, Test Acc: 0.6833334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7761960733113816\n","Epoch: 288, Train Loss: 0.9555556, Train Acc: 0.9685185, Test Acc: 0.6500000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.738562091503268\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7770709223237168\n","Epoch: 289, Train Loss: 0.9632716, Train Acc: 0.9592593, Test Acc: 0.6666667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7834521274424359\n","Epoch: 290, Train Loss: 0.9577159, Train Acc: 0.9629629, Test Acc: 0.6166667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.71875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7589987462673565\n","Epoch: 291, Train Loss: 0.9632716, Train Acc: 0.9629629, Test Acc: 0.6500000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7819112232239512\n","Epoch: 292, Train Loss: 0.9589506, Train Acc: 0.9648148, Test Acc: 0.6500000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7771640050333367\n","Epoch: 293, Train Loss: 0.9623457, Train Acc: 0.9648148, Test Acc: 0.6333334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7575106510292612\n","Epoch: 294, Train Loss: 0.9638889, Train Acc: 0.9555556, Test Acc: 0.6000000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7667020311775148\n","Epoch: 295, Train Loss: 0.9620370, Train Acc: 0.9685185, Test Acc: 0.6500000\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.7649033718653784\n","Epoch: 296, Train Loss: 0.9586419, Train Acc: 0.9592593, Test Acc: 0.6166667\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.701923076923077\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7631272905249241\n","Epoch: 297, Train Loss: 0.9626544, Train Acc: 0.9814815, Test Acc: 0.6666667\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7679035600070759\n","Epoch: 298, Train Loss: 0.9638889, Train Acc: 0.9703704, Test Acc: 0.6333334\n","AUC of 0is: 0.5359477124183007\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7400653081122203\n","Epoch: 299, Train Loss: 0.9598766, Train Acc: 0.9777778, Test Acc: 0.6833334\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7678128488314592\n","Epoch: 300, Train Loss: 0.9586420, Train Acc: 0.9592593, Test Acc: 0.6333334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.701923076923077\n","AUC of 5is: 0.6765498652291105\n","Average auc 0.7548663341507602\n","Epoch: 301, Train Loss: 0.9608026, Train Acc: 0.9703704, Test Acc: 0.6166667\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7646317384579433\n","Epoch: 302, Train Loss: 0.9614198, Train Acc: 0.9574074, Test Acc: 0.6666667\n","AUC of 0is: 0.8235294117647057\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7972548505958804\n","Epoch: 303, Train Loss: 0.9666666, Train Acc: 0.9685185, Test Acc: 0.6166667\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7591446379573658\n","Epoch: 304, Train Loss: 0.9657407, Train Acc: 0.9629629, Test Acc: 0.6333334\n","AUC of 0is: 0.6928104575163399\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7754985952796917\n","Epoch: 305, Train Loss: 0.9608026, Train Acc: 0.9814815, Test Acc: 0.6166667\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.6859838274932615\n","Average auc 0.7673004845566087\n","Epoch: 306, Train Loss: 0.9626544, Train Acc: 0.9796296, Test Acc: 0.6333334\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7811846939007238\n","Epoch: 307, Train Loss: 0.9626543, Train Acc: 0.9648148, Test Acc: 0.6166667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7662405217874341\n","Epoch: 308, Train Loss: 0.9592593, Train Acc: 0.9703704, Test Acc: 0.6166667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7559080869266972\n","Epoch: 309, Train Loss: 0.9672840, Train Acc: 0.9814815, Test Acc: 0.6000000\n","AUC of 0is: 0.6013071895424837\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.701923076923077\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7502320249763567\n","Epoch: 310, Train Loss: 0.9608026, Train Acc: 0.9685185, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7683724743910848\n","Epoch: 311, Train Loss: 0.9608026, Train Acc: 0.9759259, Test Acc: 0.6166667\n","AUC of 0is: 0.5816993464052288\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7461182533993499\n","Epoch: 312, Train Loss: 0.9722222, Train Acc: 0.9740741, Test Acc: 0.6166667\n","AUC of 0is: 0.5915032679738562\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7491962141433959\n","Epoch: 313, Train Loss: 0.9682099, Train Acc: 0.9648148, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7801174602422224\n","Epoch: 314, Train Loss: 0.9654320, Train Acc: 0.9796296, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.701923076923077\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7662102847288951\n","Epoch: 315, Train Loss: 0.9654322, Train Acc: 0.9740741, Test Acc: 0.6500000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7835137873265152\n","Epoch: 316, Train Loss: 0.9669753, Train Acc: 0.9703704, Test Acc: 0.6166667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.71875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7589370863832771\n","Epoch: 317, Train Loss: 0.9651234, Train Acc: 0.9685185, Test Acc: 0.6333334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7623195291039552\n","Epoch: 318, Train Loss: 0.9675926, Train Acc: 0.9833333, Test Acc: 0.6500000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.780308659121387\n","Epoch: 319, Train Loss: 0.9669753, Train Acc: 0.9796296, Test Acc: 0.6333334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7803388961799259\n","Epoch: 320, Train Loss: 0.9648148, Train Acc: 0.9777778, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7802772362958467\n","Epoch: 321, Train Loss: 0.9641976, Train Acc: 0.9759259, Test Acc: 0.6166667\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7941176470588235\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.6671159029649596\n","Average auc 0.7564362896607824\n","Epoch: 322, Train Loss: 0.9645061, Train Acc: 0.9777778, Test Acc: 0.6333334\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7644230769230769\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7864470219814481\n","Epoch: 323, Train Loss: 0.9675926, Train Acc: 0.9814815, Test Acc: 0.6500000\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7941176470588235\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7785451331981972\n","Epoch: 324, Train Loss: 0.9694445, Train Acc: 0.9796296, Test Acc: 0.6500000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7785765560237378\n","Epoch: 325, Train Loss: 0.9712963, Train Acc: 0.9814815, Test Acc: 0.6500000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.778673486426281\n","Epoch: 326, Train Loss: 0.9660494, Train Acc: 0.9796296, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7679738562091504\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7895679183806464\n","Epoch: 327, Train Loss: 0.9669753, Train Acc: 0.9851851, Test Acc: 0.6666667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7802458134703061\n","Epoch: 328, Train Loss: 0.9641976, Train Acc: 0.9851851, Test Acc: 0.6500000\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7710493998621278\n","Epoch: 329, Train Loss: 0.9651235, Train Acc: 0.9759259, Test Acc: 0.6166667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7124183006535947\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7786079788492781\n","Epoch: 330, Train Loss: 0.9626543, Train Acc: 0.9833333, Test Acc: 0.6000000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7609026494590153\n","Epoch: 331, Train Loss: 0.9688272, Train Acc: 0.9833333, Test Acc: 0.6333334\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.701923076923077\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.7802481850043091\n","Epoch: 332, Train Loss: 0.9685185, Train Acc: 0.9796296, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7719544859330019\n","Epoch: 333, Train Loss: 0.9679012, Train Acc: 0.9796296, Test Acc: 0.6500000\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.738544474393531\n","Average auc 0.768403897216625\n","Epoch: 334, Train Loss: 0.9706790, Train Acc: 0.9888889, Test Acc: 0.6666667\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7927428095272355\n","Epoch: 335, Train Loss: 0.9688272, Train Acc: 0.9870370, Test Acc: 0.6500000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7803074733543856\n","Epoch: 336, Train Loss: 0.9734567, Train Acc: 0.9851851, Test Acc: 0.6666667\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7896660345501911\n","Epoch: 337, Train Loss: 0.9716051, Train Acc: 0.9814815, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7755300181052323\n","Epoch: 338, Train Loss: 0.9716049, Train Acc: 0.9814815, Test Acc: 0.6166667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7699750384936488\n","Epoch: 339, Train Loss: 0.9753087, Train Acc: 0.9833333, Test Acc: 0.6000000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.7576025479718798\n","Epoch: 340, Train Loss: 0.9657407, Train Acc: 0.9851851, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7803074733543856\n","Epoch: 341, Train Loss: 0.9734568, Train Acc: 0.9759259, Test Acc: 0.6666667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7911390596576701\n","Epoch: 342, Train Loss: 0.9703705, Train Acc: 0.9888889, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.701923076923077\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7771702242602632\n","Epoch: 343, Train Loss: 0.9660494, Train Acc: 0.9851851, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7911390596576701\n","Epoch: 344, Train Loss: 0.9685185, Train Acc: 0.9833333, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7803074733543856\n","Epoch: 345, Train Loss: 0.9691359, Train Acc: 0.9833333, Test Acc: 0.6000000\n","AUC of 0is: 0.5816993464052288\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.701923076923077\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7434122766367693\n","Epoch: 346, Train Loss: 0.9737655, Train Acc: 0.9851851, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7911390596576701\n","Epoch: 347, Train Loss: 0.9719136, Train Acc: 0.9851851, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7771023451492574\n","Epoch: 348, Train Loss: 0.9663581, Train Acc: 0.9777778, Test Acc: 0.6166667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7667396732299817\n","Epoch: 349, Train Loss: 0.9694445, Train Acc: 0.9759259, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.738544474393531\n","Average auc 0.779234297752908\n","Epoch: 350, Train Loss: 0.9740741, Train Acc: 0.9796296, Test Acc: 0.6333334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7803388961799259\n","Epoch: 351, Train Loss: 0.9679012, Train Acc: 0.9833333, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.701923076923077\n","AUC of 5is: 0.8382749326145553\n","Average auc 0.7987050436387483\n","Epoch: 352, Train Loss: 0.9682098, Train Acc: 0.9833333, Test Acc: 0.6666667\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.8004599788010086\n","Epoch: 353, Train Loss: 0.9709877, Train Acc: 0.9740741, Test Acc: 0.6166667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7124183006535947\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7725538477951471\n","Epoch: 354, Train Loss: 0.9688271, Train Acc: 0.9870370, Test Acc: 0.6666667\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.8003983189169293\n","Epoch: 355, Train Loss: 0.9679012, Train Acc: 0.9833333, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7955592037836965\n","Epoch: 356, Train Loss: 0.9641976, Train Acc: 0.9814815, Test Acc: 0.6500000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7754985952796917\n","Epoch: 357, Train Loss: 0.9666668, Train Acc: 0.9851851, Test Acc: 0.6333334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7607169650013911\n","Epoch: 358, Train Loss: 0.9697531, Train Acc: 0.9888889, Test Acc: 0.6833334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7818809861654121\n","Epoch: 359, Train Loss: 0.9746913, Train Acc: 0.9907407, Test Acc: 0.6666667\n","AUC of 0is: 0.6928104575163399\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7862697074658982\n","Epoch: 360, Train Loss: 0.9709877, Train Acc: 0.9870370, Test Acc: 0.6666667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7693537530499438\n","Epoch: 361, Train Loss: 0.9750000, Train Acc: 0.9796296, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7668463611859838\n","Average auc 0.7790140475822059\n","Epoch: 362, Train Loss: 0.9728395, Train Acc: 0.9796296, Test Acc: 0.6333334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7787665691359008\n","Epoch: 363, Train Loss: 0.9722223, Train Acc: 0.9833333, Test Acc: 0.6833334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7801174602422224\n","Epoch: 364, Train Loss: 0.9731481, Train Acc: 0.9888889, Test Acc: 0.6666667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7787049092518213\n","Epoch: 365, Train Loss: 0.9691359, Train Acc: 0.9833333, Test Acc: 0.6166667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.71875\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7655143867115685\n","Epoch: 366, Train Loss: 0.9734567, Train Acc: 0.9888889, Test Acc: 0.6833334\n","AUC of 0is: 0.6928104575163399\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.7910157398895111\n","Epoch: 367, Train Loss: 0.9725309, Train Acc: 0.9851851, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.777010448206639\n","Epoch: 368, Train Loss: 0.9793209, Train Acc: 0.9851851, Test Acc: 0.6666667\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7927113867016949\n","Epoch: 369, Train Loss: 0.9768518, Train Acc: 0.9888889, Test Acc: 0.6166667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7678128488314592\n","Epoch: 370, Train Loss: 0.9746914, Train Acc: 0.9814815, Test Acc: 0.6500000\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7787049092518213\n","Epoch: 371, Train Loss: 0.9697531, Train Acc: 0.9870370, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7695740032206458\n","Epoch: 372, Train Loss: 0.9750000, Train Acc: 0.9870370, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7574123989218329\n","Average auc 0.7589232020196622\n","Epoch: 373, Train Loss: 0.9756172, Train Acc: 0.9888889, Test Acc: 0.6500000\n","AUC of 0is: 0.6372549019607843\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7693839901084828\n","Epoch: 374, Train Loss: 0.9759259, Train Acc: 0.9907407, Test Acc: 0.6500000\n","AUC of 0is: 0.6928104575163399\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7709563171525079\n","Epoch: 375, Train Loss: 0.9722222, Train Acc: 0.9907407, Test Acc: 0.6833334\n","AUC of 0is: 0.7483660130718954\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.8004347752023945\n","Epoch: 376, Train Loss: 0.9762346, Train Acc: 0.9925926, Test Acc: 0.6833334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.793889946337128\n","Epoch: 377, Train Loss: 0.9737655, Train Acc: 0.9870370, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7883652037840836\n","Epoch: 378, Train Loss: 0.9725310, Train Acc: 0.9888889, Test Acc: 0.6333334\n","AUC of 0is: 0.8039215686274509\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7902892105662837\n","Epoch: 379, Train Loss: 0.9737654, Train Acc: 0.9870370, Test Acc: 0.6166667\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7656812904751703\n","Epoch: 380, Train Loss: 0.9740741, Train Acc: 0.9870370, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7574123989218329\n","Average auc 0.7715171284791351\n","Epoch: 381, Train Loss: 0.9790125, Train Acc: 0.9888889, Test Acc: 0.6333334\n","AUC of 0is: 0.5718954248366014\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7568869940515534\n","Epoch: 382, Train Loss: 0.9753085, Train Acc: 0.9907407, Test Acc: 0.6500000\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7727500801342367\n","Epoch: 383, Train Loss: 0.9808642, Train Acc: 0.9870370, Test Acc: 0.6500000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7783721473371862\n","Epoch: 384, Train Loss: 0.9762346, Train Acc: 0.9888889, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7852884288070391\n","Epoch: 385, Train Loss: 0.9808642, Train Acc: 0.9888889, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.798795754814365\n","Epoch: 386, Train Loss: 0.9756173, Train Acc: 0.9925926, Test Acc: 0.6333334\n","AUC of 0is: 0.7941176470588235\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.785293462266964\n","Epoch: 387, Train Loss: 0.9722222, Train Acc: 0.9907407, Test Acc: 0.6833334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7835502436119807\n","Epoch: 388, Train Loss: 0.9712963, Train Acc: 0.9833333, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.769285873938938\n","Epoch: 389, Train Loss: 0.9762346, Train Acc: 0.9944444, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7787727883628272\n","Epoch: 390, Train Loss: 0.9777778, Train Acc: 0.9888889, Test Acc: 0.6500000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7785765560237378\n","Epoch: 391, Train Loss: 0.9780864, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7760908294318593\n","Epoch: 392, Train Loss: 0.9740741, Train Acc: 0.9907407, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.7798161211531277\n","Epoch: 393, Train Loss: 0.9731481, Train Acc: 0.9870370, Test Acc: 0.6500000\n","AUC of 0is: 0.7483660130718954\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7842665023376932\n","Epoch: 394, Train Loss: 0.9740741, Train Acc: 0.9907407, Test Acc: 0.6500000\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7843595850473131\n","Epoch: 395, Train Loss: 0.9796296, Train Acc: 0.9888889, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7833531027898397\n","Epoch: 396, Train Loss: 0.9774692, Train Acc: 0.9925926, Test Acc: 0.6333334\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7718940118159239\n","Epoch: 397, Train Loss: 0.9774692, Train Acc: 0.9925926, Test Acc: 0.6833334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7912069387686756\n","Epoch: 398, Train Loss: 0.9780864, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.787632592363447\n","Epoch: 399, Train Loss: 0.9762346, Train Acc: 0.9925926, Test Acc: 0.6666667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7808066247969333\n","Epoch: 400, Train Loss: 0.9780864, Train Acc: 0.9925926, Test Acc: 0.6666667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7911390596576701\n","Epoch: 401, Train Loss: 0.9805555, Train Acc: 0.9925926, Test Acc: 0.6666667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7912674128857536\n","Epoch: 402, Train Loss: 0.9771605, Train Acc: 0.9907407, Test Acc: 0.6833334\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.809595918292109\n","Epoch: 403, Train Loss: 0.9808641, Train Acc: 0.9907407, Test Acc: 0.6833334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.7987038578717467\n","Epoch: 404, Train Loss: 0.9783950, Train Acc: 0.9907407, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7863313673499777\n","Epoch: 405, Train Loss: 0.9787037, Train Acc: 0.9870370, Test Acc: 0.6166667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.871967654986523\n","Average auc 0.782098093448577\n","Epoch: 406, Train Loss: 0.9768518, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.6778846153846154\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7906091569208938\n","Epoch: 407, Train Loss: 0.9768518, Train Acc: 0.9962963, Test Acc: 0.6166667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8235294117647057\n","AUC of 4is: 0.673076923076923\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7873067040658605\n","Epoch: 408, Train Loss: 0.9753087, Train Acc: 0.9925926, Test Acc: 0.6500000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7896283924977241\n","Epoch: 409, Train Loss: 0.9762346, Train Acc: 0.9907407, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8235294117647057\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.8021606590731173\n","Epoch: 410, Train Loss: 0.9820988, Train Acc: 0.9925926, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7972901211143442\n","Epoch: 411, Train Loss: 0.9808642, Train Acc: 0.9907407, Test Acc: 0.6833334\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.8081833673017079\n","Epoch: 412, Train Loss: 0.9771605, Train Acc: 0.9870370, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.871967654986523\n","Average auc 0.8014714945184066\n","Epoch: 413, Train Loss: 0.9824074, Train Acc: 0.9925926, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8814016172506739\n","Average auc 0.7922801143701532\n","Epoch: 414, Train Loss: 0.9827160, Train Acc: 0.9925926, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.871967654986523\n","Average auc 0.7999670465853873\n","Epoch: 415, Train Loss: 0.9799383, Train Acc: 0.9944444, Test Acc: 0.6833334\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.8097254572871941\n","Epoch: 416, Train Loss: 0.9808642, Train Acc: 0.9907407, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.773564455029494\n","Epoch: 417, Train Loss: 0.9783951, Train Acc: 0.9888889, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.802098999189038\n","Epoch: 418, Train Loss: 0.9805555, Train Acc: 0.9944444, Test Acc: 0.6333334\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7920162802040082\n","Epoch: 419, Train Loss: 0.9817901, Train Acc: 0.9907407, Test Acc: 0.6666667\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7968906658557047\n","Epoch: 420, Train Loss: 0.9774692, Train Acc: 0.9925926, Test Acc: 0.7000000\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.8164746948390121\n","Epoch: 421, Train Loss: 0.9787037, Train Acc: 0.9907407, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.71875\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7884457814917027\n","Epoch: 422, Train Loss: 0.9777778, Train Acc: 0.9925926, Test Acc: 0.6833334\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.8129305854923223\n","Epoch: 423, Train Loss: 0.9796296, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.701923076923077\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7787425513042883\n","Epoch: 424, Train Loss: 0.9824074, Train Acc: 0.9907407, Test Acc: 0.6500000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7771023451492572\n","Epoch: 425, Train Loss: 0.9774691, Train Acc: 0.9925926, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7901640002257372\n","Epoch: 426, Train Loss: 0.9780864, Train Acc: 0.9944444, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7880925217391644\n","Epoch: 427, Train Loss: 0.9830247, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.871967654986523\n","Average auc 0.7798459639643047\n","Epoch: 428, Train Loss: 0.9802468, Train Acc: 0.9925926, Test Acc: 0.6833334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7896346117246505\n","Epoch: 429, Train Loss: 0.9796296, Train Acc: 0.9962963, Test Acc: 0.7000000\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.8072782812308339\n","Epoch: 430, Train Loss: 0.9833333, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7911390596576701\n","Epoch: 431, Train Loss: 0.9820987, Train Acc: 0.9925926, Test Acc: 0.6500000\n","AUC of 0is: 0.8039215686274509\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7853551221510432\n","Epoch: 432, Train Loss: 0.9737655, Train Acc: 0.9962963, Test Acc: 0.6166667\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7679738562091504\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7607786248854703\n","Epoch: 433, Train Loss: 0.9762346, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7776014965918051\n","Epoch: 434, Train Loss: 0.9808642, Train Acc: 0.9944444, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.72911051212938\n","Average auc 0.7632924942858349\n","Epoch: 435, Train Loss: 0.9768518, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7849556668924039\n","Epoch: 436, Train Loss: 0.9836420, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7651359233604159\n","Epoch: 437, Train Loss: 0.9820988, Train Acc: 0.9907407, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8784786641929501\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7681460049934562\n","Epoch: 438, Train Loss: 0.9793209, Train Acc: 0.9870370, Test Acc: 0.6666667\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7987643319888247\n","Epoch: 439, Train Loss: 0.9802470, Train Acc: 0.9907407, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8382749326145553\n","Average auc 0.7784544220225804\n","Epoch: 440, Train Loss: 0.9777778, Train Acc: 0.9907407, Test Acc: 0.6500000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7802772362958467\n","Epoch: 441, Train Loss: 0.9790124, Train Acc: 0.9962963, Test Acc: 0.6833334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7818495633398718\n","Epoch: 442, Train Loss: 0.9817901, Train Acc: 0.9925926, Test Acc: 0.6666667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7574123989218329\n","Average auc 0.7774417205381807\n","Epoch: 443, Train Loss: 0.9793211, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7776681899358092\n","Epoch: 444, Train Loss: 0.9839506, Train Acc: 0.9944444, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8908355795148248\n","Average auc 0.7720973718649912\n","Epoch: 445, Train Loss: 0.9867284, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7791726378688287\n","Epoch: 446, Train Loss: 0.9808642, Train Acc: 0.9944444, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7927780800456995\n","Epoch: 447, Train Loss: 0.9824074, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.6568627450980391\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.738562091503268\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.762354799622419\n","Epoch: 448, Train Loss: 0.9808642, Train Acc: 0.9944444, Test Acc: 0.6166667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7196765498652291\n","Average auc 0.7468074179540606\n","Epoch: 449, Train Loss: 0.9762345, Train Acc: 0.9925926, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.738544474393531\n","Average auc 0.759081792306285\n","Epoch: 450, Train Loss: 0.9762346, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.8039215686274509\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7956258971277007\n","Epoch: 451, Train Loss: 0.9817901, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7912069387686756\n","Epoch: 452, Train Loss: 0.9817901, Train Acc: 0.9944444, Test Acc: 0.6666667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7726569974246168\n","Epoch: 453, Train Loss: 0.9796296, Train Acc: 0.9907407, Test Acc: 0.6666667\n","AUC of 0is: 0.7483660130718954\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7895415290150307\n","Epoch: 454, Train Loss: 0.9824074, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7695123433365665\n","Epoch: 455, Train Loss: 0.9762346, Train Acc: 0.9944444, Test Acc: 0.6166667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.775197256190597\n","Epoch: 456, Train Loss: 0.9830248, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7879703877380071\n","Epoch: 457, Train Loss: 0.9848765, Train Acc: 0.9925926, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7641454197166104\n","Epoch: 458, Train Loss: 0.9861111, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7716757187657577\n","Epoch: 459, Train Loss: 0.9836420, Train Acc: 0.9925926, Test Acc: 0.6666667\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7574123989218329\n","Average auc 0.800964163703481\n","Epoch: 460, Train Loss: 0.9814815, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.7967006527435415\n","Epoch: 461, Train Loss: 0.9799383, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7875697467123661\n","Epoch: 462, Train Loss: 0.9817901, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7574123989218329\n","Average auc 0.7917049044442219\n","Epoch: 463, Train Loss: 0.9842592, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.7483660130718954\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.7951647819849818\n","Epoch: 464, Train Loss: 0.9756172, Train Acc: 0.9944444, Test Acc: 0.6666667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8382749326145553\n","Average auc 0.7874111564257434\n","Epoch: 465, Train Loss: 0.9771604, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7904792236784467\n","Epoch: 466, Train Loss: 0.9845679, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7872062163623128\n","Epoch: 467, Train Loss: 0.9836420, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7668463611859838\n","Average auc 0.7899739871135741\n","Epoch: 468, Train Loss: 0.9845679, Train Acc: 0.9944444, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.783254986620295\n","Epoch: 469, Train Loss: 0.9759259, Train Acc: 0.9944444, Test Acc: 0.6666667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8814016172506739\n","Average auc 0.7982047064291992\n","Epoch: 470, Train Loss: 0.9820988, Train Acc: 0.9944444, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7574123989218329\n","Average auc 0.7791424008102897\n","Epoch: 471, Train Loss: 0.9833333, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7816711590296497\n","Average auc 0.7687493577278737\n","Epoch: 472, Train Loss: 0.9858025, Train Acc: 0.9944444, Test Acc: 0.6333334\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7574123989218329\n","Average auc 0.7755994772306013\n","Epoch: 473, Train Loss: 0.9833333, Train Acc: 0.9944444, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7827244123522069\n","Epoch: 474, Train Loss: 0.9805555, Train Acc: 0.9962963, Test Acc: 0.6166667\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7878055782244581\n","Epoch: 475, Train Loss: 0.9796298, Train Acc: 0.9962963, Test Acc: 0.6000000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7124183006535947\n","AUC of 4is: 0.6923076923076923\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7635962049089328\n","Epoch: 476, Train Loss: 0.9836420, Train Acc: 0.9944444, Test Acc: 0.6166667\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7532835963547871\n","Epoch: 477, Train Loss: 0.9824074, Train Acc: 0.9925926, Test Acc: 0.6666667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7819162566838761\n","Epoch: 478, Train Loss: 0.9799383, Train Acc: 0.9925926, Test Acc: 0.6166667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7662090989618934\n","Epoch: 479, Train Loss: 0.9790124, Train Acc: 0.9944444, Test Acc: 0.6333334\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.71875\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.7991490145669035\n","Epoch: 480, Train Loss: 0.9833333, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.8235294117647057\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7988938709839098\n","Epoch: 481, Train Loss: 0.9814815, Train Acc: 0.9981481, Test Acc: 0.6500000\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7970636517167158\n","Epoch: 482, Train Loss: 0.9839506, Train Acc: 0.9944444, Test Acc: 0.6666667\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8784786641929501\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7985692854167367\n","Epoch: 483, Train Loss: 0.9830247, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7801488830677629\n","Epoch: 484, Train Loss: 0.9805555, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7754319019356873\n","Epoch: 485, Train Loss: 0.9854938, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7896334259576491\n","Epoch: 486, Train Loss: 0.9870370, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7785765560237378\n","Epoch: 487, Train Loss: 0.9817901, Train Acc: 0.9944444, Test Acc: 0.6000000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.6470588235294117\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7532773771278607\n","Epoch: 488, Train Loss: 0.9901235, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.871967654986523\n","Average auc 0.7906096711565834\n","Epoch: 489, Train Loss: 0.9861111, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8814016172506739\n","Average auc 0.8054607605602532\n","Epoch: 490, Train Loss: 0.9851851, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.72911051212938\n","Average auc 0.763465480146846\n","Epoch: 491, Train Loss: 0.9842592, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8580705009276438\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7666624320045123\n","Epoch: 492, Train Loss: 0.9873456, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7849556668924039\n","Epoch: 493, Train Loss: 0.9836420, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7849556668924039\n","Epoch: 494, Train Loss: 0.9851851, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7795192841470787\n","Epoch: 495, Train Loss: 0.9827161, Train Acc: 0.9944444, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7842967393962321\n","Epoch: 496, Train Loss: 0.9851851, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.701923076923077\n","AUC of 5is: 0.871967654986523\n","Average auc 0.7732080523894184\n","Epoch: 497, Train Loss: 0.9851851, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8814016172506739\n","Average auc 0.790548011272504\n","Epoch: 498, Train Loss: 0.9842592, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8814016172506739\n","Average auc 0.7979336043986432\n","Epoch: 499, Train Loss: 0.9848766, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8908355795148248\n","Average auc 0.7877983103600474\n","Epoch: 500, Train Loss: 0.9845678, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7711160932061322\n","Epoch: 501, Train Loss: 0.9861111, Train Acc: 0.9944444, Test Acc: 0.6666667\n","AUC of 0is: 0.8235294117647057\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.8010258235875605\n","Epoch: 502, Train Loss: 0.9839507, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7479784366576819\n","Average auc 0.7700114947791142\n","Epoch: 503, Train Loss: 0.9851851, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7859319120913382\n","Epoch: 504, Train Loss: 0.9842592, Train Acc: 0.9981481, Test Acc: 0.6333334\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7950616323555121\n","Epoch: 505, Train Loss: 0.9895062, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.7679738562091504\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.783642140554599\n","Epoch: 506, Train Loss: 0.9842592, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8814016172506739\n","Average auc 0.7837371138366064\n","Epoch: 507, Train Loss: 0.9870370, Train Acc: 0.9981481, Test Acc: 0.6333334\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.871967654986523\n","Average auc 0.7981682501437337\n","Epoch: 508, Train Loss: 0.9848765, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.701923076923077\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7755362373321586\n","Epoch: 509, Train Loss: 0.9888889, Train Acc: 0.9981481, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8784786641929501\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7845325709083241\n","Epoch: 510, Train Loss: 0.9848765, Train Acc: 0.9981481, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.789506258496567\n","Epoch: 511, Train Loss: 0.9870370, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7769123320370942\n","Epoch: 512, Train Loss: 0.9854938, Train Acc: 0.9981481, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.789408142327022\n","Epoch: 513, Train Loss: 0.9839506, Train Acc: 0.9925926, Test Acc: 0.6166667\n","AUC of 0is: 0.7483660130718954\n","AUC of 1is: 0.71875\n","AUC of 2is: 0.8784786641929501\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8814016172506739\n","Average auc 0.7859892433208788\n","Epoch: 514, Train Loss: 0.9808642, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.7483660130718954\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7906522095394578\n","Epoch: 515, Train Loss: 0.9845679, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.777010448206639\n","Epoch: 516, Train Loss: 0.9833333, Train Acc: 0.9925926, Test Acc: 0.6166667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.871967654986523\n","Average auc 0.7837987737206861\n","Epoch: 517, Train Loss: 0.9830248, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.7124183006535947\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.787693066480525\n","Epoch: 518, Train Loss: 0.9848766, Train Acc: 0.9944444, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.798795754814365\n","Epoch: 519, Train Loss: 0.9830248, Train Acc: 0.9981481, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.871967654986523\n","Average auc 0.7946605970825092\n","Epoch: 520, Train Loss: 0.9873457, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.8003680818583904\n","Epoch: 521, Train Loss: 0.9848766, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7679738562091504\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.871967654986523\n","Average auc 0.8031054814465112\n","Epoch: 522, Train Loss: 0.9820987, Train Acc: 0.9944444, Test Acc: 0.6833334\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.8112977843312192\n","Epoch: 523, Train Loss: 0.9839507, Train Acc: 0.9944444, Test Acc: 0.6833334\n","AUC of 0is: 0.8235294117647057\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.8097556943457332\n","Epoch: 524, Train Loss: 0.9842592, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.862533692722372\n","Average auc 0.7947575274850526\n","Epoch: 525, Train Loss: 0.9885802, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7896346117246505\n","Epoch: 526, Train Loss: 0.9848765, Train Acc: 0.9962963, Test Acc: 0.6833334\n","AUC of 0is: 0.8039215686274509\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.8096940344616538\n","Epoch: 527, Train Loss: 0.9830248, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.8039215686274509\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.871967654986523\n","Average auc 0.7963298545290777\n","Epoch: 528, Train Loss: 0.9916667, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7844262783913173\n","Epoch: 529, Train Loss: 0.9867283, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8137254901960783\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7876314065964455\n","Epoch: 530, Train Loss: 0.9879631, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.6928104575163399\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7843634327402363\n","Epoch: 531, Train Loss: 0.9845679, Train Acc: 0.9925926, Test Acc: 0.6666667\n","AUC of 0is: 0.6372549019607843\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.758169934640523\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8814016172506739\n","Average auc 0.7845919963879177\n","Epoch: 532, Train Loss: 0.9891976, Train Acc: 0.9925926, Test Acc: 0.6500000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7834521274424359\n","Epoch: 533, Train Loss: 0.9848766, Train Acc: 0.9925926, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.769112888077927\n","Epoch: 534, Train Loss: 0.9876543, Train Acc: 0.9925926, Test Acc: 0.6166667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8908355795148248\n","Average auc 0.7808892967546052\n","Epoch: 535, Train Loss: 0.9864198, Train Acc: 0.9944444, Test Acc: 0.6166667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8908355795148248\n","Average auc 0.7828610790572698\n","Epoch: 536, Train Loss: 0.9873456, Train Acc: 0.9962963, Test Acc: 0.6166667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7795495212056176\n","Epoch: 537, Train Loss: 0.9885802, Train Acc: 0.9962963, Test Acc: 0.6000000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7670851337412302\n","Epoch: 538, Train Loss: 0.9864198, Train Acc: 0.9981481, Test Acc: 0.6000000\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.7911051212938006\n","Average auc 0.7646367719178683\n","Epoch: 539, Train Loss: 0.9876544, Train Acc: 0.9981481, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.738544474393531\n","Average auc 0.7667384874629802\n","Epoch: 540, Train Loss: 0.9873456, Train Acc: 0.9981481, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7818181405143313\n","Epoch: 541, Train Loss: 0.9848766, Train Acc: 0.9981481, Test Acc: 0.6166667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7710482140951264\n","Epoch: 542, Train Loss: 0.9873457, Train Acc: 0.9962963, Test Acc: 0.6000000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7124183006535947\n","AUC of 4is: 0.701923076923077\n","AUC of 5is: 0.871967654986523\n","Average auc 0.772968373184403\n","Epoch: 543, Train Loss: 0.9867283, Train Acc: 0.9962963, Test Acc: 0.6166667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.6568627450980391\n","AUC of 4is: 0.701923076923077\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7618580197138743\n","Epoch: 544, Train Loss: 0.9854938, Train Acc: 0.9944444, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8814016172506739\n","Average auc 0.7853396779391706\n","Epoch: 545, Train Loss: 0.9836420, Train Acc: 0.9962963, Test Acc: 0.6166667\n","AUC of 0is: 0.6928104575163399\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8814016172506739\n","Average auc 0.770297389656336\n","Epoch: 546, Train Loss: 0.9885803, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.6470588235294117\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7632329286518086\n","Epoch: 547, Train Loss: 0.9854938, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.7926811496431562\n","Epoch: 548, Train Loss: 0.9882717, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.8125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6470588235294117\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8814016172506739\n","Average auc 0.7881310722746826\n","Epoch: 549, Train Loss: 0.9870370, Train Acc: 0.9962963, Test Acc: 0.6166667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8814016172506739\n","Average auc 0.7719313765844406\n","Epoch: 550, Train Loss: 0.9895062, Train Acc: 0.9944444, Test Acc: 0.6333334\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8886827458256029\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.871967654986523\n","Average auc 0.7796183087996748\n","Epoch: 551, Train Loss: 0.9882717, Train Acc: 0.9962963, Test Acc: 0.6500000\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8005390835579516\n","Average auc 0.7695123433365665\n","Epoch: 552, Train Loss: 0.9888889, Train Acc: 0.9962963, Test Acc: 0.6166667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6830065359477124\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7641139968910701\n","Epoch: 553, Train Loss: 0.9861111, Train Acc: 0.9981481, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.8039215686274509\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8814016172506739\n","Average auc 0.8090665297910223\n","Epoch: 554, Train Loss: 0.9885802, Train Acc: 0.9981481, Test Acc: 0.6166667\n","AUC of 0is: 0.7026143790849674\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8814016172506739\n","Average auc 0.7776829827824754\n","Epoch: 555, Train Loss: 0.9925926, Train Acc: 0.9962963, Test Acc: 0.6166667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.7403846153846153\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.772558881255072\n","Epoch: 556, Train Loss: 0.9876544, Train Acc: 0.9962963, Test Acc: 0.6166667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.75\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6830065359477124\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8194070080862534\n","Average auc 0.7733732561503293\n","Epoch: 557, Train Loss: 0.9885802, Train Acc: 0.9962963, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.6928104575163399\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8099730458221025\n","Average auc 0.7786432493677421\n","Epoch: 558, Train Loss: 0.9876543, Train Acc: 0.9944444, Test Acc: 0.6333334\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.8988868274582561\n","AUC of 3is: 0.7026143790849674\n","AUC of 4is: 0.721153846153846\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.7818193262813328\n","Epoch: 559, Train Loss: 0.9895061, Train Acc: 0.9925926, Test Acc: 0.6666667\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.8288409703504044\n","Average auc 0.8020071022464196\n","Epoch: 560, Train Loss: 0.9888889, Train Acc: 0.9907407, Test Acc: 0.6166667\n","AUC of 0is: 0.8137254901960783\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.6372549019607843\n","AUC of 4is: 0.7115384615384616\n","AUC of 5is: 0.8908355795148248\n","Average auc 0.7906158903835098\n","Epoch: 561, Train Loss: 0.9907407, Train Acc: 0.9962963, Test Acc: 0.6666667\n","AUC of 0is: 0.758169934640523\n","AUC of 1is: 0.78125\n","AUC of 2is: 0.9090909090909092\n","AUC of 3is: 0.7483660130718954\n","AUC of 4is: 0.7307692307692307\n","AUC of 5is: 0.9002695417789758\n","Average auc 0.8046526048919224\n"]}],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","import sklearn.metrics as metrics\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6, heads=16)\n","        self.conv5 = GraphConv(dim*16, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return torch.sigmoid(x)\n","\n","def train(epoch):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    correct = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = F.one_hot(data.y, num_classes = 6).type(torch.FloatTensor)\n","        #assert len(data.y) == len(train_loader.dataset), (str(len(train_loader.dataset))+\" \"+str(len(data.y)))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.5).float()\n","        loss = torch.nn.BCELoss()\n","        loss = loss(output_probs, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        correct += (output == data.y).float().sum()/6\n","    return correct / len(train_loader.dataset)\n","\n","\n","def test(loader, epoch, test=False):\n","    model.eval()\n","\n","    correct = 0\n","    if test: \n","      outs = []\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        #data.y = F.one_hot(data.y, num_classes = 6).type(torch.FloatTensor)\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.5).float()\n","        correct += (torch.argmax(output, dim=1) == data.y).float().sum()\n","        #print(output, data.y)\n","        if test: \n","          outs.append(output.cpu().detach().numpy())\n","    if test: \n","      outputs =np.concatenate(outs, axis=0 ).astype(float)\n","      np.savetxt(\"Enzymes_epoch\"+str(epoch)+\".csv\", outputs)\n","    return correct / len(loader.dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n","\n","for epoch in range(1, 5000):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader, epoch=epoch)\n","    test_acc = test(test_loader, epoch, test=True)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))\n","    y = np.zeros((len(test_dataset)))\n","    x = np.loadtxt(\"Enzymes_epoch\"+str(epoch)+\".csv\")\n","    for i in range(len(test_dataset)):\n","      y[i] = test_dataset[i].y\n","    y = torch.as_tensor(y)\n","    y = F.one_hot(y.long(), num_classes = 6).long()\n","    store_auc = 0\n","    for i in range(len(x[0,:])): \n","      auc = metrics.roc_auc_score(y[:,i], x[:,i])\n","      print(\"AUC of \"+str(i) +\"is:\", auc)\n","      store_auc += auc\n","    print(\"Average auc\", store_auc/6)\n","#print(y.shape)\n","    if auc >=0.9:\n","      break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":435,"status":"ok","timestamp":1621784825121,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"IT7flQBV6ER_","outputId":"8efe4339-d3ff-4a4a-d7aa-59b67e581eee"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([3, 3, 2, 4, 1, 3, 0, 1, 4, 4])\n","tensor([[0, 0, 0, 1, 0],\n","        [0, 0, 0, 1, 0],\n","        [0, 0, 1, 0, 0],\n","        [0, 0, 0, 0, 1],\n","        [0, 1, 0, 0, 0],\n","        [0, 0, 0, 1, 0],\n","        [1, 0, 0, 0, 0],\n","        [0, 1, 0, 0, 0],\n","        [0, 0, 0, 0, 1],\n","        [0, 0, 0, 0, 1]])\n"]}],"source":["import random\n","n_classes = 5\n","n_samples = 10\n","\n","# Create list n_samples random labels (can also be numpy array)\n","labels = [random.randrange(n_classes) for _ in range(n_samples)]\n","# Convert to torch Tensor\n","labels_tensor = torch.as_tensor(labels)\n","print(labels_tensor)\n","# Create one-hot encodings of labels\n","one_hot = torch.nn.functional.one_hot(labels_tensor, num_classes=n_classes)\n","print(one_hot)"]},{"cell_type":"markdown","metadata":{"id":"wiNoFOStyDzz"},"source":["#Proteins\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3354,"status":"ok","timestamp":1621786058180,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"78wtGPPfyEAd","outputId":"63130866-326c-4886-f5ca-35e3ed4fbfac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/PROTEINS.zip\n","Extracting ./PROTEINS/PROTEINS.zip\n","Processing...\n","Done!\n","Train Dataset: PROTEINS(1002):\n","======================\n","Number of graphs: 1002\n","Number of features: 3\n","Number of classes: 2\n","Test Dataset: PROTEINS(111):\n","======================\n","Number of graphs: 111\n","Number of features: 3\n","Number of classes: 2\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"PROTEINS\").shuffle()\n","\n","train_dataset = dataset[len(dataset) // 10:]\n","test_dataset = dataset[:len(dataset) // 10]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8928,"status":"ok","timestamp":1621786237327,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"wvlSNwOFyEq7","outputId":"5b15edc1-8b41-49e3-808b-d497e587e2fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 001, Train Loss: 0.1989355, Train Acc: 0.6087824, Test Acc: 0.4774775\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","Average auc 0.5\n","Epoch: 002, Train Loss: 0.2040918, Train Acc: 0.6576846, Test Acc: 0.6036036\n","AUC of 0is: 0.6190631099544568\n","AUC of 1is: 0.6268705270006506\n","Average auc 0.6229668184775536\n","Epoch: 003, Train Loss: 0.2124085, Train Acc: 0.6886228, Test Acc: 0.6036036\n","AUC of 0is: 0.6699739752765127\n","AUC of 1is: 0.6276837996096292\n","Average auc 0.648828887443071\n","Epoch: 004, Train Loss: 0.2227212, Train Acc: 0.6506986, Test Acc: 0.5675676\n","AUC of 0is: 0.6872153545868576\n","AUC of 1is: 0.5853936239427456\n","Average auc 0.6363044892648015\n","Epoch: 005, Train Loss: 0.2262142, Train Acc: 0.6986028, Test Acc: 0.6216216\n","AUC of 0is: 0.7467469095640858\n","AUC of 1is: 0.635491216655823\n","Average auc 0.6911190631099544\n","Epoch: 006, Train Loss: 0.2258816, Train Acc: 0.7205589, Test Acc: 0.6936937\n","AUC of 0is: 0.7340598568640209\n","AUC of 1is: 0.7036434612882239\n","Average auc 0.7188516590761224\n","Epoch: 007, Train Loss: 0.2327013, Train Acc: 0.7125748, Test Acc: 0.6936937\n","AUC of 0is: 0.7984710474951204\n","AUC of 1is: 0.7036434612882239\n","Average auc 0.7510572543916721\n","Epoch: 008, Train Loss: 0.2290419, Train Acc: 0.7035928, Test Acc: 0.6576577\n","AUC of 0is: 0.7044567338972023\n","AUC of 1is: 0.6794079375406636\n","Average auc 0.691932335718933\n","Epoch: 009, Train Loss: 0.2248836, Train Acc: 0.7025948, Test Acc: 0.6486487\n","AUC of 0is: 0.7639882888744307\n","AUC of 1is: 0.6629798308392973\n","Average auc 0.713484059856864\n","Epoch: 010, Train Loss: 0.2302063, Train Acc: 0.7285429, Test Acc: 0.6936937\n","AUC of 0is: 0.7553675992192583\n","AUC of 1is: 0.7130774235523748\n","Average auc 0.7342225113858165\n","Epoch: 011, Train Loss: 0.2336993, Train Acc: 0.7105789, Test Acc: 0.7117117\n","AUC of 0is: 0.7504879635653872\n","AUC of 1is: 0.7303188028627196\n","Average auc 0.7404033832140533\n","Epoch: 012, Train Loss: 0.2355289, Train Acc: 0.7255489, Test Acc: 0.6936937\n","AUC of 0is: 0.7709824333116461\n","AUC of 1is: 0.7122641509433962\n","Average auc 0.7416232921275212\n","Epoch: 013, Train Loss: 0.2405190, Train Acc: 0.7275449, Test Acc: 0.7477478\n","AUC of 0is: 0.7796031229668186\n","AUC of 1is: 0.7553675992192583\n","Average auc 0.7674853610930384\n","Epoch: 014, Train Loss: 0.2350300, Train Acc: 0.7365270, Test Acc: 0.7387388\n","AUC of 0is: 0.7857839947950553\n","AUC of 1is: 0.746746909564086\n","Average auc 0.7662654521795706\n","Epoch: 015, Train Loss: 0.2391883, Train Acc: 0.7405190, Test Acc: 0.7387388\n","AUC of 0is: 0.7796031229668186\n","AUC of 1is: 0.7475601821730644\n","Average auc 0.7635816525699415\n","Epoch: 016, Train Loss: 0.2353626, Train Acc: 0.7305389, Test Acc: 0.7117117\n","AUC of 0is: 0.7553675992192583\n","AUC of 1is: 0.7303188028627196\n","Average auc 0.7428432010409889\n","Epoch: 017, Train Loss: 0.2340319, Train Acc: 0.7165669, Test Acc: 0.6756757\n","AUC of 0is: 0.77878985035784\n","AUC of 1is: 0.688028627195836\n","Average auc 0.7334092387768381\n","Epoch: 018, Train Loss: 0.2358616, Train Acc: 0.7315369, Test Acc: 0.7567568\n","AUC of 0is: 0.7968445022771633\n","AUC of 1is: 0.7734222511385817\n","Average auc 0.7851333767078725\n","Epoch: 019, Train Loss: 0.2390219, Train Acc: 0.7405190, Test Acc: 0.7567568\n","AUC of 0is: 0.7882238126219909\n","AUC of 1is: 0.7812296681847756\n","Average auc 0.7847267404033833\n","Epoch: 020, Train Loss: 0.2375249, Train Acc: 0.7375249, Test Acc: 0.7207208\n","AUC of 0is: 0.7796031229668186\n","AUC of 1is: 0.729505530253741\n","Average auc 0.7545543266102798\n","Epoch: 021, Train Loss: 0.2370259, Train Acc: 0.7345309, Test Acc: 0.7477478\n","AUC of 0is: 0.77878985035784\n","AUC of 1is: 0.7553675992192583\n","Average auc 0.7670787247885491\n","Epoch: 022, Train Loss: 0.2408516, Train Acc: 0.7395210, Test Acc: 0.7477478\n","AUC of 0is: 0.7874105400130124\n","AUC of 1is: 0.7561808718282369\n","Average auc 0.7717957059206246\n","Epoch: 023, Train Loss: 0.2430140, Train Acc: 0.7255489, Test Acc: 0.6936937\n","AUC of 0is: 0.7984710474951204\n","AUC of 1is: 0.7044567338972023\n","Average auc 0.7514638906961614\n","Epoch: 024, Train Loss: 0.2400199, Train Acc: 0.7375249, Test Acc: 0.7387388\n","AUC of 0is: 0.8218932986337021\n","AUC of 1is: 0.7475601821730644\n","Average auc 0.7847267404033833\n","Epoch: 025, Train Loss: 0.2438457, Train Acc: 0.7285429, Test Acc: 0.6846847\n","AUC of 0is: 0.7648015614834093\n","AUC of 1is: 0.6958360442420299\n","Average auc 0.7303188028627197\n","Epoch: 026, Train Loss: 0.2395210, Train Acc: 0.7534930, Test Acc: 0.7747748\n","AUC of 0is: 0.8227065712426805\n","AUC of 1is: 0.7812296681847756\n","Average auc 0.8019681197137281\n","Epoch: 027, Train Loss: 0.2413506, Train Acc: 0.7445109, Test Acc: 0.7027027\n","AUC of 0is: 0.8054651919323357\n","AUC of 1is: 0.7122641509433962\n","Average auc 0.758864671437866\n","Epoch: 028, Train Loss: 0.2410180, Train Acc: 0.7385229, Test Acc: 0.7747748\n","AUC of 0is: 0.7865972674040338\n","AUC of 1is: 0.7796031229668186\n","Average auc 0.7831001951854262\n","Epoch: 029, Train Loss: 0.2423486, Train Acc: 0.7405190, Test Acc: 0.7567568\n","AUC of 0is: 0.7906636304489265\n","AUC of 1is: 0.7734222511385817\n","Average auc 0.7820429407937541\n","Epoch: 030, Train Loss: 0.2416833, Train Acc: 0.7475050, Test Acc: 0.7657658\n","AUC of 0is: 0.7882238126219909\n","AUC of 1is: 0.7734222511385817\n","Average auc 0.7808230318802862\n","Epoch: 031, Train Loss: 0.2438457, Train Acc: 0.7345309, Test Acc: 0.7297298\n","AUC of 0is: 0.7561808718282368\n","AUC of 1is: 0.7389394925178919\n","Average auc 0.7475601821730644\n","Epoch: 032, Train Loss: 0.2486693, Train Acc: 0.7485030, Test Acc: 0.7837838\n","AUC of 0is: 0.7874105400130124\n","AUC of 1is: 0.789850357839948\n","Average auc 0.7886304489264802\n","Epoch: 033, Train Loss: 0.2435130, Train Acc: 0.7514970, Test Acc: 0.7657658\n","AUC of 0is: 0.8046519193233572\n","AUC of 1is: 0.7717957059206246\n","Average auc 0.7882238126219909\n","Epoch: 034, Train Loss: 0.2406853, Train Acc: 0.7425150, Test Acc: 0.7657658\n","AUC of 0is: 0.7717957059206246\n","AUC of 1is: 0.7734222511385817\n","Average auc 0.7726089785296031\n","Epoch: 035, Train Loss: 0.2453426, Train Acc: 0.7584831, Test Acc: 0.7837838\n","AUC of 0is: 0.8054651919323357\n","AUC of 1is: 0.789850357839948\n","Average auc 0.7976577748861418\n","Epoch: 036, Train Loss: 0.2496673, Train Acc: 0.7415169, Test Acc: 0.7837838\n","AUC of 0is: 0.7984710474951204\n","AUC of 1is: 0.789850357839948\n","Average auc 0.7941607026675341\n","Epoch: 037, Train Loss: 0.2501663, Train Acc: 0.7604790, Test Acc: 0.7927928\n","AUC of 0is: 0.8046519193233572\n","AUC of 1is: 0.7960312296681847\n","Average auc 0.8003415744957709\n","Epoch: 038, Train Loss: 0.2468397, Train Acc: 0.7574850, Test Acc: 0.8198199\n","AUC of 0is: 0.8116460637605726\n","AUC of 1is: 0.8218932986337021\n","Average auc 0.8167696811971373\n"]}],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","import sklearn.metrics as metrics\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return torch.sigmoid(x)\n","\n","def train(epoch):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    correct = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = F.one_hot(data.y, num_classes = 2).type(torch.FloatTensor)\n","        #assert len(data.y) == len(train_loader.dataset), (str(len(train_loader.dataset))+\" \"+str(len(data.y)))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.5).float()\n","        loss = torch.nn.BCELoss()\n","        loss = loss(output_probs, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        correct += (output == data.y).float().sum()/6\n","    return correct / len(train_loader.dataset)\n","\n","\n","def test(loader, epoch, test=False):\n","    model.eval()\n","\n","    correct = 0\n","    if test: \n","      outs = []\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        #data.y = F.one_hot(data.y, num_classes = 6).type(torch.FloatTensor)\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.5).float()\n","        correct += (torch.argmax(output, dim=1) == data.y).float().sum()\n","        #print(output, data.y)\n","        if test: \n","          outs.append(output.cpu().detach().numpy())\n","    if test: \n","      outputs =np.concatenate(outs, axis=0 ).astype(float)\n","      np.savetxt(\"Enzymes_epoch\"+str(epoch)+\".csv\", outputs)\n","    return correct / len(loader.dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n","\n","for epoch in range(1, 5000):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader, epoch=epoch)\n","    test_acc = test(test_loader, epoch, test=True)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))\n","    y = np.zeros((len(test_dataset)))\n","    x = np.loadtxt(\"Enzymes_epoch\"+str(epoch)+\".csv\")\n","    for i in range(len(test_dataset)):\n","      y[i] = test_dataset[i].y\n","    y = torch.as_tensor(y)\n","    y = F.one_hot(y.long(), num_classes = 6).long()\n","    store_auc = 0\n","    for i in range(len(x[0,:])): \n","      auc = metrics.roc_auc_score(y[:,i], x[:,i])\n","      print(\"AUC of \"+str(i) +\"is:\", auc)\n","      store_auc += auc\n","    print(\"Average auc\", store_auc/2)\n","#print(y.shape)\n","    if auc >=0.8:\n","      break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h_JR5Et73OmT"},"outputs":[],"source":["for epoch in range(1, 5000):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))"]},{"cell_type":"markdown","metadata":{"id":"M3T4xk6O1X0f"},"source":["#MCF-7\n","\n","Breast Cancer actives to MCF-7 cells\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14457,"status":"ok","timestamp":1621786340543,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"acVc7yBh1X9b","outputId":"c21f3746-92fa-4b8f-daaa-78d14ca114b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/MCF-7.zip\n","Extracting ./MCF-7/MCF-7.zip\n","Processing...\n","Done!\n","Train Dataset: MCF-7(24993):\n","======================\n","Number of graphs: 24993\n","Number of features: 46\n","Number of classes: 2\n","Test Dataset: MCF-7(2777):\n","======================\n","Number of graphs: 2777\n","Number of features: 46\n","Number of classes: 2\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"MCF-7\").shuffle()\n","\n","train_dataset = dataset[len(dataset) // 10:]\n","test_dataset = dataset[:len(dataset) // 10]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2236,"status":"ok","timestamp":1621786381363,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"SiZQ2bZyAgpd","outputId":"3999e04c-6ee9-442a-9ac1-7f88c7a0ab3b"},"outputs":[{"name":"stdout","output_type":"stream","text":["count\n","0.08318329132157004\n","24993\n","0.91681670867843\n","torch.Size([])\n"]}],"source":["count = 0\n","for i in range(len(train_dataset)):\n","  if train_dataset[i].y[0] == 1: \n","    count+=1\n","print(\"count\")\n","print(count/len(train_dataset))\n","print(len(train_dataset))\n","print((len(train_dataset)-count)/len(train_dataset))\n","print(train_dataset[i].y[0].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2121168,"status":"error","timestamp":1621788557746,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"WyzB5Zew1YAG","outputId":"d71b0908-f894-48a7-bc5b-37b77071b552"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 001, Train Loss: 0.3054458, Train Acc: 0.9168167, Test Acc: 0.9225783\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","Average auc 0.5\n","Epoch: 002, Train Loss: 0.3055991, Train Acc: 0.9168167, Test Acc: 0.9225783\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","Average auc 0.5\n","Epoch: 003, Train Loss: 0.3055591, Train Acc: 0.9168167, Test Acc: 0.9225783\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","Average auc 0.5\n","Epoch: 004, Train Loss: 0.3057058, Train Acc: 0.9170168, Test Acc: 0.9225783\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","Average auc 0.5\n","Epoch: 005, Train Loss: 0.3056390, Train Acc: 0.9171768, Test Acc: 0.9225783\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","Average auc 0.5\n","Epoch: 006, Train Loss: 0.3056858, Train Acc: 0.9167767, Test Acc: 0.9225783\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","Average auc 0.5\n","Epoch: 007, Train Loss: 0.3056658, Train Acc: 0.9171368, Test Acc: 0.9225783\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","Average auc 0.5\n","Epoch: 008, Train Loss: 0.3059859, Train Acc: 0.9169368, Test Acc: 0.9225783\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","Average auc 0.5\n","Epoch: 009, Train Loss: 0.3060792, Train Acc: 0.9171368, Test Acc: 0.9229384\n","AUC of 0is: 0.5023255813953489\n","AUC of 1is: 0.5023255813953489\n","Average auc 0.5023255813953489\n","Epoch: 010, Train Loss: 0.3059590, Train Acc: 0.9173369, Test Acc: 0.9225783\n","AUC of 0is: 0.5021304213641232\n","AUC of 1is: 0.5021304213641232\n","Average auc 0.5021304213641232\n","Epoch: 011, Train Loss: 0.3060924, Train Acc: 0.9174969, Test Acc: 0.9222182\n","AUC of 0is: 0.5019352613328977\n","AUC of 1is: 0.5019352613328977\n","Average auc 0.5019352613328977\n","Epoch: 012, Train Loss: 0.3059123, Train Acc: 0.9171768, Test Acc: 0.9222182\n","AUC of 0is: 0.4998048399687744\n","AUC of 1is: 0.4998048399687744\n","Average auc 0.4998048399687744\n","Epoch: 013, Train Loss: 0.3061925, Train Acc: 0.9174569, Test Acc: 0.9222182\n","AUC of 0is: 0.5019352613328977\n","AUC of 1is: 0.5019352613328977\n","Average auc 0.5019352613328977\n","Epoch: 014, Train Loss: 0.3062325, Train Acc: 0.9180171, Test Acc: 0.9218581\n","AUC of 0is: 0.501740101301672\n","AUC of 1is: 0.501740101301672\n","Average auc 0.501740101301672\n","Epoch: 015, Train Loss: 0.3061990, Train Acc: 0.9172168, Test Acc: 0.9222182\n","AUC of 0is: 0.4998048399687744\n","AUC of 1is: 0.4998048399687744\n","Average auc 0.4998048399687744\n","Epoch: 016, Train Loss: 0.3063458, Train Acc: 0.9181771, Test Acc: 0.9222182\n","AUC of 0is: 0.5040656826970209\n","AUC of 1is: 0.5040656826970209\n","Average auc 0.5040656826970209\n","Epoch: 017, Train Loss: 0.3060990, Train Acc: 0.9176570, Test Acc: 0.9222182\n","AUC of 0is: 0.5019352613328977\n","AUC of 1is: 0.5019352613328977\n","Average auc 0.5019352613328977\n","Epoch: 018, Train Loss: 0.3063725, Train Acc: 0.9171368, Test Acc: 0.9225783\n","AUC of 0is: 0.4998048399687744\n","AUC of 1is: 0.5\n","Average auc 0.4999024199843872\n","Epoch: 019, Train Loss: 0.3065125, Train Acc: 0.9178170, Test Acc: 0.9218581\n","AUC of 0is: 0.4996096799375488\n","AUC of 1is: 0.4996096799375488\n","Average auc 0.4996096799375488\n","Epoch: 020, Train Loss: 0.3064791, Train Acc: 0.9178970, Test Acc: 0.9222182\n","AUC of 0is: 0.5019352613328977\n","AUC of 1is: 0.501740101301672\n","Average auc 0.5018376813172849\n","Epoch: 021, Train Loss: 0.3066525, Train Acc: 0.9172969, Test Acc: 0.9218581\n","AUC of 0is: 0.4996096799375488\n","AUC of 1is: 0.4996096799375488\n","Average auc 0.4996096799375488\n","Epoch: 022, Train Loss: 0.3063457, Train Acc: 0.9179370, Test Acc: 0.9218581\n","AUC of 0is: 0.501740101301672\n","AUC of 1is: 0.501740101301672\n","Average auc 0.501740101301672\n","Epoch: 023, Train Loss: 0.3063392, Train Acc: 0.9176970, Test Acc: 0.9222182\n","AUC of 0is: 0.5040656826970209\n","AUC of 1is: 0.5040656826970209\n","Average auc 0.5040656826970209\n","Epoch: 024, Train Loss: 0.3064525, Train Acc: 0.9176170, Test Acc: 0.9218581\n","AUC of 0is: 0.4996096799375488\n","AUC of 1is: 0.4996096799375488\n","Average auc 0.4996096799375488\n","Epoch: 025, Train Loss: 0.3068591, Train Acc: 0.9186972, Test Acc: 0.9222182\n","AUC of 0is: 0.5040656826970209\n","AUC of 1is: 0.5040656826970209\n","Average auc 0.5040656826970209\n","Epoch: 026, Train Loss: 0.3068192, Train Acc: 0.9187373, Test Acc: 0.9222182\n","AUC of 0is: 0.5040656826970209\n","AUC of 1is: 0.5038705226657952\n","Average auc 0.503968102681408\n","Epoch: 027, Train Loss: 0.3064259, Train Acc: 0.9183772, Test Acc: 0.9214980\n","AUC of 0is: 0.5015449412704465\n","AUC of 1is: 0.5015449412704465\n","Average auc 0.5015449412704465\n","Epoch: 028, Train Loss: 0.3067528, Train Acc: 0.9184572, Test Acc: 0.9225783\n","AUC of 0is: 0.5042608427282465\n","AUC of 1is: 0.5042608427282465\n","Average auc 0.5042608427282465\n","Epoch: 029, Train Loss: 0.3068592, Train Acc: 0.9194575, Test Acc: 0.9218581\n","AUC of 0is: 0.501740101301672\n","AUC of 1is: 0.501740101301672\n","Average auc 0.501740101301672\n","Epoch: 030, Train Loss: 0.3065859, Train Acc: 0.9189773, Test Acc: 0.9222182\n","AUC of 0is: 0.5040656826970209\n","AUC of 1is: 0.5040656826970209\n","Average auc 0.5040656826970209\n","Epoch: 031, Train Loss: 0.3068793, Train Acc: 0.9192974, Test Acc: 0.9225783\n","AUC of 0is: 0.5063912640923697\n","AUC of 1is: 0.5061961040611441\n","Average auc 0.5062936840767569\n","Epoch: 032, Train Loss: 0.3073128, Train Acc: 0.9196175, Test Acc: 0.9222182\n","AUC of 0is: 0.5040656826970209\n","AUC of 1is: 0.5040656826970209\n","Average auc 0.5040656826970209\n","Epoch: 033, Train Loss: 0.3067459, Train Acc: 0.9197776, Test Acc: 0.9222182\n","AUC of 0is: 0.506196104061144\n","AUC of 1is: 0.5083265254252672\n","Average auc 0.5072613147432057\n","Epoch: 034, Train Loss: 0.3068526, Train Acc: 0.9190574, Test Acc: 0.9211379\n","AUC of 0is: 0.503480202603344\n","AUC of 1is: 0.5032850425721185\n","Average auc 0.5033826225877313\n","Epoch: 035, Train Loss: 0.3069992, Train Acc: 0.9186572, Test Acc: 0.9211379\n","AUC of 0is: 0.5013497812392208\n","AUC of 1is: 0.5013497812392208\n","Average auc 0.5013497812392208\n","Epoch: 036, Train Loss: 0.3071393, Train Acc: 0.9189373, Test Acc: 0.9218581\n","AUC of 0is: 0.501740101301672\n","AUC of 1is: 0.5015449412704465\n","Average auc 0.5016425212860592\n","Epoch: 037, Train Loss: 0.3068060, Train Acc: 0.9177770, Test Acc: 0.9214980\n","AUC of 0is: 0.5036753626345696\n","AUC of 1is: 0.503480202603344\n","Average auc 0.5035777826189568\n","Epoch: 038, Train Loss: 0.3069594, Train Acc: 0.9188573, Test Acc: 0.9214980\n","AUC of 0is: 0.5100666267269394\n","AUC of 1is: 0.5100666267269394\n","Average auc 0.5100666267269394\n","Epoch: 039, Train Loss: 0.3071927, Train Acc: 0.9188973, Test Acc: 0.9214980\n","AUC of 0is: 0.5058057839986929\n","AUC of 1is: 0.5056106239674674\n","Average auc 0.5057082039830801\n","Epoch: 040, Train Loss: 0.3071260, Train Acc: 0.9196175, Test Acc: 0.9222182\n","AUC of 0is: 0.5149129495488627\n","AUC of 1is: 0.5149129495488627\n","Average auc 0.5149129495488627\n","Epoch: 041, Train Loss: 0.3072594, Train Acc: 0.9189373, Test Acc: 0.9225783\n","AUC of 0is: 0.5063912640923697\n","AUC of 1is: 0.5063912640923697\n","Average auc 0.5063912640923697\n","Epoch: 042, Train Loss: 0.3071926, Train Acc: 0.9176570, Test Acc: 0.9211379\n","AUC of 0is: 0.5013497812392208\n","AUC of 1is: 0.5013497812392208\n","Average auc 0.5013497812392208\n","Epoch: 043, Train Loss: 0.3074994, Train Acc: 0.9191774, Test Acc: 0.9229384\n","AUC of 0is: 0.5193689523083347\n","AUC of 1is: 0.5193689523083347\n","Average auc 0.5193689523083347\n","Epoch: 044, Train Loss: 0.3070527, Train Acc: 0.9191374, Test Acc: 0.9222182\n","AUC of 0is: 0.5083265254252674\n","AUC of 1is: 0.5083265254252672\n","Average auc 0.5083265254252674\n","Epoch: 045, Train Loss: 0.3072327, Train Acc: 0.9198976, Test Acc: 0.9232985\n","AUC of 0is: 0.5174336909754371\n","AUC of 1is: 0.517433690975437\n","Average auc 0.5174336909754371\n","Epoch: 046, Train Loss: 0.3073928, Train Acc: 0.9194575, Test Acc: 0.9243788\n","AUC of 0is: 0.52867127788973\n","AUC of 1is: 0.5309968592850789\n","Average auc 0.5298340685874044\n","Epoch: 047, Train Loss: 0.3068392, Train Acc: 0.9198576, Test Acc: 0.9236586\n","AUC of 0is: 0.5218896937349091\n","AUC of 1is: 0.5218896937349092\n","Average auc 0.5218896937349091\n","Epoch: 048, Train Loss: 0.3076327, Train Acc: 0.9197375, Test Acc: 0.9225783\n","AUC of 0is: 0.5149129495488627\n","AUC of 1is: 0.5149129495488627\n","Average auc 0.5149129495488627\n","Epoch: 049, Train Loss: 0.3069660, Train Acc: 0.9206178, Test Acc: 0.9229384\n","AUC of 0is: 0.5172385309442115\n","AUC of 1is: 0.5172385309442113\n","Average auc 0.5172385309442113\n","Epoch: 050, Train Loss: 0.3076595, Train Acc: 0.9197776, Test Acc: 0.9240187\n","AUC of 0is: 0.5284761178585045\n","AUC of 1is: 0.5308016992538533\n","Average auc 0.5296389085561789\n","Epoch: 051, Train Loss: 0.3078997, Train Acc: 0.9202977, Test Acc: 0.9240187\n","AUC of 0is: 0.5284761178585045\n","AUC of 1is: 0.5308016992538533\n","Average auc 0.5296389085561789\n","Epoch: 052, Train Loss: 0.3077262, Train Acc: 0.9207378, Test Acc: 0.9240187\n","AUC of 0is: 0.5263456964943812\n","AUC of 1is: 0.5263456964943812\n","Average auc 0.5263456964943812\n","Epoch: 053, Train Loss: 0.3077596, Train Acc: 0.9208179, Test Acc: 0.9243788\n","AUC of 0is: 0.52867127788973\n","AUC of 1is: 0.52867127788973\n","Average auc 0.52867127788973\n","Epoch: 054, Train Loss: 0.3082262, Train Acc: 0.9203777, Test Acc: 0.9243788\n","AUC of 0is: 0.5265408565256069\n","AUC of 1is: 0.5265408565256068\n","Average auc 0.5265408565256069\n","Epoch: 055, Train Loss: 0.3080195, Train Acc: 0.9198976, Test Acc: 0.9236586\n","AUC of 0is: 0.5261505364631557\n","AUC of 1is: 0.5261505364631556\n","Average auc 0.5261505364631556\n","Epoch: 056, Train Loss: 0.3076928, Train Acc: 0.9195775, Test Acc: 0.9236586\n","AUC of 0is: 0.5240201150990323\n","AUC of 1is: 0.5240201150990323\n","Average auc 0.5240201150990323\n","Epoch: 057, Train Loss: 0.3078795, Train Acc: 0.9207378, Test Acc: 0.9243788\n","AUC of 0is: 0.52867127788973\n","AUC of 1is: 0.52867127788973\n","Average auc 0.52867127788973\n","Epoch: 058, Train Loss: 0.3081997, Train Acc: 0.9204577, Test Acc: 0.9243788\n","AUC of 0is: 0.52867127788973\n","AUC of 1is: 0.52867127788973\n","Average auc 0.52867127788973\n","Epoch: 059, Train Loss: 0.3080931, Train Acc: 0.9212580, Test Acc: 0.9250990\n","AUC of 0is: 0.5375832834086742\n","AUC of 1is: 0.5373881233774486\n","Average auc 0.5374857033930613\n","Epoch: 060, Train Loss: 0.3082329, Train Acc: 0.9206178, Test Acc: 0.9243788\n","AUC of 0is: 0.5308016992538533\n","AUC of 1is: 0.5306065392226277\n","Average auc 0.5307041192382405\n","Epoch: 061, Train Loss: 0.3080195, Train Acc: 0.9212980, Test Acc: 0.9250990\n","AUC of 0is: 0.535452862044551\n","AUC of 1is: 0.5354528620445509\n","Average auc 0.5354528620445509\n","Epoch: 062, Train Loss: 0.3078327, Train Acc: 0.9214180, Test Acc: 0.9243788\n","AUC of 0is: 0.52867127788973\n","AUC of 1is: 0.52867127788973\n","Average auc 0.52867127788973\n","Epoch: 063, Train Loss: 0.3079596, Train Acc: 0.9213780, Test Acc: 0.9247389\n","AUC of 0is: 0.5331272806492021\n","AUC of 1is: 0.5333224406804277\n","Average auc 0.5332248606648149\n","Epoch: 064, Train Loss: 0.3080128, Train Acc: 0.9223382, Test Acc: 0.9247389\n","AUC of 0is: 0.5331272806492021\n","AUC of 1is: 0.5329321206179765\n","Average auc 0.5330297006335893\n","Epoch: 065, Train Loss: 0.3081196, Train Acc: 0.9215381, Test Acc: 0.9250990\n","AUC of 0is: 0.5333224406804277\n","AUC of 1is: 0.5333224406804277\n","Average auc 0.5333224406804277\n","Epoch: 066, Train Loss: 0.3082929, Train Acc: 0.9224183, Test Acc: 0.9250990\n","AUC of 0is: 0.5333224406804277\n","AUC of 1is: 0.5333224406804277\n","Average auc 0.5333224406804277\n","Epoch: 067, Train Loss: 0.3082195, Train Acc: 0.9217381, Test Acc: 0.9254591\n","AUC of 0is: 0.5356480220757766\n","AUC of 1is: 0.5356480220757766\n","Average auc 0.5356480220757766\n","Epoch: 068, Train Loss: 0.3082397, Train Acc: 0.9217381, Test Acc: 0.9247389\n","AUC of 0is: 0.5309968592850789\n","AUC of 1is: 0.5308016992538533\n","Average auc 0.5308992792694661\n","Epoch: 069, Train Loss: 0.3083263, Train Acc: 0.9224583, Test Acc: 0.9261793\n","AUC of 0is: 0.538168763502351\n","AUC of 1is: 0.5381687635023511\n","Average auc 0.5381687635023511\n","Epoch: 070, Train Loss: 0.3085998, Train Acc: 0.9214580, Test Acc: 0.9254591\n","AUC of 0is: 0.5356480220757766\n","AUC of 1is: 0.5356480220757766\n","Average auc 0.5356480220757766\n","Epoch: 071, Train Loss: 0.3083130, Train Acc: 0.9212180, Test Acc: 0.9250990\n","AUC of 0is: 0.5333224406804277\n","AUC of 1is: 0.5333224406804277\n","Average auc 0.5333224406804277\n","Epoch: 072, Train Loss: 0.3086930, Train Acc: 0.9212980, Test Acc: 0.9250990\n","AUC of 0is: 0.5333224406804277\n","AUC of 1is: 0.5333224406804277\n","Average auc 0.5333224406804277\n","Epoch: 073, Train Loss: 0.3083063, Train Acc: 0.9226584, Test Acc: 0.9254591\n","AUC of 0is: 0.5335176007116533\n","AUC of 1is: 0.5335176007116532\n","Average auc 0.5335176007116533\n","Epoch: 074, Train Loss: 0.3085731, Train Acc: 0.9225383, Test Acc: 0.9258192\n","AUC of 0is: 0.5337127607428789\n","AUC of 1is: 0.5337127607428789\n","Average auc 0.5337127607428789\n","Epoch: 075, Train Loss: 0.3078729, Train Acc: 0.9220182, Test Acc: 0.9254591\n","AUC of 0is: 0.5401040248352486\n","AUC of 1is: 0.5377784434398999\n","Average auc 0.5389412341375742\n","Epoch: 076, Train Loss: 0.3087464, Train Acc: 0.9236987, Test Acc: 0.9254591\n","AUC of 0is: 0.5464952889276183\n","AUC of 1is: 0.5441697075322695\n","Average auc 0.5453324982299439\n","Epoch: 077, Train Loss: 0.3081196, Train Acc: 0.9216581, Test Acc: 0.9247389\n","AUC of 0is: 0.5288664379209557\n","AUC of 1is: 0.5288664379209557\n","Average auc 0.5288664379209557\n","Epoch: 078, Train Loss: 0.3086064, Train Acc: 0.9233385, Test Acc: 0.9258192\n","AUC of 0is: 0.5379736034711253\n","AUC of 1is: 0.5379736034711254\n","Average auc 0.5379736034711253\n","Epoch: 079, Train Loss: 0.3086596, Train Acc: 0.9229385, Test Acc: 0.9261793\n","AUC of 0is: 0.5424296062305974\n","AUC of 1is: 0.5424296062305975\n","Average auc 0.5424296062305975\n","Epoch: 080, Train Loss: 0.3085930, Train Acc: 0.9233385, Test Acc: 0.9258192\n","AUC of 0is: 0.5401040248352486\n","AUC of 1is: 0.5401040248352487\n","Average auc 0.5401040248352487\n","Epoch: 081, Train Loss: 0.3085797, Train Acc: 0.9224183, Test Acc: 0.9258192\n","AUC of 0is: 0.5379736034711253\n","AUC of 1is: 0.5379736034711254\n","Average auc 0.5379736034711253\n","Epoch: 082, Train Loss: 0.3085664, Train Acc: 0.9227784, Test Acc: 0.9258192\n","AUC of 0is: 0.5401040248352486\n","AUC of 1is: 0.5401040248352487\n","Average auc 0.5401040248352487\n","Epoch: 083, Train Loss: 0.3087533, Train Acc: 0.9209379, Test Acc: 0.9258192\n","AUC of 0is: 0.5358431821070022\n","AUC of 1is: 0.5358431821070021\n","Average auc 0.5358431821070022\n","Epoch: 084, Train Loss: 0.3085463, Train Acc: 0.9230185, Test Acc: 0.9258192\n","AUC of 0is: 0.5379736034711253\n","AUC of 1is: 0.5379736034711254\n","Average auc 0.5379736034711253\n","Epoch: 085, Train Loss: 0.3088130, Train Acc: 0.9240988, Test Acc: 0.9265394\n","AUC of 0is: 0.5470807690212952\n","AUC of 1is: 0.5447551876259462\n","Average auc 0.5459179783236208\n","Epoch: 086, Train Loss: 0.3083731, Train Acc: 0.9232985, Test Acc: 0.9254591\n","AUC of 0is: 0.5356480220757766\n","AUC of 1is: 0.5356480220757766\n","Average auc 0.5356480220757766\n","Epoch: 087, Train Loss: 0.3092466, Train Acc: 0.9256992, Test Acc: 0.9268995\n","AUC of 0is: 0.5557976145090137\n","AUC of 1is: 0.5534720331136649\n","Average auc 0.5546348238113392\n","Epoch: 088, Train Loss: 0.3089332, Train Acc: 0.9248990, Test Acc: 0.9272596\n","AUC of 0is: 0.549406350416644\n","AUC of 1is: 0.549406350416644\n","Average auc 0.549406350416644\n","Epoch: 089, Train Loss: 0.3089398, Train Acc: 0.9244589, Test Acc: 0.9272596\n","AUC of 0is: 0.5451455076883975\n","AUC of 1is: 0.5451455076883974\n","Average auc 0.5451455076883975\n","Epoch: 090, Train Loss: 0.3085331, Train Acc: 0.9237787, Test Acc: 0.9272596\n","AUC of 0is: 0.5451455076883975\n","AUC of 1is: 0.5451455076883974\n","Average auc 0.5451455076883975\n","Epoch: 091, Train Loss: 0.3087997, Train Acc: 0.9232985, Test Acc: 0.9268995\n","AUC of 0is: 0.5428199262930486\n","AUC of 1is: 0.5428199262930486\n","Average auc 0.5428199262930486\n","Epoch: 092, Train Loss: 0.3089131, Train Acc: 0.9237387, Test Acc: 0.9261793\n","AUC of 0is: 0.5424296062305974\n","AUC of 1is: 0.5424296062305975\n","Average auc 0.5424296062305975\n","Epoch: 093, Train Loss: 0.3089799, Train Acc: 0.9244189, Test Acc: 0.9268995\n","AUC of 0is: 0.5492111903854184\n","AUC of 1is: 0.5492111903854183\n","Average auc 0.5492111903854184\n","Epoch: 094, Train Loss: 0.3086931, Train Acc: 0.9244189, Test Acc: 0.9261793\n","AUC of 0is: 0.5424296062305974\n","AUC of 1is: 0.5424296062305975\n","Average auc 0.5424296062305975\n","Epoch: 095, Train Loss: 0.3089399, Train Acc: 0.9252991, Test Acc: 0.9261793\n","AUC of 0is: 0.5424296062305974\n","AUC of 1is: 0.5424296062305975\n","Average auc 0.5424296062305975\n","Epoch: 096, Train Loss: 0.3088931, Train Acc: 0.9255392, Test Acc: 0.9279798\n","AUC of 0is: 0.5519270918432184\n","AUC of 1is: 0.5519270918432184\n","Average auc 0.5519270918432184\n","Epoch: 097, Train Loss: 0.3087464, Train Acc: 0.9260193, Test Acc: 0.9279798\n","AUC of 0is: 0.5519270918432184\n","AUC of 1is: 0.5519270918432184\n","Average auc 0.5519270918432184\n","Epoch: 098, Train Loss: 0.3085463, Train Acc: 0.9251391, Test Acc: 0.9276197\n","AUC of 0is: 0.5474710890837463\n","AUC of 1is: 0.5474710890837464\n","Average auc 0.5474710890837464\n","Epoch: 099, Train Loss: 0.3087797, Train Acc: 0.9248990, Test Acc: 0.9261793\n","AUC of 0is: 0.5424296062305974\n","AUC of 1is: 0.5424296062305975\n","Average auc 0.5424296062305975\n","Epoch: 100, Train Loss: 0.3091466, Train Acc: 0.9249790, Test Acc: 0.9258192\n","AUC of 0is: 0.5507561316558648\n","AUC of 1is: 0.5507561316558648\n","Average auc 0.5507561316558648\n","Epoch: 101, Train Loss: 0.3089131, Train Acc: 0.9260993, Test Acc: 0.9276197\n","AUC of 0is: 0.5474710890837463\n","AUC of 1is: 0.5497966704790952\n","Average auc 0.5486338797814208\n","Epoch: 102, Train Loss: 0.3089199, Train Acc: 0.9280599, Test Acc: 0.9283399\n","AUC of 0is: 0.5563830946026904\n","AUC of 1is: 0.5563830946026904\n","Average auc 0.5563830946026904\n","Epoch: 103, Train Loss: 0.3091865, Train Acc: 0.9280199, Test Acc: 0.9290601\n","AUC of 0is: 0.5567734146651417\n","AUC of 1is: 0.5567734146651417\n","Average auc 0.5567734146651417\n","Epoch: 104, Train Loss: 0.3091200, Train Acc: 0.9266995, Test Acc: 0.9283399\n","AUC of 0is: 0.5606439373309369\n","AUC of 1is: 0.5604487772997113\n","Average auc 0.5605463573153241\n","Epoch: 105, Train Loss: 0.3094265, Train Acc: 0.9261793, Test Acc: 0.9279798\n","AUC of 0is: 0.5561879345714649\n","AUC of 1is: 0.5561879345714649\n","Average auc 0.5561879345714649\n","Epoch: 106, Train Loss: 0.3092399, Train Acc: 0.9254991, Test Acc: 0.9276197\n","AUC of 0is: 0.5496015104478696\n","AUC of 1is: 0.5496015104478695\n","Average auc 0.5496015104478695\n","Epoch: 107, Train Loss: 0.3090066, Train Acc: 0.9291002, Test Acc: 0.9287000\n","AUC of 0is: 0.5629695187262858\n","AUC of 1is: 0.5629695187262859\n","Average auc 0.5629695187262858\n","Epoch: 108, Train Loss: 0.3089732, Train Acc: 0.9272997, Test Acc: 0.9276197\n","AUC of 0is: 0.5517319318119929\n","AUC of 1is: 0.5517319318119929\n","Average auc 0.5517319318119929\n","Epoch: 109, Train Loss: 0.3089998, Train Acc: 0.9285800, Test Acc: 0.9287000\n","AUC of 0is: 0.5587086759980393\n","AUC of 1is: 0.5587086759980393\n","Average auc 0.5587086759980393\n","Epoch: 110, Train Loss: 0.3095000, Train Acc: 0.9279798, Test Acc: 0.9290601\n","AUC of 0is: 0.5589038360292649\n","AUC of 1is: 0.558903836029265\n","Average auc 0.5589038360292649\n","Epoch: 111, Train Loss: 0.3095200, Train Acc: 0.9272596, Test Acc: 0.9276197\n","AUC of 0is: 0.5517319318119929\n","AUC of 1is: 0.5517319318119929\n","Average auc 0.5517319318119929\n","Epoch: 112, Train Loss: 0.3095801, Train Acc: 0.9270996, Test Acc: 0.9276197\n","AUC of 0is: 0.5581231959043625\n","AUC of 1is: 0.5581231959043625\n","Average auc 0.5581231959043625\n","Epoch: 113, Train Loss: 0.3096533, Train Acc: 0.9276998, Test Acc: 0.9290601\n","AUC of 0is: 0.5674255214857579\n","AUC of 1is: 0.5674255214857579\n","Average auc 0.5674255214857579\n","Epoch: 114, Train Loss: 0.3091666, Train Acc: 0.9278998, Test Acc: 0.9279798\n","AUC of 0is: 0.5561879345714649\n","AUC of 1is: 0.5561879345714649\n","Average auc 0.5561879345714649\n","Epoch: 115, Train Loss: 0.3093199, Train Acc: 0.9275798, Test Acc: 0.9279798\n","AUC of 0is: 0.5647096200279579\n","AUC of 1is: 0.5647096200279578\n","Average auc 0.5647096200279578\n","Epoch: 116, Train Loss: 0.3090332, Train Acc: 0.9285400, Test Acc: 0.9287000\n","AUC of 0is: 0.5676206815169835\n","AUC of 1is: 0.5627743586950602\n","Average auc 0.5651975201060219\n","Epoch: 117, Train Loss: 0.3096668, Train Acc: 0.9301004, Test Acc: 0.9315808\n","AUC of 0is: 0.5837045912531997\n","AUC of 1is: 0.5837045912531997\n","Average auc 0.5837045912531997\n","Epoch: 118, Train Loss: 0.3092399, Train Acc: 0.9293402, Test Acc: 0.9297803\n","AUC of 0is: 0.5786631084000509\n","AUC of 1is: 0.5763375270047019\n","Average auc 0.5775003177023763\n","Epoch: 119, Train Loss: 0.3096135, Train Acc: 0.9283400, Test Acc: 0.9290601\n","AUC of 0is: 0.5695559428498811\n","AUC of 1is: 0.569555942849881\n","Average auc 0.5695559428498811\n","Epoch: 120, Train Loss: 0.3093667, Train Acc: 0.9286600, Test Acc: 0.9287000\n","AUC of 0is: 0.5629695187262858\n","AUC of 1is: 0.5629695187262859\n","Average auc 0.5629695187262858\n","Epoch: 121, Train Loss: 0.3094866, Train Acc: 0.9286600, Test Acc: 0.9290601\n","AUC of 0is: 0.5695559428498811\n","AUC of 1is: 0.569555942849881\n","Average auc 0.5695559428498811\n","Epoch: 122, Train Loss: 0.3095867, Train Acc: 0.9301805, Test Acc: 0.9301404\n","AUC of 0is: 0.570141422943558\n","AUC of 1is: 0.5701414229435579\n","Average auc 0.570141422943558\n","Epoch: 123, Train Loss: 0.3095267, Train Acc: 0.9286600, Test Acc: 0.9297803\n","AUC of 0is: 0.5699462629123323\n","AUC of 1is: 0.5699462629123322\n","Average auc 0.5699462629123322\n","Epoch: 124, Train Loss: 0.3099535, Train Acc: 0.9282199, Test Acc: 0.9294202\n","AUC of 0is: 0.5697511028811066\n","AUC of 1is: 0.5720766842764555\n","Average auc 0.5709138935787811\n","Epoch: 125, Train Loss: 0.3096466, Train Acc: 0.9293802, Test Acc: 0.9287000\n","AUC of 0is: 0.5610342573933882\n","AUC of 1is: 0.5587086759980393\n","Average auc 0.5598714666957137\n","Epoch: 126, Train Loss: 0.3093933, Train Acc: 0.9285000, Test Acc: 0.9287000\n","AUC of 0is: 0.5629695187262858\n","AUC of 1is: 0.5629695187262859\n","Average auc 0.5629695187262858\n","Epoch: 127, Train Loss: 0.3095466, Train Acc: 0.9282199, Test Acc: 0.9305005\n","AUC of 0is: 0.5767278470671532\n","AUC of 1is: 0.5765326870359276\n","Average auc 0.5766302670515404\n","Epoch: 128, Train Loss: 0.3099067, Train Acc: 0.9297804, Test Acc: 0.9308606\n","AUC of 0is: 0.5726621643701324\n","AUC of 1is: 0.5726621643701324\n","Average auc 0.5726621643701324\n","Epoch: 129, Train Loss: 0.3096933, Train Acc: 0.9303805, Test Acc: 0.9301404\n","AUC of 0is: 0.5703365829747835\n","AUC of 1is: 0.5680110015794346\n","Average auc 0.5691737922771091\n","Epoch: 130, Train Loss: 0.3097467, Train Acc: 0.9307806, Test Acc: 0.9312207\n","AUC of 0is: 0.5771181671296044\n","AUC of 1is: 0.5794437485249533\n","Average auc 0.5782809578272788\n","Epoch: 131, Train Loss: 0.3094334, Train Acc: 0.9293402, Test Acc: 0.9301404\n","AUC of 0is: 0.5680110015794346\n","AUC of 1is: 0.5680110015794346\n","Average auc 0.5680110015794346\n","Epoch: 132, Train Loss: 0.3098468, Train Acc: 0.9291002, Test Acc: 0.9290601\n","AUC of 0is: 0.5610342573933882\n","AUC of 1is: 0.5610342573933882\n","Average auc 0.5610342573933882\n","Epoch: 133, Train Loss: 0.3098066, Train Acc: 0.9296203, Test Acc: 0.9290601\n","AUC of 0is: 0.5670352014233067\n","AUC of 1is: 0.5674255214857579\n","Average auc 0.5672303614545322\n","Epoch: 134, Train Loss: 0.3099999, Train Acc: 0.9305406, Test Acc: 0.9319409\n","AUC of 0is: 0.5837045912531997\n","AUC of 1is: 0.5837045912531997\n","Average auc 0.5837045912531997\n","Epoch: 135, Train Loss: 0.3096000, Train Acc: 0.9313808, Test Acc: 0.9312207\n","AUC of 0is: 0.5771181671296044\n","AUC of 1is: 0.5769230070983788\n","Average auc 0.5770205871139916\n","Epoch: 136, Train Loss: 0.3096069, Train Acc: 0.9293802, Test Acc: 0.9308606\n","AUC of 0is: 0.5790534284625021\n","AUC of 1is: 0.5788582684312765\n","Average auc 0.5789558484468893\n","Epoch: 137, Train Loss: 0.3099267, Train Acc: 0.9304205, Test Acc: 0.9315808\n","AUC of 0is: 0.5796389085561788\n","AUC of 1is: 0.5796389085561788\n","Average auc 0.5796389085561788\n","Epoch: 138, Train Loss: 0.3092934, Train Acc: 0.9313808, Test Acc: 0.9323010\n","AUC of 0is: 0.5926165967721438\n","AUC of 1is: 0.5926165967721438\n","Average auc 0.5926165967721438\n","Epoch: 139, Train Loss: 0.3097002, Train Acc: 0.9303805, Test Acc: 0.9308606\n","AUC of 0is: 0.5747925857342556\n","AUC of 1is: 0.5747925857342556\n","Average auc 0.5747925857342556\n","Epoch: 140, Train Loss: 0.3099934, Train Acc: 0.9305806, Test Acc: 0.9319409\n","AUC of 0is: 0.5902910153767951\n","AUC of 1is: 0.590291015376795\n","Average auc 0.5902910153767951\n","Epoch: 141, Train Loss: 0.3097599, Train Acc: 0.9305806, Test Acc: 0.9305005\n","AUC of 0is: 0.5767278470671532\n","AUC of 1is: 0.5767278470671532\n","Average auc 0.5767278470671532\n","Epoch: 142, Train Loss: 0.3099934, Train Acc: 0.9320610, Test Acc: 0.9323010\n","AUC of 0is: 0.5904861754080206\n","AUC of 1is: 0.5904861754080205\n","Average auc 0.5904861754080206\n","Epoch: 143, Train Loss: 0.3098201, Train Acc: 0.9309807, Test Acc: 0.9326611\n","AUC of 0is: 0.5864204927109997\n","AUC of 1is: 0.5864204927109997\n","Average auc 0.5864204927109997\n","Epoch: 144, Train Loss: 0.3098601, Train Acc: 0.9315408, Test Acc: 0.9315808\n","AUC of 0is: 0.5837045912531997\n","AUC of 1is: 0.5860301726485485\n","Average auc 0.5848673819508741\n","Epoch: 145, Train Loss: 0.3100936, Train Acc: 0.9327412, Test Acc: 0.9308606\n","AUC of 0is: 0.5811838498266253\n","AUC of 1is: 0.5811838498266253\n","Average auc 0.5811838498266253\n","Epoch: 146, Train Loss: 0.3100001, Train Acc: 0.9304606, Test Acc: 0.9297803\n","AUC of 0is: 0.5805983697329484\n","AUC of 1is: 0.5805983697329484\n","Average auc 0.5805983697329484\n","Epoch: 147, Train Loss: 0.3098800, Train Acc: 0.9318609, Test Acc: 0.9301404\n","AUC of 0is: 0.5829239511282973\n","AUC of 1is: 0.5829239511282973\n","Average auc 0.5829239511282973\n","Epoch: 148, Train Loss: 0.3099334, Train Acc: 0.9314208, Test Acc: 0.9305005\n","AUC of 0is: 0.5767278470671532\n","AUC of 1is: 0.5767278470671532\n","Average auc 0.5767278470671532\n","Epoch: 149, Train Loss: 0.3099867, Train Acc: 0.9323411, Test Acc: 0.9315808\n","AUC of 0is: 0.5837045912531997\n","AUC of 1is: 0.5837045912531997\n","Average auc 0.5837045912531997\n","Epoch: 150, Train Loss: 0.3098466, Train Acc: 0.9342616, Test Acc: 0.9301404\n","AUC of 0is: 0.5850543724924205\n","AUC of 1is: 0.5850543724924205\n","Average auc 0.5850543724924205\n","Epoch: 151, Train Loss: 0.3100533, Train Acc: 0.9341816, Test Acc: 0.9330212\n","AUC of 0is: 0.5993981809269648\n","AUC of 1is: 0.5993981809269648\n","Average auc 0.5993981809269648\n","Epoch: 152, Train Loss: 0.3101735, Train Acc: 0.9313008, Test Acc: 0.9297803\n","AUC of 0is: 0.5699462629123323\n","AUC of 1is: 0.5699462629123322\n","Average auc 0.5699462629123322\n","Epoch: 153, Train Loss: 0.3100335, Train Acc: 0.9323811, Test Acc: 0.9319409\n","AUC of 0is: 0.5860301726485485\n","AUC of 1is: 0.5860301726485485\n","Average auc 0.5860301726485485\n","Epoch: 154, Train Loss: 0.3102735, Train Acc: 0.9344217, Test Acc: 0.9312207\n","AUC of 0is: 0.5939663780113646\n","AUC of 1is: 0.5962919594067135\n","Average auc 0.5951291687090391\n","Epoch: 155, Train Loss: 0.3105137, Train Acc: 0.9353419, Test Acc: 0.9301404\n","AUC of 0is: 0.5957064793130367\n","AUC of 1is: 0.5957064793130367\n","Average auc 0.5957064793130367\n","Epoch: 156, Train Loss: 0.3101669, Train Acc: 0.9347017, Test Acc: 0.9301404\n","AUC of 0is: 0.5829239511282973\n","AUC of 1is: 0.5829239511282973\n","Average auc 0.5829239511282973\n","Epoch: 157, Train Loss: 0.3103068, Train Acc: 0.9327012, Test Acc: 0.9287000\n","AUC of 0is: 0.565099940090409\n","AUC of 1is: 0.565099940090409\n","Average auc 0.565099940090409\n","Epoch: 158, Train Loss: 0.3101068, Train Acc: 0.9336615, Test Acc: 0.9308606\n","AUC of 0is: 0.5854446925548717\n","AUC of 1is: 0.5877702739502205\n","Average auc 0.5866074832525461\n","Epoch: 159, Train Loss: 0.3101135, Train Acc: 0.9347817, Test Acc: 0.9315808\n","AUC of 0is: 0.6007479621661855\n","AUC of 1is: 0.6007479621661855\n","Average auc 0.6007479621661855\n","Epoch: 160, Train Loss: 0.3100868, Train Acc: 0.9355820, Test Acc: 0.9323010\n","AUC of 0is: 0.6096599676851298\n","AUC of 1is: 0.6096599676851298\n","Average auc 0.6096599676851298\n","Epoch: 161, Train Loss: 0.3097667, Train Acc: 0.9332213, Test Acc: 0.9305005\n","AUC of 0is: 0.5895103752518926\n","AUC of 1is: 0.5895103752518925\n","Average auc 0.5895103752518926\n","Epoch: 162, Train Loss: 0.3099934, Train Acc: 0.9355019, Test Acc: 0.9319409\n","AUC of 0is: 0.6052039649256576\n","AUC of 1is: 0.6052039649256576\n","Average auc 0.6052039649256576\n","Epoch: 163, Train Loss: 0.3106137, Train Acc: 0.9352619, Test Acc: 0.9308606\n","AUC of 0is: 0.5960967993754879\n","AUC of 1is: 0.5960967993754879\n","Average auc 0.5960967993754879\n","Epoch: 164, Train Loss: 0.3105468, Train Acc: 0.9346617, Test Acc: 0.9312207\n","AUC of 0is: 0.5962919594067135\n","AUC of 1is: 0.5962919594067135\n","Average auc 0.5962919594067135\n","Epoch: 165, Train Loss: 0.3103937, Train Acc: 0.9336615, Test Acc: 0.9326611\n","AUC of 0is: 0.6055942849881089\n","AUC of 1is: 0.6055942849881089\n","Average auc 0.6055942849881089\n","Epoch: 166, Train Loss: 0.3104136, Train Acc: 0.9350618, Test Acc: 0.9326611\n","AUC of 0is: 0.6055942849881089\n","AUC of 1is: 0.6055942849881089\n","Average auc 0.6055942849881089\n","Epoch: 167, Train Loss: 0.3104469, Train Acc: 0.9350218, Test Acc: 0.9305005\n","AUC of 0is: 0.593771217980139\n","AUC of 1is: 0.5937712179801391\n","Average auc 0.5937712179801391\n","Epoch: 168, Train Loss: 0.3103268, Train Acc: 0.9360621, Test Acc: 0.9315808\n","AUC of 0is: 0.6092696476226784\n","AUC of 1is: 0.6092696476226785\n","Average auc 0.6092696476226784\n","Epoch: 169, Train Loss: 0.3105604, Train Acc: 0.9343817, Test Acc: 0.9319409\n","AUC of 0is: 0.5966822794691646\n","AUC of 1is: 0.5966822794691647\n","Average auc 0.5966822794691646\n","Epoch: 170, Train Loss: 0.3104002, Train Acc: 0.9343016, Test Acc: 0.9301404\n","AUC of 0is: 0.5807935297641741\n","AUC of 1is: 0.580793529764174\n","Average auc 0.580793529764174\n","Epoch: 171, Train Loss: 0.3104470, Train Acc: 0.9361421, Test Acc: 0.9326611\n","AUC of 0is: 0.6119855490804785\n","AUC of 1is: 0.6119855490804785\n","Average auc 0.6119855490804785\n","Epoch: 172, Train Loss: 0.3103336, Train Acc: 0.9355820, Test Acc: 0.9319409\n","AUC of 0is: 0.6094648076539041\n","AUC of 1is: 0.6094648076539042\n","Average auc 0.6094648076539042\n","Epoch: 173, Train Loss: 0.3101602, Train Acc: 0.9337815, Test Acc: 0.9301404\n","AUC of 0is: 0.5831191111595229\n","AUC of 1is: 0.580793529764174\n","Average auc 0.5819563204618484\n","Epoch: 174, Train Loss: 0.3105470, Train Acc: 0.9340615, Test Acc: 0.9301404\n","AUC of 0is: 0.5850543724924205\n","AUC of 1is: 0.5850543724924205\n","Average auc 0.5850543724924205\n","Epoch: 175, Train Loss: 0.3109270, Train Acc: 0.9326212, Test Acc: 0.9294202\n","AUC of 0is: 0.578077628306374\n","AUC of 1is: 0.5782727883375997\n","Average auc 0.5781752083219869\n","Epoch: 176, Train Loss: 0.3106804, Train Acc: 0.9325811, Test Acc: 0.9319409\n","AUC of 0is: 0.5902910153767951\n","AUC of 1is: 0.590291015376795\n","Average auc 0.5902910153767951\n","Epoch: 177, Train Loss: 0.3101536, Train Acc: 0.9335814, Test Acc: 0.9308606\n","AUC of 0is: 0.587575113918995\n","AUC of 1is: 0.5873799538877694\n","Average auc 0.5874775339033822\n","Epoch: 178, Train Loss: 0.3105202, Train Acc: 0.9333414, Test Acc: 0.9312207\n","AUC of 0is: 0.5899006953143437\n","AUC of 1is: 0.5899006953143437\n","Average auc 0.5899006953143437\n","Epoch: 179, Train Loss: 0.3106405, Train Acc: 0.9357420, Test Acc: 0.9315808\n","AUC of 0is: 0.5943566980738159\n","AUC of 1is: 0.594356698073816\n","Average auc 0.594356698073816\n","Epoch: 180, Train Loss: 0.3104602, Train Acc: 0.9343016, Test Acc: 0.9315808\n","AUC of 0is: 0.5922262767096926\n","AUC of 1is: 0.5922262767096926\n","Average auc 0.5922262767096926\n","Epoch: 181, Train Loss: 0.3103868, Train Acc: 0.9359821, Test Acc: 0.9323010\n","AUC of 0is: 0.6053991249568833\n","AUC of 1is: 0.6053991249568833\n","Average auc 0.6053991249568833\n","Epoch: 182, Train Loss: 0.3105736, Train Acc: 0.9352619, Test Acc: 0.9308606\n","AUC of 0is: 0.6003576421037344\n","AUC of 1is: 0.6003576421037343\n","Average auc 0.6003576421037344\n","Epoch: 183, Train Loss: 0.3108002, Train Acc: 0.9337015, Test Acc: 0.9301404\n","AUC of 0is: 0.5765326870359275\n","AUC of 1is: 0.5765326870359276\n","Average auc 0.5765326870359275\n","Epoch: 184, Train Loss: 0.3104402, Train Acc: 0.9345017, Test Acc: 0.9305005\n","AUC of 0is: 0.5959016393442622\n","AUC of 1is: 0.5959016393442622\n","Average auc 0.5959016393442622\n","Epoch: 185, Train Loss: 0.3099668, Train Acc: 0.9345417, Test Acc: 0.9315808\n","AUC of 0is: 0.5943566980738159\n","AUC of 1is: 0.594356698073816\n","Average auc 0.594356698073816\n","Epoch: 186, Train Loss: 0.3104269, Train Acc: 0.9352219, Test Acc: 0.9337415\n","AUC of 0is: 0.608310186445909\n","AUC of 1is: 0.6083101864459088\n","Average auc 0.6083101864459088\n","Epoch: 187, Train Loss: 0.3107203, Train Acc: 0.9350618, Test Acc: 0.9323010\n","AUC of 0is: 0.5947470181362671\n","AUC of 1is: 0.5947470181362671\n","Average auc 0.5947470181362671\n","Epoch: 188, Train Loss: 0.3107803, Train Acc: 0.9353019, Test Acc: 0.9319409\n","AUC of 0is: 0.6009431221974112\n","AUC of 1is: 0.6009431221974112\n","Average auc 0.6009431221974112\n","Epoch: 189, Train Loss: 0.3105136, Train Acc: 0.9347417, Test Acc: 0.9333813\n","AUC of 0is: 0.601528602291088\n","AUC of 1is: 0.6017237623223136\n","Average auc 0.6016261823067008\n","Epoch: 190, Train Loss: 0.3103336, Train Acc: 0.9346617, Test Acc: 0.9283399\n","AUC of 0is: 0.5904698364286622\n","AUC of 1is: 0.5904698364286621\n","Average auc 0.5904698364286622\n","Epoch: 191, Train Loss: 0.3108736, Train Acc: 0.9353819, Test Acc: 0.9315808\n","AUC of 0is: 0.6007479621661855\n","AUC of 1is: 0.6007479621661855\n","Average auc 0.6007479621661855\n","Epoch: 192, Train Loss: 0.3108337, Train Acc: 0.9343416, Test Acc: 0.9308606\n","AUC of 0is: 0.5897055352831182\n","AUC of 1is: 0.5897055352831182\n","Average auc 0.5897055352831182\n","Epoch: 193, Train Loss: 0.3107936, Train Acc: 0.9355820, Test Acc: 0.9312207\n","AUC of 0is: 0.5939663780113646\n","AUC of 1is: 0.5941615380425903\n","Average auc 0.5940639580269775\n","Epoch: 194, Train Loss: 0.3106802, Train Acc: 0.9344217, Test Acc: 0.9308606\n","AUC of 0is: 0.5790534284625021\n","AUC of 1is: 0.5790534284625021\n","Average auc 0.5790534284625021\n","Epoch: 195, Train Loss: 0.3101068, Train Acc: 0.9338615, Test Acc: 0.9308606\n","AUC of 0is: 0.5833142711907485\n","AUC of 1is: 0.5833142711907485\n","Average auc 0.5833142711907485\n","Epoch: 196, Train Loss: 0.3106403, Train Acc: 0.9343817, Test Acc: 0.9319409\n","AUC of 0is: 0.5860301726485485\n","AUC of 1is: 0.5860301726485485\n","Average auc 0.5860301726485485\n","Epoch: 197, Train Loss: 0.3105537, Train Acc: 0.9352619, Test Acc: 0.9333813\n","AUC of 0is: 0.6081150264146833\n","AUC of 1is: 0.6081150264146833\n","Average auc 0.6081150264146833\n","Epoch: 198, Train Loss: 0.3108871, Train Acc: 0.9351019, Test Acc: 0.9319409\n","AUC of 0is: 0.5860301726485485\n","AUC of 1is: 0.5860301726485485\n","Average auc 0.5860301726485485\n","Epoch: 199, Train Loss: 0.3106603, Train Acc: 0.9347417, Test Acc: 0.9333813\n","AUC of 0is: 0.599788500989416\n","AUC of 1is: 0.597462919594067\n","Average auc 0.5986257102917416\n","Epoch: 200, Train Loss: 0.3104802, Train Acc: 0.9343817, Test Acc: 0.9323010\n","AUC of 0is: 0.5840949113156509\n","AUC of 1is: 0.5840949113156509\n","Average auc 0.5840949113156509\n","Epoch: 201, Train Loss: 0.3109005, Train Acc: 0.9371824, Test Acc: 0.9315808\n","AUC of 0is: 0.6071392262585552\n","AUC of 1is: 0.6071392262585552\n","Average auc 0.6071392262585552\n","Epoch: 202, Train Loss: 0.3109806, Train Acc: 0.9351419, Test Acc: 0.9312207\n","AUC of 0is: 0.5941615380425902\n","AUC of 1is: 0.5941615380425903\n","Average auc 0.5941615380425902\n","Epoch: 203, Train Loss: 0.3107804, Train Acc: 0.9352219, Test Acc: 0.9323010\n","AUC of 0is: 0.5968774395003903\n","AUC of 1is: 0.5968774395003903\n","Average auc 0.5968774395003903\n","Epoch: 204, Train Loss: 0.3109337, Train Acc: 0.9375426, Test Acc: 0.9315808\n","AUC of 0is: 0.6114000689868018\n","AUC of 1is: 0.6112049089555761\n","Average auc 0.6113024889711889\n","Epoch: 205, Train Loss: 0.3106804, Train Acc: 0.9361022, Test Acc: 0.9315808\n","AUC of 0is: 0.5900958553455694\n","AUC of 1is: 0.5924214367409182\n","Average auc 0.5912586460432439\n","Epoch: 206, Train Loss: 0.3107603, Train Acc: 0.9368623, Test Acc: 0.9319409\n","AUC of 0is: 0.6030735435615344\n","AUC of 1is: 0.6053991249568833\n","Average auc 0.6042363342592089\n","Epoch: 207, Train Loss: 0.3106937, Train Acc: 0.9360221, Test Acc: 0.9319409\n","AUC of 0is: 0.6179864931103971\n","AUC of 1is: 0.6179864931103971\n","Average auc 0.6179864931103971\n","Epoch: 208, Train Loss: 0.3111672, Train Acc: 0.9351419, Test Acc: 0.9319409\n","AUC of 0is: 0.6094648076539041\n","AUC of 1is: 0.6094648076539042\n","Average auc 0.6094648076539042\n","Epoch: 209, Train Loss: 0.3103403, Train Acc: 0.9355019, Test Acc: 0.9330212\n","AUC of 0is: 0.6079198663834577\n","AUC of 1is: 0.6079198663834576\n","Average auc 0.6079198663834577\n","Epoch: 210, Train Loss: 0.3109937, Train Acc: 0.9351019, Test Acc: 0.9297803\n","AUC of 0is: 0.5933808979176878\n","AUC of 1is: 0.5933808979176879\n","Average auc 0.5933808979176878\n","Epoch: 211, Train Loss: 0.3108604, Train Acc: 0.9349018, Test Acc: 0.9315808\n","AUC of 0is: 0.6028783835303089\n","AUC of 1is: 0.6028783835303089\n","Average auc 0.6028783835303089\n","Epoch: 212, Train Loss: 0.3108538, Train Acc: 0.9361421, Test Acc: 0.9323010\n","AUC of 0is: 0.6096599676851298\n","AUC of 1is: 0.6096599676851298\n","Average auc 0.6096599676851298\n","Epoch: 213, Train Loss: 0.3106669, Train Acc: 0.9357020, Test Acc: 0.9308606\n","AUC of 0is: 0.5918359566472414\n","AUC of 1is: 0.5918359566472414\n","Average auc 0.5918359566472414\n","Epoch: 214, Train Loss: 0.3103403, Train Acc: 0.9360621, Test Acc: 0.9319409\n","AUC of 0is: 0.6052039649256576\n","AUC of 1is: 0.6052039649256576\n","Average auc 0.6052039649256576\n","Epoch: 215, Train Loss: 0.3109604, Train Acc: 0.9349018, Test Acc: 0.9305005\n","AUC of 0is: 0.602292903436632\n","AUC of 1is: 0.602292903436632\n","Average auc 0.602292903436632\n","Epoch: 216, Train Loss: 0.3108738, Train Acc: 0.9347817, Test Acc: 0.9312207\n","AUC of 0is: 0.5941615380425902\n","AUC of 1is: 0.5941615380425903\n","Average auc 0.5941615380425902\n","Epoch: 217, Train Loss: 0.3108537, Train Acc: 0.9340615, Test Acc: 0.9315808\n","AUC of 0is: 0.5922262767096926\n","AUC of 1is: 0.5922262767096926\n","Average auc 0.5922262767096926\n","Epoch: 218, Train Loss: 0.3107871, Train Acc: 0.9366223, Test Acc: 0.9308606\n","AUC of 0is: 0.6046184848319809\n","AUC of 1is: 0.6046184848319809\n","Average auc 0.6046184848319809\n","Epoch: 219, Train Loss: 0.3109669, Train Acc: 0.9362622, Test Acc: 0.9315808\n","AUC of 0is: 0.5986175408020624\n","AUC of 1is: 0.5986175408020624\n","Average auc 0.5986175408020624\n","Epoch: 220, Train Loss: 0.3111270, Train Acc: 0.9361821, Test Acc: 0.9337415\n","AUC of 0is: 0.6019189223535393\n","AUC of 1is: 0.6019189223535392\n","Average auc 0.6019189223535393\n","Epoch: 221, Train Loss: 0.3110271, Train Acc: 0.9364622, Test Acc: 0.9297803\n","AUC of 0is: 0.604033004738304\n","AUC of 1is: 0.604033004738304\n","Average auc 0.604033004738304\n","Epoch: 222, Train Loss: 0.3107671, Train Acc: 0.9362622, Test Acc: 0.9315808\n","AUC of 0is: 0.6092696476226784\n","AUC of 1is: 0.6092696476226785\n","Average auc 0.6092696476226784\n","Epoch: 223, Train Loss: 0.3109872, Train Acc: 0.9367423, Test Acc: 0.9326611\n","AUC of 0is: 0.6077247063522321\n","AUC of 1is: 0.6077247063522321\n","Average auc 0.6077247063522321\n","Epoch: 224, Train Loss: 0.3110338, Train Acc: 0.9355019, Test Acc: 0.9308606\n","AUC of 0is: 0.5939663780113646\n","AUC of 1is: 0.5939663780113646\n","Average auc 0.5939663780113646\n","Epoch: 225, Train Loss: 0.3111939, Train Acc: 0.9344217, Test Acc: 0.9308606\n","AUC of 0is: 0.5918359566472414\n","AUC of 1is: 0.5918359566472414\n","Average auc 0.5918359566472414\n","Epoch: 226, Train Loss: 0.3108402, Train Acc: 0.9368623, Test Acc: 0.9287000\n","AUC of 0is: 0.6036426846758528\n","AUC of 1is: 0.601317103280504\n","Average auc 0.6024798939781784\n","Epoch: 227, Train Loss: 0.3110405, Train Acc: 0.9350618, Test Acc: 0.9297803\n","AUC of 0is: 0.5869896338253182\n","AUC of 1is: 0.5869896338253181\n","Average auc 0.5869896338253182\n","Epoch: 228, Train Loss: 0.3110605, Train Acc: 0.9366623, Test Acc: 0.9319409\n","AUC of 0is: 0.6075295463210064\n","AUC of 1is: 0.6075295463210064\n","Average auc 0.6075295463210064\n","Epoch: 229, Train Loss: 0.3109739, Train Acc: 0.9336214, Test Acc: 0.9312207\n","AUC of 0is: 0.5962919594067135\n","AUC of 1is: 0.5962919594067135\n","Average auc 0.5962919594067135\n","Epoch: 230, Train Loss: 0.3114938, Train Acc: 0.9349418, Test Acc: 0.9301404\n","AUC of 0is: 0.5999673220412832\n","AUC of 1is: 0.5999673220412831\n","Average auc 0.5999673220412831\n","Epoch: 231, Train Loss: 0.3110539, Train Acc: 0.9350618, Test Acc: 0.9279798\n","AUC of 0is: 0.5817529909409437\n","AUC of 1is: 0.5817529909409437\n","Average auc 0.5817529909409437\n","Epoch: 232, Train Loss: 0.3112072, Train Acc: 0.9361821, Test Acc: 0.9308606\n","AUC of 0is: 0.5959016393442622\n","AUC of 1is: 0.5984223807708368\n","Average auc 0.5971620100575494\n","Epoch: 233, Train Loss: 0.3109803, Train Acc: 0.9347017, Test Acc: 0.9312207\n","AUC of 0is: 0.5920311166784671\n","AUC of 1is: 0.5920311166784671\n","Average auc 0.5920311166784671\n","Epoch: 234, Train Loss: 0.3111138, Train Acc: 0.9368224, Test Acc: 0.9315808\n","AUC of 0is: 0.6092696476226784\n","AUC of 1is: 0.6092696476226785\n","Average auc 0.6092696476226784\n","Epoch: 235, Train Loss: 0.3114870, Train Acc: 0.9349018, Test Acc: 0.9305005\n","AUC of 0is: 0.5852495325236461\n","AUC of 1is: 0.5852495325236461\n","Average auc 0.5852495325236461\n","Epoch: 236, Train Loss: 0.3115005, Train Acc: 0.9360621, Test Acc: 0.9323010\n","AUC of 0is: 0.5990078608645135\n","AUC of 1is: 0.5990078608645136\n","Average auc 0.5990078608645135\n","Epoch: 237, Train Loss: 0.3114806, Train Acc: 0.9332213, Test Acc: 0.9301404\n","AUC of 0is: 0.5807935297641741\n","AUC of 1is: 0.580793529764174\n","Average auc 0.580793529764174\n","Epoch: 238, Train Loss: 0.3108536, Train Acc: 0.9375426, Test Acc: 0.9333813\n","AUC of 0is: 0.6187671332352995\n","AUC of 1is: 0.6185719732040739\n","Average auc 0.6186695532196866\n","Epoch: 239, Train Loss: 0.3111939, Train Acc: 0.9371824, Test Acc: 0.9315808\n","AUC of 0is: 0.5964871194379391\n","AUC of 1is: 0.5964871194379391\n","Average auc 0.5964871194379391\n","Epoch: 240, Train Loss: 0.3109270, Train Acc: 0.9338215, Test Acc: 0.9301404\n","AUC of 0is: 0.5786631084000509\n","AUC of 1is: 0.5786631084000509\n","Average auc 0.5786631084000509\n","Epoch: 241, Train Loss: 0.3109471, Train Acc: 0.9347017, Test Acc: 0.9308606\n","AUC of 0is: 0.5833142711907485\n","AUC of 1is: 0.5856398525860973\n","Average auc 0.584477061888423\n","Epoch: 242, Train Loss: 0.3112006, Train Acc: 0.9360221, Test Acc: 0.9308606\n","AUC of 0is: 0.5854446925548717\n","AUC of 1is: 0.5854446925548716\n","Average auc 0.5854446925548717\n","Epoch: 243, Train Loss: 0.3113737, Train Acc: 0.9348218, Test Acc: 0.9301404\n","AUC of 0is: 0.5807935297641741\n","AUC of 1is: 0.580793529764174\n","Average auc 0.580793529764174\n","Epoch: 244, Train Loss: 0.3112605, Train Acc: 0.9349418, Test Acc: 0.9308606\n","AUC of 0is: 0.5960967993754879\n","AUC of 1is: 0.5960967993754879\n","Average auc 0.5960967993754879\n","Epoch: 245, Train Loss: 0.3110805, Train Acc: 0.9365823, Test Acc: 0.9305005\n","AUC of 0is: 0.593771217980139\n","AUC of 1is: 0.5937712179801391\n","Average auc 0.5937712179801391\n","Epoch: 246, Train Loss: 0.3113206, Train Acc: 0.9363422, Test Acc: 0.9301404\n","AUC of 0is: 0.5978369006771599\n","AUC of 1is: 0.5978369006771599\n","Average auc 0.5978369006771599\n","Epoch: 247, Train Loss: 0.3111672, Train Acc: 0.9348618, Test Acc: 0.9294202\n","AUC of 0is: 0.5825336310658461\n","AUC of 1is: 0.5825336310658461\n","Average auc 0.5825336310658461\n","Epoch: 248, Train Loss: 0.3113473, Train Acc: 0.9331413, Test Acc: 0.9308606\n","AUC of 0is: 0.5854446925548717\n","AUC of 1is: 0.5854446925548716\n","Average auc 0.5854446925548717\n","Epoch: 249, Train Loss: 0.3110538, Train Acc: 0.9363822, Test Acc: 0.9297803\n","AUC of 0is: 0.5848592124611949\n","AUC of 1is: 0.5848592124611949\n","Average auc 0.5848592124611949\n","Epoch: 250, Train Loss: 0.3108138, Train Acc: 0.9361421, Test Acc: 0.9305005\n","AUC of 0is: 0.5916407966160158\n","AUC of 1is: 0.5916407966160158\n","Average auc 0.5916407966160158\n","Epoch: 251, Train Loss: 0.3111672, Train Acc: 0.9356620, Test Acc: 0.9312207\n","AUC of 0is: 0.5962919594067135\n","AUC of 1is: 0.5962919594067135\n","Average auc 0.5962919594067135\n","Epoch: 252, Train Loss: 0.3115339, Train Acc: 0.9353019, Test Acc: 0.9323010\n","AUC of 0is: 0.5990078608645135\n","AUC of 1is: 0.5990078608645136\n","Average auc 0.5990078608645135\n","Epoch: 253, Train Loss: 0.3110603, Train Acc: 0.9380227, Test Acc: 0.9305005\n","AUC of 0is: 0.5959016393442622\n","AUC of 1is: 0.5959016393442622\n","Average auc 0.5959016393442622\n","Epoch: 254, Train Loss: 0.3106603, Train Acc: 0.9329413, Test Acc: 0.9301404\n","AUC of 0is: 0.5765326870359275\n","AUC of 1is: 0.5765326870359276\n","Average auc 0.5765326870359275\n","Epoch: 255, Train Loss: 0.3116407, Train Acc: 0.9341416, Test Acc: 0.9312207\n","AUC of 0is: 0.5877702739502206\n","AUC of 1is: 0.5877702739502205\n","Average auc 0.5877702739502206\n","Epoch: 256, Train Loss: 0.3111605, Train Acc: 0.9354619, Test Acc: 0.9312207\n","AUC of 0is: 0.5877702739502206\n","AUC of 1is: 0.5877702739502205\n","Average auc 0.5877702739502206\n","Epoch: 257, Train Loss: 0.3116540, Train Acc: 0.9358221, Test Acc: 0.9301404\n","AUC of 0is: 0.589315215220667\n","AUC of 1is: 0.5893152152206669\n","Average auc 0.5893152152206669\n","Epoch: 258, Train Loss: 0.3114272, Train Acc: 0.9352219, Test Acc: 0.9312207\n","AUC of 0is: 0.5899006953143437\n","AUC of 1is: 0.5899006953143437\n","Average auc 0.5899006953143437\n","Epoch: 259, Train Loss: 0.3112871, Train Acc: 0.9340215, Test Acc: 0.9308606\n","AUC of 0is: 0.5918359566472414\n","AUC of 1is: 0.5918359566472414\n","Average auc 0.5918359566472414\n","Epoch: 260, Train Loss: 0.3110470, Train Acc: 0.9350218, Test Acc: 0.9315808\n","AUC of 0is: 0.5962919594067135\n","AUC of 1is: 0.5964871194379391\n","Average auc 0.5963895394223263\n","Epoch: 261, Train Loss: 0.3112338, Train Acc: 0.9340615, Test Acc: 0.9319409\n","AUC of 0is: 0.5881605940126717\n","AUC of 1is: 0.5881605940126718\n","Average auc 0.5881605940126717\n","Epoch: 262, Train Loss: 0.3112271, Train Acc: 0.9372625, Test Acc: 0.9319409\n","AUC of 0is: 0.6030735435615344\n","AUC of 1is: 0.6030735435615344\n","Average auc 0.6030735435615344\n","Epoch: 263, Train Loss: 0.3113205, Train Acc: 0.9345017, Test Acc: 0.9326611\n","AUC of 0is: 0.597072599531616\n","AUC of 1is: 0.5970725995316158\n","Average auc 0.597072599531616\n","Epoch: 264, Train Loss: 0.3113671, Train Acc: 0.9347017, Test Acc: 0.9308606\n","AUC of 0is: 0.5877702739502206\n","AUC of 1is: 0.5854446925548716\n","Average auc 0.5866074832525461\n","Epoch: 265, Train Loss: 0.3110205, Train Acc: 0.9368224, Test Acc: 0.9312207\n","AUC of 0is: 0.6048136448632064\n","AUC of 1is: 0.6048136448632064\n","Average auc 0.6048136448632064\n","Epoch: 266, Train Loss: 0.3114338, Train Acc: 0.9355019, Test Acc: 0.9294202\n","AUC of 0is: 0.591055316522339\n","AUC of 1is: 0.591055316522339\n","Average auc 0.591055316522339\n","Epoch: 267, Train Loss: 0.3115405, Train Acc: 0.9340215, Test Acc: 0.9312207\n","AUC of 0is: 0.5856398525860973\n","AUC of 1is: 0.5856398525860973\n","Average auc 0.5856398525860973\n","Epoch: 268, Train Loss: 0.3110070, Train Acc: 0.9342616, Test Acc: 0.9297803\n","AUC of 0is: 0.5933808979176878\n","AUC of 1is: 0.5933808979176879\n","Average auc 0.5933808979176878\n","Epoch: 269, Train Loss: 0.3117473, Train Acc: 0.9381827, Test Acc: 0.9319409\n","AUC of 0is: 0.6009431221974112\n","AUC of 1is: 0.6009431221974112\n","Average auc 0.6009431221974112\n","Epoch: 270, Train Loss: 0.3112405, Train Acc: 0.9329012, Test Acc: 0.9272596\n","AUC of 0is: 0.5643192999655067\n","AUC of 1is: 0.5643192999655066\n","Average auc 0.5643192999655067\n","Epoch: 271, Train Loss: 0.3112005, Train Acc: 0.9347417, Test Acc: 0.9283399\n","AUC of 0is: 0.579817729608046\n","AUC of 1is: 0.579817729608046\n","Average auc 0.579817729608046\n","Epoch: 272, Train Loss: 0.3114139, Train Acc: 0.9336214, Test Acc: 0.9294202\n","AUC of 0is: 0.5740119456093531\n","AUC of 1is: 0.5740119456093532\n","Average auc 0.5740119456093531\n","Epoch: 273, Train Loss: 0.3114605, Train Acc: 0.9343817, Test Acc: 0.9301404\n","AUC of 0is: 0.5850543724924205\n","AUC of 1is: 0.5850543724924205\n","Average auc 0.5850543724924205\n","Epoch: 274, Train Loss: 0.3113004, Train Acc: 0.9349018, Test Acc: 0.9305005\n","AUC of 0is: 0.5895103752518926\n","AUC of 1is: 0.5895103752518925\n","Average auc 0.5895103752518926\n","Epoch: 275, Train Loss: 0.3116606, Train Acc: 0.9342216, Test Acc: 0.9297803\n","AUC of 0is: 0.5829239511282973\n","AUC of 1is: 0.5805983697329484\n","Average auc 0.5817611604306229\n","Epoch: 276, Train Loss: 0.3117004, Train Acc: 0.9370224, Test Acc: 0.9308606\n","AUC of 0is: 0.5939663780113646\n","AUC of 1is: 0.5939663780113646\n","Average auc 0.5939663780113646\n","Epoch: 277, Train Loss: 0.3110204, Train Acc: 0.9343817, Test Acc: 0.9326611\n","AUC of 0is: 0.6013334422598624\n","AUC of 1is: 0.6013334422598624\n","Average auc 0.6013334422598624\n","Epoch: 278, Train Loss: 0.3115406, Train Acc: 0.9397432, Test Acc: 0.9330212\n","AUC of 0is: 0.6100502877475809\n","AUC of 1is: 0.610050287747581\n","Average auc 0.6100502877475809\n","Epoch: 279, Train Loss: 0.3117473, Train Acc: 0.9345017, Test Acc: 0.9312207\n","AUC of 0is: 0.5856398525860973\n","AUC of 1is: 0.5856398525860973\n","Average auc 0.5856398525860973\n","Epoch: 280, Train Loss: 0.3115073, Train Acc: 0.9352619, Test Acc: 0.9305005\n","AUC of 0is: 0.5873799538877694\n","AUC of 1is: 0.5873799538877694\n","Average auc 0.5873799538877694\n","Epoch: 281, Train Loss: 0.3113938, Train Acc: 0.9343416, Test Acc: 0.9297803\n","AUC of 0is: 0.5848592124611949\n","AUC of 1is: 0.5848592124611949\n","Average auc 0.5848592124611949\n","Epoch: 282, Train Loss: 0.3116406, Train Acc: 0.9343016, Test Acc: 0.9272596\n","AUC of 0is: 0.5664497213296299\n","AUC of 1is: 0.5664497213296298\n","Average auc 0.5664497213296298\n","Epoch: 283, Train Loss: 0.3109871, Train Acc: 0.9358621, Test Acc: 0.9305005\n","AUC of 0is: 0.5852495325236461\n","AUC of 1is: 0.5852495325236461\n","Average auc 0.5852495325236461\n","Epoch: 284, Train Loss: 0.3114472, Train Acc: 0.9354619, Test Acc: 0.9283399\n","AUC of 0is: 0.5776873082439228\n","AUC of 1is: 0.5776873082439229\n","Average auc 0.5776873082439229\n","Epoch: 285, Train Loss: 0.3119807, Train Acc: 0.9376625, Test Acc: 0.9301404\n","AUC of 0is: 0.5850543724924205\n","AUC of 1is: 0.5850543724924205\n","Average auc 0.5850543724924205\n","Epoch: 286, Train Loss: 0.3120274, Train Acc: 0.9366623, Test Acc: 0.9326611\n","AUC of 0is: 0.588550914075123\n","AUC of 1is: 0.588550914075123\n","Average auc 0.588550914075123\n","Epoch: 287, Train Loss: 0.3113004, Train Acc: 0.9319810, Test Acc: 0.9279798\n","AUC of 0is: 0.5625791986638347\n","AUC of 1is: 0.5625791986638345\n","Average auc 0.5625791986638347\n","Epoch: 288, Train Loss: 0.3116606, Train Acc: 0.9375826, Test Acc: 0.9319409\n","AUC of 0is: 0.598812700833288\n","AUC of 1is: 0.598812700833288\n","Average auc 0.598812700833288\n","Epoch: 289, Train Loss: 0.3116339, Train Acc: 0.9357820, Test Acc: 0.9287000\n","AUC of 0is: 0.5778824682751484\n","AUC of 1is: 0.5778824682751484\n","Average auc 0.5778824682751484\n","Epoch: 290, Train Loss: 0.3119740, Train Acc: 0.9373425, Test Acc: 0.9312207\n","AUC of 0is: 0.5962919594067135\n","AUC of 1is: 0.5962919594067135\n","Average auc 0.5962919594067135\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-a8e5212a386b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","\u001b[0;32m<ipython-input-53-a8e5212a386b>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader, epoch, test)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m       \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m#data.y = F.one_hot(data.y, num_classes = 6).type(torch.FloatTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             return Batch.from_data_list(batch, self.follow_batch,\n\u001b[0;32m---> 17\u001b[0;31m                                         self.exclude_keys)\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Append item to the attribute list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mslices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","import sklearn.metrics as metrics\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return torch.sigmoid(x)\n","\n","def train(epoch):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    correct = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = F.one_hot(data.y, num_classes = 2).type(torch.FloatTensor)\n","        #assert len(data.y) == len(train_loader.dataset), (str(len(train_loader.dataset))+\" \"+str(len(data.y)))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.5).float()\n","        loss = torch.nn.BCELoss()\n","        loss = loss(output_probs, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        correct += (output == data.y).float().sum()/6\n","    return correct / len(train_loader.dataset)\n","\n","\n","def test(loader, epoch, test=False):\n","    model.eval()\n","\n","    correct = 0\n","    if test: \n","      outs = []\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        #data.y = F.one_hot(data.y, num_classes = 6).type(torch.FloatTensor)\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.5).float()\n","        correct += (torch.argmax(output, dim=1) == data.y).float().sum()\n","        #print(output, data.y)\n","        if test: \n","          outs.append(output.cpu().detach().numpy())\n","    if test: \n","      outputs =np.concatenate(outs, axis=0 ).astype(float)\n","      np.savetxt(\"MCF-7_epoch\"+str(epoch)+\".csv\", outputs)\n","    return correct / len(loader.dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n","\n","for epoch in range(1, 5000):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader, epoch=epoch)\n","    test_acc = test(test_loader, epoch, test=True)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))\n","    y = np.zeros((len(test_dataset)))\n","    x = np.loadtxt(\"MCF-7_epoch\"+str(epoch)+\".csv\")\n","    for i in range(len(test_dataset)):\n","      y[i] = test_dataset[i].y\n","    y = torch.as_tensor(y)\n","    y = F.one_hot(y.long(), num_classes = 2).long()\n","    store_auc = 0\n","    for i in range(len(x[0,:])): \n","      auc = metrics.roc_auc_score(y[:,i], x[:,i])\n","      print(\"AUC of \"+str(i) +\"is:\", auc)\n","      store_auc += auc\n","    print(\"Average auc\", store_auc/2)\n","#print(y.shape)\n","    if auc >=0.9:\n","      break"]},{"cell_type":"markdown","metadata":{"id":"PuLokhRx1a9q"},"source":["#MOLT-4\n","Leucemia"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":491,"status":"ok","timestamp":1621788563687,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"_X6jofIn1bHx","outputId":"c7644d07-cdb5-4d23-a166-0e0b66c6f86f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Dataset: MCF-7(24993):\n","======================\n","Number of graphs: 24993\n","Number of features: 46\n","Number of classes: 2\n","Test Dataset: MCF-7(2777):\n","======================\n","Number of graphs: 2777\n","Number of features: 46\n","Number of classes: 2\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"MCF-7\").shuffle()\n","\n","train_dataset = dataset[len(dataset) // 10:]\n","test_dataset = dataset[:len(dataset) // 10]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":832860,"status":"error","timestamp":1621789617107,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"_l5tRh831bKY","outputId":"ae358a7d-12f7-4def-f553-3ed0916ebef1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 001, Train Loss: 0.3056255, Train Acc: 0.9179770, Test Acc: 0.9121354\n","MOLT of 0is: 0.5\n","MOLT of 1is: 0.5\n","Average auc 0.5\n","Epoch: 002, Train Loss: 0.3059923, Train Acc: 0.9179770, Test Acc: 0.9121354\n","MOLT of 0is: 0.5\n","MOLT of 1is: 0.5\n","Average auc 0.5\n","Epoch: 003, Train Loss: 0.3059790, Train Acc: 0.9184172, Test Acc: 0.9135758\n","MOLT of 0is: 0.5\n","MOLT of 1is: 0.5\n","Average auc 0.5\n","Epoch: 004, Train Loss: 0.3061123, Train Acc: 0.9184972, Test Acc: 0.9139359\n","MOLT of 0is: 0.5\n","MOLT of 1is: 0.5\n","Average auc 0.5\n","Epoch: 005, Train Loss: 0.3061191, Train Acc: 0.9182571, Test Acc: 0.9128556\n","MOLT of 0is: 0.5\n","MOLT of 1is: 0.5\n","Average auc 0.5\n","Epoch: 006, Train Loss: 0.3059189, Train Acc: 0.9186572, Test Acc: 0.9124955\n","MOLT of 0is: 0.5\n","MOLT of 1is: 0.5\n","Average auc 0.5\n","Epoch: 007, Train Loss: 0.3062590, Train Acc: 0.9184972, Test Acc: 0.9124955\n","MOLT of 0is: 0.5\n","MOLT of 1is: 0.5\n","Average auc 0.5\n","Epoch: 008, Train Loss: 0.3063257, Train Acc: 0.9184972, Test Acc: 0.9124955\n","MOLT of 0is: 0.5\n","MOLT of 1is: 0.5\n","Average auc 0.5\n","Epoch: 009, Train Loss: 0.3060523, Train Acc: 0.9193375, Test Acc: 0.9139359\n","MOLT of 0is: 0.4998026056060008\n","MOLT of 1is: 0.4998026056060008\n","Average auc 0.4998026056060008\n","Epoch: 010, Train Loss: 0.3062057, Train Acc: 0.9182571, Test Acc: 0.9124955\n","MOLT of 0is: 0.4996052112120016\n","MOLT of 1is: 0.4996052112120016\n","Average auc 0.4996052112120016\n","Epoch: 011, Train Loss: 0.3065591, Train Acc: 0.9189373, Test Acc: 0.9128556\n","MOLT of 0is: 0.5016543915398705\n","MOLT of 1is: 0.5016543915398705\n","Average auc 0.5016543915398705\n","Epoch: 012, Train Loss: 0.3064325, Train Acc: 0.9183372, Test Acc: 0.9124955\n","MOLT of 0is: 0.4998026056060008\n","MOLT of 1is: 0.4998026056060008\n","Average auc 0.4998026056060008\n","Epoch: 013, Train Loss: 0.3063724, Train Acc: 0.9184972, Test Acc: 0.9124955\n","MOLT of 0is: 0.4994078168180024\n","MOLT of 1is: 0.4994078168180024\n","Average auc 0.4994078168180024\n","Epoch: 014, Train Loss: 0.3068126, Train Acc: 0.9185372, Test Acc: 0.9124955\n","MOLT of 0is: 0.5014569971458712\n","MOLT of 1is: 0.5014569971458712\n","Average auc 0.5014569971458712\n","Epoch: 015, Train Loss: 0.3064924, Train Acc: 0.9189373, Test Acc: 0.9124955\n","MOLT of 0is: 0.4998026056060008\n","MOLT of 1is: 0.4998026056060008\n","Average auc 0.4998026056060008\n","Epoch: 016, Train Loss: 0.3062792, Train Acc: 0.9187373, Test Acc: 0.9124955\n","MOLT of 0is: 0.501259602751872\n","MOLT of 1is: 0.501259602751872\n","Average auc 0.501259602751872\n","Epoch: 017, Train Loss: 0.3068994, Train Acc: 0.9184572, Test Acc: 0.9128556\n","MOLT of 0is: 0.4994078168180024\n","MOLT of 1is: 0.4994078168180024\n","Average auc 0.4994078168180024\n","Epoch: 018, Train Loss: 0.3066860, Train Acc: 0.9189373, Test Acc: 0.9132157\n","MOLT of 0is: 0.4998026056060008\n","MOLT of 1is: 0.5\n","Average auc 0.4999013028030004\n","Epoch: 019, Train Loss: 0.3064926, Train Acc: 0.9189773, Test Acc: 0.9124955\n","MOLT of 0is: 0.5018517859338697\n","MOLT of 1is: 0.5018517859338697\n","Average auc 0.5018517859338697\n","Epoch: 020, Train Loss: 0.3068126, Train Acc: 0.9186972, Test Acc: 0.9124955\n","MOLT of 0is: 0.5016543915398705\n","MOLT of 1is: 0.5014569971458712\n","Average auc 0.5015556943428708\n","Epoch: 021, Train Loss: 0.3068993, Train Acc: 0.9188573, Test Acc: 0.9124955\n","MOLT of 0is: 0.5018517859338697\n","MOLT of 1is: 0.5018517859338697\n","Average auc 0.5018517859338697\n","Epoch: 022, Train Loss: 0.3068993, Train Acc: 0.9188173, Test Acc: 0.9124955\n","MOLT of 0is: 0.5014569971458712\n","MOLT of 1is: 0.5014569971458712\n","Average auc 0.5014569971458712\n","Epoch: 023, Train Loss: 0.3069594, Train Acc: 0.9185772, Test Acc: 0.9124955\n","MOLT of 0is: 0.501259602751872\n","MOLT of 1is: 0.501259602751872\n","Average auc 0.501259602751872\n","Epoch: 024, Train Loss: 0.3069193, Train Acc: 0.9190173, Test Acc: 0.9128556\n","MOLT of 0is: 0.5018517859338697\n","MOLT of 1is: 0.5018517859338697\n","Average auc 0.5018517859338697\n","Epoch: 025, Train Loss: 0.3069526, Train Acc: 0.9190173, Test Acc: 0.9128556\n","MOLT of 0is: 0.501259602751872\n","MOLT of 1is: 0.501259602751872\n","Average auc 0.501259602751872\n","Epoch: 026, Train Loss: 0.3066526, Train Acc: 0.9191374, Test Acc: 0.9132157\n","MOLT of 0is: 0.501259602751872\n","MOLT of 1is: 0.5010622083578729\n","Average auc 0.5011609055548725\n","Epoch: 027, Train Loss: 0.3068595, Train Acc: 0.9187373, Test Acc: 0.9124955\n","MOLT of 0is: 0.501259602751872\n","MOLT of 1is: 0.501259602751872\n","Average auc 0.501259602751872\n","Epoch: 028, Train Loss: 0.3068926, Train Acc: 0.9192574, Test Acc: 0.9124955\n","MOLT of 0is: 0.5014569971458712\n","MOLT of 1is: 0.5014569971458712\n","Average auc 0.5014569971458712\n","Epoch: 029, Train Loss: 0.3069327, Train Acc: 0.9194575, Test Acc: 0.9128556\n","MOLT of 0is: 0.5014569971458712\n","MOLT of 1is: 0.5014569971458712\n","Average auc 0.5014569971458712\n","Epoch: 030, Train Loss: 0.3070327, Train Acc: 0.9198576, Test Acc: 0.9139359\n","MOLT of 0is: 0.501259602751872\n","MOLT of 1is: 0.501259602751872\n","Average auc 0.501259602751872\n","Epoch: 031, Train Loss: 0.3073128, Train Acc: 0.9193774, Test Acc: 0.9128556\n","MOLT of 0is: 0.5010622083578729\n","MOLT of 1is: 0.5008648139638736\n","Average auc 0.5009635111608732\n","Epoch: 032, Train Loss: 0.3070062, Train Acc: 0.9192574, Test Acc: 0.9132157\n","MOLT of 0is: 0.501259602751872\n","MOLT of 1is: 0.501259602751872\n","Average auc 0.501259602751872\n","Epoch: 033, Train Loss: 0.3071993, Train Acc: 0.9194975, Test Acc: 0.9135758\n","MOLT of 0is: 0.5008648139638736\n","MOLT of 1is: 0.5004700251758751\n","Average auc 0.5006674195698744\n","Epoch: 034, Train Loss: 0.3073861, Train Acc: 0.9190173, Test Acc: 0.9124955\n","MOLT of 0is: 0.5006674195698744\n","MOLT of 1is: 0.5004700251758751\n","Average auc 0.5005687223728748\n","Epoch: 035, Train Loss: 0.3070593, Train Acc: 0.9194575, Test Acc: 0.9139359\n","MOLT of 0is: 0.5010622083578729\n","MOLT of 1is: 0.5010622083578729\n","Average auc 0.5010622083578729\n","Epoch: 036, Train Loss: 0.3072327, Train Acc: 0.9191774, Test Acc: 0.9124955\n","MOLT of 0is: 0.5014569971458712\n","MOLT of 1is: 0.501259602751872\n","Average auc 0.5013582999488716\n","Epoch: 037, Train Loss: 0.3075329, Train Acc: 0.9193774, Test Acc: 0.9128556\n","MOLT of 0is: 0.5008648139638736\n","MOLT of 1is: 0.5006674195698744\n","Average auc 0.500766116766874\n","Epoch: 038, Train Loss: 0.3069060, Train Acc: 0.9196575, Test Acc: 0.9135758\n","MOLT of 0is: 0.4996804475998783\n","MOLT of 1is: 0.4996804475998783\n","Average auc 0.4996804475998783\n","Epoch: 039, Train Loss: 0.3071927, Train Acc: 0.9193375, Test Acc: 0.9135758\n","MOLT of 0is: 0.5004700251758751\n","MOLT of 1is: 0.500272630781876\n","Average auc 0.5003713279788755\n","Epoch: 040, Train Loss: 0.3074394, Train Acc: 0.9204177, Test Acc: 0.9142960\n","MOLT of 0is: 0.4994830532058791\n","MOLT of 1is: 0.4994830532058791\n","Average auc 0.4994830532058791\n","Epoch: 041, Train Loss: 0.3072860, Train Acc: 0.9195775, Test Acc: 0.9128556\n","MOLT of 0is: 0.5010622083578729\n","MOLT of 1is: 0.5010622083578729\n","Average auc 0.5010622083578729\n","Epoch: 042, Train Loss: 0.3074594, Train Acc: 0.9194174, Test Acc: 0.9128556\n","MOLT of 0is: 0.5010622083578729\n","MOLT of 1is: 0.5010622083578729\n","Average auc 0.5010622083578729\n","Epoch: 043, Train Loss: 0.3073994, Train Acc: 0.9197776, Test Acc: 0.9139359\n","MOLT of 0is: 0.5011374447457496\n","MOLT of 1is: 0.5011374447457495\n","Average auc 0.5011374447457495\n","Epoch: 044, Train Loss: 0.3075930, Train Acc: 0.9202977, Test Acc: 0.9150162\n","MOLT of 0is: 0.5004700251758751\n","MOLT of 1is: 0.5004700251758751\n","Average auc 0.5004700251758751\n","Epoch: 045, Train Loss: 0.3075595, Train Acc: 0.9202577, Test Acc: 0.9153763\n","MOLT of 0is: 0.4994830532058791\n","MOLT of 1is: 0.4994830532058791\n","Average auc 0.4994830532058791\n","Epoch: 046, Train Loss: 0.3076329, Train Acc: 0.9204177, Test Acc: 0.9150162\n","MOLT of 0is: 0.5003478671697527\n","MOLT of 1is: 0.5001504727757534\n","Average auc 0.500249169972753\n","Epoch: 047, Train Loss: 0.3074194, Train Acc: 0.9197375, Test Acc: 0.9142960\n","MOLT of 0is: 0.5011374447457496\n","MOLT of 1is: 0.5011374447457495\n","Average auc 0.5011374447457495\n","Epoch: 048, Train Loss: 0.3078863, Train Acc: 0.9195775, Test Acc: 0.9139359\n","MOLT of 0is: 0.5017296279277471\n","MOLT of 1is: 0.5017296279277471\n","Average auc 0.5017296279277471\n","Epoch: 049, Train Loss: 0.3075662, Train Acc: 0.9200976, Test Acc: 0.9142960\n","MOLT of 0is: 0.501532233533748\n","MOLT of 1is: 0.5015322335337479\n","Average auc 0.501532233533748\n","Epoch: 050, Train Loss: 0.3074929, Train Acc: 0.9200976, Test Acc: 0.9139359\n","MOLT of 0is: 0.5001504727757534\n","MOLT of 1is: 0.49995307838175423\n","Average auc 0.5000517755787538\n","Epoch: 051, Train Loss: 0.3079996, Train Acc: 0.9206578, Test Acc: 0.9153763\n","MOLT of 0is: 0.5023970474976215\n","MOLT of 1is: 0.5021996531036224\n","Average auc 0.502298350300622\n","Epoch: 052, Train Loss: 0.3077463, Train Acc: 0.9212180, Test Acc: 0.9160965\n","MOLT of 0is: 0.5005452615637519\n","MOLT of 1is: 0.5005452615637519\n","Average auc 0.5005452615637519\n","Epoch: 053, Train Loss: 0.3077262, Train Acc: 0.9208978, Test Acc: 0.9157364\n","MOLT of 0is: 0.5003478671697527\n","MOLT of 1is: 0.5003478671697527\n","Average auc 0.5003478671697527\n","Epoch: 054, Train Loss: 0.3081062, Train Acc: 0.9215780, Test Acc: 0.9168167\n","MOLT of 0is: 0.5007426559577511\n","MOLT of 1is: 0.5007426559577511\n","Average auc 0.5007426559577511\n","Epoch: 055, Train Loss: 0.3079728, Train Acc: 0.9220982, Test Acc: 0.9160965\n","MOLT of 0is: 0.5003478671697527\n","MOLT of 1is: 0.5003478671697527\n","Average auc 0.5003478671697527\n","Epoch: 056, Train Loss: 0.3083396, Train Acc: 0.9226584, Test Acc: 0.9160965\n","MOLT of 0is: 0.5007426559577511\n","MOLT of 1is: 0.5007426559577511\n","Average auc 0.5007426559577511\n","Epoch: 057, Train Loss: 0.3079863, Train Acc: 0.9210579, Test Acc: 0.9157364\n","MOLT of 0is: 0.5003478671697527\n","MOLT of 1is: 0.5003478671697527\n","Average auc 0.5003478671697527\n","Epoch: 058, Train Loss: 0.3081397, Train Acc: 0.9220982, Test Acc: 0.9164566\n","MOLT of 0is: 0.5003478671697527\n","MOLT of 1is: 0.5003478671697527\n","Average auc 0.5003478671697527\n","Epoch: 059, Train Loss: 0.3080397, Train Acc: 0.9229785, Test Acc: 0.9171768\n","MOLT of 0is: 0.49916350080575744\n","MOLT of 1is: 0.4989661064117582\n","Average auc 0.4990648036087578\n","Epoch: 060, Train Loss: 0.3078929, Train Acc: 0.9216981, Test Acc: 0.9153763\n","MOLT of 0is: 0.4999530783817543\n","MOLT of 1is: 0.49975568398775505\n","Average auc 0.49985438118475467\n","Epoch: 061, Train Loss: 0.3081797, Train Acc: 0.9222983, Test Acc: 0.9168167\n","MOLT of 0is: 0.49955828959375587\n","MOLT of 1is: 0.4995582895937558\n","Average auc 0.4995582895937558\n","Epoch: 062, Train Loss: 0.3084931, Train Acc: 0.9229385, Test Acc: 0.9193374\n","MOLT of 0is: 0.5003478671697527\n","MOLT of 1is: 0.5003478671697527\n","Average auc 0.5003478671697527\n","Epoch: 063, Train Loss: 0.3079796, Train Acc: 0.9228584, Test Acc: 0.9171768\n","MOLT of 0is: 0.4997556839877551\n","MOLT of 1is: 0.49995307838175423\n","Average auc 0.49985438118475467\n","Epoch: 064, Train Loss: 0.3082397, Train Acc: 0.9224183, Test Acc: 0.9178970\n","MOLT of 0is: 0.4997556839877551\n","MOLT of 1is: 0.4995582895937558\n","Average auc 0.49965698679075543\n","Epoch: 065, Train Loss: 0.3084396, Train Acc: 0.9228184, Test Acc: 0.9182571\n","MOLT of 0is: 0.4999530783817543\n","MOLT of 1is: 0.49995307838175423\n","Average auc 0.4999530783817543\n","Epoch: 066, Train Loss: 0.3083064, Train Acc: 0.9231785, Test Acc: 0.9175369\n","MOLT of 0is: 0.4999530783817543\n","MOLT of 1is: 0.49995307838175423\n","Average auc 0.4999530783817543\n","Epoch: 067, Train Loss: 0.3086332, Train Acc: 0.9228984, Test Acc: 0.9175369\n","MOLT of 0is: 0.4997556839877551\n","MOLT of 1is: 0.49975568398775505\n","Average auc 0.49975568398775505\n","Epoch: 068, Train Loss: 0.3082597, Train Acc: 0.9229785, Test Acc: 0.9175369\n","MOLT of 0is: 0.5001504727757534\n","MOLT of 1is: 0.49995307838175423\n","Average auc 0.5000517755787538\n","Epoch: 069, Train Loss: 0.3082597, Train Acc: 0.9225783, Test Acc: 0.9178970\n","MOLT of 0is: 0.4997556839877551\n","MOLT of 1is: 0.49975568398775505\n","Average auc 0.49975568398775505\n","Epoch: 070, Train Loss: 0.3085997, Train Acc: 0.9232985, Test Acc: 0.9175369\n","MOLT of 0is: 0.4997556839877551\n","MOLT of 1is: 0.49975568398775505\n","Average auc 0.49975568398775505\n","Epoch: 071, Train Loss: 0.3084598, Train Acc: 0.9245789, Test Acc: 0.9196975\n","MOLT of 0is: 0.4999530783817543\n","MOLT of 1is: 0.49995307838175423\n","Average auc 0.4999530783817543\n","Epoch: 072, Train Loss: 0.3087465, Train Acc: 0.9248990, Test Acc: 0.9193374\n","MOLT of 0is: 0.4999530783817543\n","MOLT of 1is: 0.49995307838175423\n","Average auc 0.4999530783817543\n","Epoch: 073, Train Loss: 0.3085331, Train Acc: 0.9253791, Test Acc: 0.9211379\n","MOLT of 0is: 0.5001504727757534\n","MOLT of 1is: 0.5001504727757534\n","Average auc 0.5001504727757534\n","Epoch: 074, Train Loss: 0.3085063, Train Acc: 0.9235786, Test Acc: 0.9186172\n","MOLT of 0is: 0.5003478671697527\n","MOLT of 1is: 0.5003478671697527\n","Average auc 0.5003478671697527\n","Epoch: 075, Train Loss: 0.3087799, Train Acc: 0.9235786, Test Acc: 0.9182571\n","MOLT of 0is: 0.49916350080575744\n","MOLT of 1is: 0.4993608951997566\n","Average auc 0.49926219800275706\n","Epoch: 076, Train Loss: 0.3086265, Train Acc: 0.9237787, Test Acc: 0.9186172\n","MOLT of 0is: 0.5024722838854982\n","MOLT of 1is: 0.5004231035576294\n","Average auc 0.5014476937215638\n","Epoch: 077, Train Loss: 0.3087199, Train Acc: 0.9233385, Test Acc: 0.9171768\n","MOLT of 0is: 0.5005452615637519\n","MOLT of 1is: 0.5005452615637519\n","Average auc 0.5005452615637519\n","Epoch: 078, Train Loss: 0.3083330, Train Acc: 0.9258193, Test Acc: 0.9189773\n","MOLT of 0is: 0.49955828959375587\n","MOLT of 1is: 0.4995582895937558\n","Average auc 0.4995582895937558\n","Epoch: 079, Train Loss: 0.3085196, Train Acc: 0.9253791, Test Acc: 0.9200576\n","MOLT of 0is: 0.5012126811336263\n","MOLT of 1is: 0.5012126811336263\n","Average auc 0.5012126811336263\n","Epoch: 080, Train Loss: 0.3087199, Train Acc: 0.9249790, Test Acc: 0.9207778\n","MOLT of 0is: 0.49916350080575744\n","MOLT of 1is: 0.4991635008057574\n","Average auc 0.49916350080575744\n","Epoch: 081, Train Loss: 0.3085331, Train Acc: 0.9238587, Test Acc: 0.9171768\n","MOLT of 0is: 0.49955828959375587\n","MOLT of 1is: 0.4995582895937558\n","Average auc 0.4995582895937558\n","Epoch: 082, Train Loss: 0.3086532, Train Acc: 0.9264594, Test Acc: 0.9214980\n","MOLT of 0is: 0.49916350080575744\n","MOLT of 1is: 0.4991635008057574\n","Average auc 0.49916350080575744\n","Epoch: 083, Train Loss: 0.3088598, Train Acc: 0.9261793, Test Acc: 0.9193374\n","MOLT of 0is: 0.4999530783817543\n","MOLT of 1is: 0.49995307838175423\n","Average auc 0.4999530783817543\n","Epoch: 084, Train Loss: 0.3086465, Train Acc: 0.9254192, Test Acc: 0.9189773\n","MOLT of 0is: 0.49955828959375587\n","MOLT of 1is: 0.4995582895937558\n","Average auc 0.4995582895937558\n","Epoch: 085, Train Loss: 0.3085600, Train Acc: 0.9228184, Test Acc: 0.9182571\n","MOLT of 0is: 0.49857131762375984\n","MOLT of 1is: 0.49876871201775896\n","Average auc 0.4986700148207594\n","Epoch: 086, Train Loss: 0.3087198, Train Acc: 0.9249390, Test Acc: 0.9178970\n","MOLT of 0is: 0.4997556839877551\n","MOLT of 1is: 0.49975568398775505\n","Average auc 0.49975568398775505\n","Epoch: 087, Train Loss: 0.3090799, Train Acc: 0.9228984, Test Acc: 0.9175369\n","MOLT of 0is: 0.5061758557532375\n","MOLT of 1is: 0.5063732501472368\n","Average auc 0.5062745529502372\n","Epoch: 088, Train Loss: 0.3087065, Train Acc: 0.9242988, Test Acc: 0.9164566\n","MOLT of 0is: 0.5006204979516287\n","MOLT of 1is: 0.5006204979516287\n","Average auc 0.5006204979516287\n","Epoch: 089, Train Loss: 0.3084197, Train Acc: 0.9245389, Test Acc: 0.9182571\n","MOLT of 0is: 0.49916350080575744\n","MOLT of 1is: 0.4991635008057574\n","Average auc 0.49916350080575744\n","Epoch: 090, Train Loss: 0.3089600, Train Acc: 0.9239787, Test Acc: 0.9186172\n","MOLT of 0is: 0.49916350080575744\n","MOLT of 1is: 0.4991635008057574\n","Average auc 0.49916350080575744\n","Epoch: 091, Train Loss: 0.3086464, Train Acc: 0.9236587, Test Acc: 0.9171768\n","MOLT of 0is: 0.4993608951997567\n","MOLT of 1is: 0.4993608951997566\n","Average auc 0.4993608951997567\n","Epoch: 092, Train Loss: 0.3089398, Train Acc: 0.9239787, Test Acc: 0.9178970\n","MOLT of 0is: 0.49896610641175826\n","MOLT of 1is: 0.4989661064117582\n","Average auc 0.4989661064117582\n","Epoch: 093, Train Loss: 0.3092799, Train Acc: 0.9238987, Test Acc: 0.9168167\n","MOLT of 0is: 0.5004231035576294\n","MOLT of 1is: 0.5004231035576294\n","Average auc 0.5004231035576294\n","Epoch: 094, Train Loss: 0.3088332, Train Acc: 0.9249790, Test Acc: 0.9182571\n","MOLT of 0is: 0.49896610641175826\n","MOLT of 1is: 0.4989661064117582\n","Average auc 0.4989661064117582\n","Epoch: 095, Train Loss: 0.3089065, Train Acc: 0.9242588, Test Acc: 0.9175369\n","MOLT of 0is: 0.5012126811336263\n","MOLT of 1is: 0.5012126811336263\n","Average auc 0.5012126811336263\n","Epoch: 096, Train Loss: 0.3090399, Train Acc: 0.9274197, Test Acc: 0.9200576\n","MOLT of 0is: 0.4983739232297606\n","MOLT of 1is: 0.49837392322976054\n","Average auc 0.4983739232297606\n","Epoch: 097, Train Loss: 0.3091266, Train Acc: 0.9258993, Test Acc: 0.9189773\n","MOLT of 0is: 0.5006204979516287\n","MOLT of 1is: 0.5006204979516287\n","Average auc 0.5006204979516287\n","Epoch: 098, Train Loss: 0.3087732, Train Acc: 0.9261793, Test Acc: 0.9189773\n","MOLT of 0is: 0.49896610641175826\n","MOLT of 1is: 0.4989661064117582\n","Average auc 0.4989661064117582\n","Epoch: 099, Train Loss: 0.3089732, Train Acc: 0.9254991, Test Acc: 0.9182571\n","MOLT of 0is: 0.49896610641175826\n","MOLT of 1is: 0.4989661064117582\n","Average auc 0.4989661064117582\n","Epoch: 100, Train Loss: 0.3092534, Train Acc: 0.9250190, Test Acc: 0.9164566\n","MOLT of 0is: 0.5039292810313695\n","MOLT of 1is: 0.5039292810313696\n","Average auc 0.5039292810313696\n","Epoch: 101, Train Loss: 0.3089467, Train Acc: 0.9265795, Test Acc: 0.9193374\n","MOLT of 0is: 0.49896610641175826\n","MOLT of 1is: 0.49876871201775896\n","Average auc 0.4988674092147586\n","Epoch: 102, Train Loss: 0.3094067, Train Acc: 0.9264194, Test Acc: 0.9214980\n","MOLT of 0is: 0.497781740047763\n","MOLT of 1is: 0.49778174004776293\n","Average auc 0.497781740047763\n","Epoch: 103, Train Loss: 0.3090998, Train Acc: 0.9265394, Test Acc: 0.9189773\n","MOLT of 0is: 0.5026696782794975\n","MOLT of 1is: 0.5026696782794975\n","Average auc 0.5026696782794975\n","Epoch: 104, Train Loss: 0.3093067, Train Acc: 0.9267395, Test Acc: 0.9196975\n","MOLT of 0is: 0.49923873719363415\n","MOLT of 1is: 0.501287917521503\n","Average auc 0.5002633273575686\n","Epoch: 105, Train Loss: 0.3092267, Train Acc: 0.9280999, Test Acc: 0.9196975\n","MOLT of 0is: 0.504324069819368\n","MOLT of 1is: 0.504324069819368\n","Average auc 0.504324069819368\n","Epoch: 106, Train Loss: 0.3091333, Train Acc: 0.9273397, Test Acc: 0.9204177\n","MOLT of 0is: 0.5008178923456279\n","MOLT of 1is: 0.5008178923456279\n","Average auc 0.5008178923456279\n","Epoch: 107, Train Loss: 0.3091132, Train Acc: 0.9257792, Test Acc: 0.9175369\n","MOLT of 0is: 0.5035344922433711\n","MOLT of 1is: 0.5035344922433711\n","Average auc 0.5035344922433711\n","Epoch: 108, Train Loss: 0.3091600, Train Acc: 0.9246189, Test Acc: 0.9171768\n","MOLT of 0is: 0.5026696782794975\n","MOLT of 1is: 0.5026696782794975\n","Average auc 0.5026696782794975\n","Epoch: 109, Train Loss: 0.3094735, Train Acc: 0.9250590, Test Acc: 0.9189773\n","MOLT of 0is: 0.504324069819368\n","MOLT of 1is: 0.504324069819368\n","Average auc 0.504324069819368\n","Epoch: 110, Train Loss: 0.3093065, Train Acc: 0.9257792, Test Acc: 0.9189773\n","MOLT of 0is: 0.5045214642133671\n","MOLT of 1is: 0.5045214642133671\n","Average auc 0.5045214642133671\n","Epoch: 111, Train Loss: 0.3095801, Train Acc: 0.9279398, Test Acc: 0.9182571\n","MOLT of 0is: 0.5026696782794975\n","MOLT of 1is: 0.5026696782794975\n","Average auc 0.5026696782794975\n","Epoch: 112, Train Loss: 0.3087798, Train Acc: 0.9272196, Test Acc: 0.9214980\n","MOLT of 0is: 0.5014853119155023\n","MOLT of 1is: 0.5014853119155023\n","Average auc 0.5014853119155023\n","Epoch: 113, Train Loss: 0.3091600, Train Acc: 0.9284600, Test Acc: 0.9207778\n","MOLT of 0is: 0.5029423090613734\n","MOLT of 1is: 0.5029423090613735\n","Average auc 0.5029423090613734\n","Epoch: 114, Train Loss: 0.3092799, Train Acc: 0.9267795, Test Acc: 0.9204177\n","MOLT of 0is: 0.4998309203756318\n","MOLT of 1is: 0.4998309203756318\n","Average auc 0.4998309203756318\n","Epoch: 115, Train Loss: 0.3094667, Train Acc: 0.9270596, Test Acc: 0.9196975\n","MOLT of 0is: 0.5027449146673743\n","MOLT of 1is: 0.5027449146673743\n","Average auc 0.5027449146673743\n","Epoch: 116, Train Loss: 0.3094201, Train Acc: 0.9274597, Test Acc: 0.9204177\n","MOLT of 0is: 0.5031397034553727\n","MOLT of 1is: 0.5033370978493719\n","Average auc 0.5032384006523722\n","Epoch: 117, Train Loss: 0.3093533, Train Acc: 0.9262994, Test Acc: 0.9178970\n","MOLT of 0is: 0.5038071230252471\n","MOLT of 1is: 0.503807123025247\n","Average auc 0.503807123025247\n","Epoch: 118, Train Loss: 0.3091799, Train Acc: 0.9269395, Test Acc: 0.9204177\n","MOLT of 0is: 0.5015605483033789\n","MOLT of 1is: 0.5017579426973783\n","Average auc 0.5016592455003785\n","Epoch: 119, Train Loss: 0.3096734, Train Acc: 0.9274197, Test Acc: 0.9193374\n","MOLT of 0is: 0.502547520273375\n","MOLT of 1is: 0.502547520273375\n","Average auc 0.502547520273375\n","Epoch: 120, Train Loss: 0.3095733, Train Acc: 0.9283800, Test Acc: 0.9207778\n","MOLT of 0is: 0.49904134279963497\n","MOLT of 1is: 0.499041342799635\n","Average auc 0.49904134279963497\n","Epoch: 121, Train Loss: 0.3095267, Train Acc: 0.9264594, Test Acc: 0.9189773\n","MOLT of 0is: 0.502547520273375\n","MOLT of 1is: 0.502547520273375\n","Average auc 0.502547520273375\n","Epoch: 122, Train Loss: 0.3097335, Train Acc: 0.9272596, Test Acc: 0.9196975\n","MOLT of 0is: 0.5031397034553727\n","MOLT of 1is: 0.5031397034553727\n","Average auc 0.5031397034553727\n","Epoch: 123, Train Loss: 0.3095668, Train Acc: 0.9252591, Test Acc: 0.9171768\n","MOLT of 0is: 0.5006957343395054\n","MOLT of 1is: 0.5006957343395054\n","Average auc 0.5006957343395054\n","Epoch: 124, Train Loss: 0.3091667, Train Acc: 0.9269796, Test Acc: 0.9186172\n","MOLT of 0is: 0.5027449146673743\n","MOLT of 1is: 0.502547520273375\n","Average auc 0.5026462174703746\n","Epoch: 125, Train Loss: 0.3093400, Train Acc: 0.9267795, Test Acc: 0.9193374\n","MOLT of 0is: 0.5018801007035006\n","MOLT of 1is: 0.5020774950974999\n","Average auc 0.5019787979005003\n","Epoch: 126, Train Loss: 0.3095000, Train Acc: 0.9282599, Test Acc: 0.9204177\n","MOLT of 0is: 0.5057810669652392\n","MOLT of 1is: 0.5057810669652391\n","Average auc 0.5057810669652392\n","Epoch: 127, Train Loss: 0.3099602, Train Acc: 0.9277798, Test Acc: 0.9196975\n","MOLT of 0is: 0.5043993062072447\n","MOLT of 1is: 0.5042019118132455\n","Average auc 0.5043006090102451\n","Epoch: 128, Train Loss: 0.3095200, Train Acc: 0.9284199, Test Acc: 0.9222182\n","MOLT of 0is: 0.5031397034553727\n","MOLT of 1is: 0.5031397034553727\n","Average auc 0.5031397034553727\n","Epoch: 129, Train Loss: 0.3100537, Train Acc: 0.9277798, Test Acc: 0.9229384\n","MOLT of 0is: 0.5055836725712399\n","MOLT of 1is: 0.5057810669652391\n","Average auc 0.5056823697682395\n","Epoch: 130, Train Loss: 0.3095600, Train Acc: 0.9297003, Test Acc: 0.9247389\n","MOLT of 0is: 0.502547520273375\n","MOLT of 1is: 0.5023501258793758\n","Average auc 0.5024488230763754\n","Epoch: 131, Train Loss: 0.3098668, Train Acc: 0.9274197, Test Acc: 0.9222182\n","MOLT of 0is: 0.5035344922433711\n","MOLT of 1is: 0.5035344922433711\n","Average auc 0.5035344922433711\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-30f7aded1dd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","\u001b[0;32m<ipython-input-58-30f7aded1dd2>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader, epoch, test)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m       \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m#data.y = F.one_hot(data.y, num_classes = 6).type(torch.FloatTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataloader.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             return Batch.from_data_list(batch, self.follow_batch,\n\u001b[0;32m---> 17\u001b[0;31m                                         self.exclude_keys)\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mcat_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcat_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcat_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","import sklearn.metrics as metrics\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return torch.sigmoid(x)\n","\n","def train(epoch):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    correct = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = F.one_hot(data.y, num_classes = 2).type(torch.FloatTensor)\n","        #assert len(data.y) == len(train_loader.dataset), (str(len(train_loader.dataset))+\" \"+str(len(data.y)))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.5).float()\n","        loss = torch.nn.BCELoss()\n","        loss = loss(output_probs, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        correct += (output == data.y).float().sum()/6\n","    return correct / len(train_loader.dataset)\n","\n","\n","def test(loader, epoch, test=False):\n","    model.eval()\n","\n","    correct = 0\n","    if test: \n","      outs = []\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        #data.y = F.one_hot(data.y, num_classes = 6).type(torch.FloatTensor)\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.5).float()\n","        correct += (torch.argmax(output, dim=1) == data.y).float().sum()\n","        #print(output, data.y)\n","        if test: \n","          outs.append(output.cpu().detach().numpy())\n","    if test: \n","      outputs =np.concatenate(outs, axis=0 ).astype(float)\n","      np.savetxt(\"MOLT_epoch\"+str(epoch)+\".csv\", outputs)\n","    return correct / len(loader.dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n","\n","for epoch in range(1, 5000):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader, epoch=epoch)\n","    test_acc = test(test_loader, epoch, test=True)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))\n","    y = np.zeros((len(test_dataset)))\n","    x = np.loadtxt(\"MCF-7_epoch\"+str(epoch)+\".csv\")\n","    for i in range(len(test_dataset)):\n","      y[i] = test_dataset[i].y\n","    y = torch.as_tensor(y)\n","    y = F.one_hot(y.long(), num_classes = 2).long()\n","    store_auc = 0\n","    for i in range(len(x[0,:])): \n","      auc = metrics.roc_auc_score(y[:,i], x[:,i])\n","      print(\"MOLT of \"+str(i) +\"is:\", auc)\n","      store_auc += auc\n","    print(\"Average auc\", store_auc/2)\n","#print(y.shape)\n","    if auc >=0.9:\n","      break"]},{"cell_type":"markdown","metadata":{"id":"ysNbfd8kAnhp"},"source":["# AIDS\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1xn4JnvAApKo"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UcGqoPohApZl"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NE2Q2YqBApcn"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"MRqHeKf1C3tm"},"source":["# Mutagenicity"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Biy6RxXTAmWm"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2045,"status":"ok","timestamp":1621667787595,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"7X56RY7O52Dk","outputId":"1b4759dc-f3f0-4cf4-e84f-60ff85050a99"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/Mutagenicity.zip\n","Extracting ./Mutagenicity/Mutagenicity.zip\n","Processing...\n","Done!\n","Train Dataset: Mutagenicity(3904):\n","======================\n","Number of graphs: 3904\n","Number of features: 14\n","Number of classes: 2\n","Test Dataset: P388H(4147):\n","======================\n","Number of graphs: 4147\n","Number of features: 73\n","Number of classes: 2\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import MoleculeNet\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"Mutagenicity\").shuffle()\n","\n","train_dataset = dataset[len(dataset) // 10:]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hAzRYfaosgxo"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"elapsed":637,"status":"error","timestamp":1621668021405,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"tdwrn-Zu6Iqe","outputId":"692df102-c81e-4f71-918e-e41c6b7d1136"},"outputs":[{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-0f99f6ac04ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m364\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(1, 1001):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":420,"status":"ok","timestamp":1621638885915,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"_TXenuwl7H5Y","outputId":"5a5b50fb-e0e4-4176-cc1f-cd330121cb70"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Dataset: AIDS(1800):\n","======================\n","Number of graphs: 1800\n","Number of features: 38\n","Number of classes: 2\n","Test Dataset: AIDS(200):\n","======================\n","Number of graphs: 200\n","Number of features: 38\n","Number of classes: 2\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import MoleculeNet\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"AIDS\").shuffle()\n","test_dataset = dataset[:len(dataset) // 10]\n","train_dataset = dataset[len(dataset) // 10:]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67504,"status":"ok","timestamp":1621638956998,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"-fQ4TlEisgz8","outputId":"95a5c95e-3c0d-4229-e1a9-bfeab8e749fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 001, Train Loss: 0.9208113, Train Acc: 0.4227778, Test Acc: 0.4300000\n","Epoch: 002, Train Loss: 0.6673507, Train Acc: 0.7283333, Test Acc: 0.7350000\n","Epoch: 003, Train Loss: 0.5849178, Train Acc: 0.7400000, Test Acc: 0.7400000\n","Epoch: 004, Train Loss: 0.5287516, Train Acc: 0.7933333, Test Acc: 0.8100000\n","Epoch: 005, Train Loss: 0.4770865, Train Acc: 0.8300000, Test Acc: 0.8600000\n","Epoch: 006, Train Loss: 0.4336108, Train Acc: 0.8088889, Test Acc: 0.8350000\n","Epoch: 007, Train Loss: 0.4078016, Train Acc: 0.9411111, Test Acc: 0.9450000\n","Epoch: 008, Train Loss: 0.3789038, Train Acc: 0.9627778, Test Acc: 0.9500000\n","Epoch: 009, Train Loss: 0.3754142, Train Acc: 0.9844444, Test Acc: 0.9850000\n","Epoch: 010, Train Loss: 0.3343692, Train Acc: 0.9438889, Test Acc: 0.9200000\n","Epoch: 011, Train Loss: 0.3270785, Train Acc: 0.9472222, Test Acc: 0.9200000\n","Epoch: 012, Train Loss: 0.3043898, Train Acc: 0.9372222, Test Acc: 0.9050000\n","Epoch: 013, Train Loss: 0.2835328, Train Acc: 0.9211111, Test Acc: 0.9000000\n","Epoch: 014, Train Loss: 0.2696671, Train Acc: 0.9494444, Test Acc: 0.9250000\n","Epoch: 015, Train Loss: 0.2428701, Train Acc: 0.9183333, Test Acc: 0.9000000\n","Epoch: 016, Train Loss: 0.2335417, Train Acc: 0.9266667, Test Acc: 0.9000000\n","Epoch: 017, Train Loss: 0.2280720, Train Acc: 0.9438889, Test Acc: 0.9150000\n","Epoch: 018, Train Loss: 0.2122332, Train Acc: 0.9400000, Test Acc: 0.9100000\n","Epoch: 019, Train Loss: 0.1994646, Train Acc: 0.9527778, Test Acc: 0.9300000\n","Epoch: 020, Train Loss: 0.1807380, Train Acc: 0.9283333, Test Acc: 0.9150000\n","Epoch: 021, Train Loss: 0.1708280, Train Acc: 0.9522222, Test Acc: 0.9400000\n","Epoch: 022, Train Loss: 0.1571530, Train Acc: 0.9355556, Test Acc: 0.9150000\n","Epoch: 023, Train Loss: 0.1574078, Train Acc: 0.9455556, Test Acc: 0.9300000\n","Epoch: 024, Train Loss: 0.1397052, Train Acc: 0.9411111, Test Acc: 0.9150000\n","Epoch: 025, Train Loss: 0.1267054, Train Acc: 0.9500000, Test Acc: 0.9300000\n","Epoch: 026, Train Loss: 0.1260741, Train Acc: 0.9438889, Test Acc: 0.9200000\n","Epoch: 027, Train Loss: 0.1175656, Train Acc: 0.9622222, Test Acc: 0.9550000\n","Epoch: 028, Train Loss: 0.1211634, Train Acc: 0.9561111, Test Acc: 0.9400000\n","Epoch: 029, Train Loss: 0.1025911, Train Acc: 0.9572222, Test Acc: 0.9400000\n","Epoch: 030, Train Loss: 0.0987325, Train Acc: 0.9794444, Test Acc: 0.9800000\n","Epoch: 031, Train Loss: 0.0981593, Train Acc: 0.9738889, Test Acc: 0.9700000\n","Epoch: 032, Train Loss: 0.0958905, Train Acc: 0.9711111, Test Acc: 0.9650000\n","Epoch: 033, Train Loss: 0.0968908, Train Acc: 0.9672222, Test Acc: 0.9600000\n","Epoch: 034, Train Loss: 0.0840328, Train Acc: 0.9822222, Test Acc: 0.9750000\n","Epoch: 035, Train Loss: 0.0875940, Train Acc: 0.9822222, Test Acc: 0.9850000\n","Epoch: 036, Train Loss: 0.0789958, Train Acc: 0.9744444, Test Acc: 0.9750000\n","Epoch: 037, Train Loss: 0.0736216, Train Acc: 0.9883333, Test Acc: 0.9950000\n","Epoch: 038, Train Loss: 0.0755305, Train Acc: 0.9827778, Test Acc: 0.9750000\n","Epoch: 039, Train Loss: 0.0690521, Train Acc: 0.9838889, Test Acc: 0.9750000\n","Epoch: 040, Train Loss: 0.0680344, Train Acc: 0.9888889, Test Acc: 1.0000000\n","Epoch: 041, Train Loss: 0.0667555, Train Acc: 0.9888889, Test Acc: 0.9950000\n","Epoch: 042, Train Loss: 0.0656647, Train Acc: 0.9916667, Test Acc: 1.0000000\n","Epoch: 043, Train Loss: 0.0642151, Train Acc: 0.9888889, Test Acc: 0.9950000\n","Epoch: 044, Train Loss: 0.0626730, Train Acc: 0.9933333, Test Acc: 1.0000000\n","Epoch: 045, Train Loss: 0.0547140, Train Acc: 0.9922222, Test Acc: 1.0000000\n","Epoch: 046, Train Loss: 0.0573754, Train Acc: 0.9827778, Test Acc: 0.9800000\n","Epoch: 047, Train Loss: 0.0540643, Train Acc: 0.9855556, Test Acc: 0.9900000\n","Epoch: 048, Train Loss: 0.0469396, Train Acc: 0.9866667, Test Acc: 0.9950000\n","Epoch: 049, Train Loss: 0.0524783, Train Acc: 0.9883333, Test Acc: 0.9950000\n","Epoch: 050, Train Loss: 0.0510087, Train Acc: 0.9927778, Test Acc: 1.0000000\n","Epoch: 051, Train Loss: 0.0470917, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 052, Train Loss: 0.0497545, Train Acc: 0.9911111, Test Acc: 1.0000000\n","Epoch: 053, Train Loss: 0.0559363, Train Acc: 0.9905556, Test Acc: 1.0000000\n","Epoch: 054, Train Loss: 0.0538136, Train Acc: 0.9933333, Test Acc: 1.0000000\n","Epoch: 055, Train Loss: 0.0496394, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 056, Train Loss: 0.0524469, Train Acc: 0.9933333, Test Acc: 1.0000000\n","Epoch: 057, Train Loss: 0.0473403, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 058, Train Loss: 0.0462938, Train Acc: 0.9922222, Test Acc: 1.0000000\n","Epoch: 059, Train Loss: 0.0458985, Train Acc: 0.9933333, Test Acc: 1.0000000\n","Epoch: 060, Train Loss: 0.0436208, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 061, Train Loss: 0.0475837, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 062, Train Loss: 0.0440173, Train Acc: 0.9944444, Test Acc: 1.0000000\n","Epoch: 063, Train Loss: 0.0440421, Train Acc: 0.9933333, Test Acc: 1.0000000\n","Epoch: 064, Train Loss: 0.0514410, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 065, Train Loss: 0.0444200, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 066, Train Loss: 0.0410878, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 067, Train Loss: 0.0449709, Train Acc: 0.9944444, Test Acc: 1.0000000\n","Epoch: 068, Train Loss: 0.0412881, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 069, Train Loss: 0.0415730, Train Acc: 0.9944444, Test Acc: 1.0000000\n","Epoch: 070, Train Loss: 0.0378741, Train Acc: 0.9950000, Test Acc: 1.0000000\n","Epoch: 071, Train Loss: 0.0386738, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 072, Train Loss: 0.0413609, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 073, Train Loss: 0.0390656, Train Acc: 0.9944444, Test Acc: 1.0000000\n","Epoch: 074, Train Loss: 0.0453860, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 075, Train Loss: 0.0439080, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 076, Train Loss: 0.0411100, Train Acc: 0.9950000, Test Acc: 1.0000000\n","Epoch: 077, Train Loss: 0.0397128, Train Acc: 0.9950000, Test Acc: 1.0000000\n","Epoch: 078, Train Loss: 0.0389329, Train Acc: 0.9944444, Test Acc: 1.0000000\n","Epoch: 079, Train Loss: 0.0412631, Train Acc: 0.9955556, Test Acc: 1.0000000\n","Epoch: 080, Train Loss: 0.0404319, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 081, Train Loss: 0.0330077, Train Acc: 0.9916667, Test Acc: 1.0000000\n","Epoch: 082, Train Loss: 0.0335892, Train Acc: 0.9955556, Test Acc: 1.0000000\n","Epoch: 083, Train Loss: 0.0346211, Train Acc: 0.9955556, Test Acc: 1.0000000\n","Epoch: 084, Train Loss: 0.0356400, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 085, Train Loss: 0.0378493, Train Acc: 0.9950000, Test Acc: 1.0000000\n","Epoch: 086, Train Loss: 0.0397563, Train Acc: 0.9950000, Test Acc: 1.0000000\n","Epoch: 087, Train Loss: 0.0385065, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 088, Train Loss: 0.0362854, Train Acc: 0.9950000, Test Acc: 1.0000000\n","Epoch: 089, Train Loss: 0.0350923, Train Acc: 0.9955556, Test Acc: 1.0000000\n","Epoch: 090, Train Loss: 0.0354491, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 091, Train Loss: 0.0357188, Train Acc: 0.9944444, Test Acc: 1.0000000\n","Epoch: 092, Train Loss: 0.0320642, Train Acc: 0.9961111, Test Acc: 1.0000000\n","Epoch: 093, Train Loss: 0.0299335, Train Acc: 0.9944444, Test Acc: 1.0000000\n","Epoch: 094, Train Loss: 0.0377060, Train Acc: 0.9950000, Test Acc: 1.0000000\n","Epoch: 095, Train Loss: 0.0316644, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 096, Train Loss: 0.0334216, Train Acc: 0.9944444, Test Acc: 1.0000000\n","Epoch: 097, Train Loss: 0.0349572, Train Acc: 0.9955556, Test Acc: 1.0000000\n","Epoch: 098, Train Loss: 0.0335587, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 099, Train Loss: 0.0371099, Train Acc: 0.9938889, Test Acc: 1.0000000\n","Epoch: 100, Train Loss: 0.0347716, Train Acc: 0.9955556, Test Acc: 1.0000000\n"]}],"source":["def train(epoch):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    loss_all = 0\n","    for data in train_loader:\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output = model(data.x, data.edge_index, data.batch)\n","        loss = F.nll_loss(output, data.y)\n","        loss.backward()\n","        loss_all += loss.item() * data.num_graphs\n","        optimizer.step()\n","    return loss_all / len(train_dataset)\n","\n","\n","def test(loader):\n","    model.eval()\n","\n","    correct = 0\n","    for data in loader:\n","        data = data.to(device)\n","        output = model(data.x, data.edge_index, data.batch)\n","        pred = output.max(dim=1)[1]\n","        correct += pred.eq(data.y).sum().item()\n","    return correct / len(loader.dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=32).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(1, 101):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))"]},{"cell_type":"markdown","metadata":{"id":"9dBj91kSvj09"},"source":["# Alchemy Full"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40569,"status":"ok","timestamp":1621639009223,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"RLCuA9D57FGC","outputId":"6eecff32-561a-4a0b-b40f-b7bc5d91f384"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/alchemy_full.zip\n","Extracting ./alchemy_full/alchemy_full.zip\n","Processing...\n","Done!\n","Train Dataset: alchemy_full(2000):\n","======================\n","Number of graphs: 2000\n","Number of features: 6\n","Number of classes: 12\n","Test Dataset: alchemy_full(200):\n","======================\n","Number of graphs: 200\n","Number of features: 6\n","Number of classes: 12\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import MoleculeNet\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"alchemy_full\").shuffle()\n","test_dataset = dataset[:len(dataset) // 10][:200]\n","train_dataset = dataset[len(dataset) // 10:][:2000]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=128)\n","train_loader = DataLoader(train_dataset, batch_size=128)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":15836,"status":"error","timestamp":1621639025448,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"d3kRqHu6bK2u","outputId":"7b7ce121-bba3-48dd-d76f-4564102e10fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 001, Train Loss: 0.8972569, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 002, Train Loss: 0.0031712, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 003, Train Loss: 0.0003454, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 004, Train Loss: 0.0001011, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 005, Train Loss: 0.0001405, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 006, Train Loss: 0.0000450, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 007, Train Loss: 0.0000660, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 008, Train Loss: 0.0000699, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 009, Train Loss: 0.0000258, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 010, Train Loss: 0.0000336, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 011, Train Loss: 0.0000803, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 012, Train Loss: 0.0000075, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 013, Train Loss: 0.0000863, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 014, Train Loss: 0.0000740, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 015, Train Loss: 0.0000231, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 016, Train Loss: 0.0000377, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 017, Train Loss: 0.0000350, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 018, Train Loss: 0.0000301, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 019, Train Loss: 0.0000823, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 020, Train Loss: 0.0000468, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 021, Train Loss: 0.0000822, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 022, Train Loss: 0.0000229, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 023, Train Loss: 0.0000068, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 024, Train Loss: 0.0000989, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 025, Train Loss: 0.0000620, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 026, Train Loss: 0.0000664, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 027, Train Loss: 0.0000280, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 028, Train Loss: 0.0000101, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 029, Train Loss: 0.0000234, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 030, Train Loss: 0.0000192, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 031, Train Loss: 0.0000220, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 032, Train Loss: 0.0000254, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 033, Train Loss: 0.0000277, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 034, Train Loss: 0.0000039, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 035, Train Loss: 0.0000123, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 036, Train Loss: 0.0000132, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 037, Train Loss: 0.0000058, Train Acc: 0.0000000, Test Acc: 0.0000000\n","Epoch: 038, Train Loss: 0.0000305, Train Acc: 0.0000000, Test Acc: 0.0000000\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-5d0aac336114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-5d0aac336114>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-5d0aac336114>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, batch, edge_weight)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#x = F.relu(self.conv2(x, edge_index, edge_weight))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_add_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor, alpha: OptPairTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         out = self.propagate(edge_index, x=(x_l, x_r),\n\u001b[0;32m--> 153\u001b[0;31m                              alpha=(alpha_l, alpha_r), size=size)\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mmsg_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minspector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoll_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;31m# For `GNNExplainer`, we require a separate message and aggregate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mmessage\u001b[0;34m(self, x_j, alpha_j, alpha_i, index, ptr, size_i)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_j\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0malpha_i\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0malpha_j\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=-1)\n","\n","def train(epoch):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    loss_all = 0\n","    for data in train_loader:\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output = model(data.x, data.edge_index, data.batch)\n","        loss = F.nll_loss(output, torch.max(data.y, 1)[1])\n","        loss.backward()\n","        loss_all += loss.item() * data.num_graphs\n","        optimizer.step()\n","    return loss_all / len(train_dataset)\n","\n","\n","def test(loader):\n","    model.eval()\n","\n","    correct = 0\n","    for data in loader:\n","        data = data.to(device)\n","        output = model(data.x, data.edge_index, data.batch)\n","        pred = output.max(dim=1)[1]\n","        correct += (output == data.y).float().sum()\n","    return correct / len(loader.dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=64).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(1, 500):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))"]},{"cell_type":"markdown","metadata":{"id":"e4c5ASVcvbNu"},"source":["#P388H"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":32468,"status":"error","timestamp":1621755818055,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"G6qaHFvhClZl","outputId":"21b8a7ba-579e-4cf8-af61-bef6199f19db"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/P388H.zip\n","Extracting ./P388H/P388H.zip\n","Processing...\n","Done!\n","Train Dataset: P388H(37325):\n","======================\n","Number of graphs: 37325\n","Number of features: 73\n","Number of classes: 2\n","Test Dataset: P388H(4147):\n","======================\n","Number of graphs: 4147\n","Number of features: 73\n","Number of classes: 2\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 1, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n","        1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 1], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 1, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","torch.Size([128])\n","tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n","torch.Size([128])\n","tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 1, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 1, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 1, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 1, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n","torch.Size([128])\n","tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-85-65cc049edc9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-85-65cc049edc9b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mloss_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import MoleculeNet\n","from torch_geometric.datasets import TUDataset\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"P388H\").shuffle()\n","test_dataset = dataset[:len(dataset) // 10]\n","train_dataset = dataset[len(dataset) // 10:]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=128)\n","train_loader = DataLoader(train_dataset, batch_size=128)\n","\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=-1)\n","\n","def train(epoch):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    loss_all = 0\n","    for data in train_loader:\n","        data = data.to(device)\n","        print(data.y.shape)\n","        print(data.y)\n","        optimizer.zero_grad()\n","        output = model(data.x, data.edge_index, data.batch)\n","        loss = F.nll_loss(output, data.y)\n","        loss.backward()\n","        loss_all += loss.item() * data.num_graphs\n","        optimizer.step()\n","    return loss_all / len(train_dataset)\n","\n","\n","def test(loader):\n","    model.eval()\n","\n","    correct = 0\n","    for data in loader:\n","        data = data.to(device)\n","        output = model(data.x, data.edge_index, data.batch)\n","        pred = output.max(dim=1)[1]\n","        correct += pred.eq(data.y).sum().item()\n","    return correct / len(loader.dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=64).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(1, 500):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","          'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                       train_acc, test_acc))"]},{"cell_type":"markdown","metadata":{"id":"MkXXxkIy1jL3"},"source":["# Regression\n"]},{"cell_type":"markdown","metadata":{"id":"Q7qry4p71l4h"},"source":["## ZINC"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50597,"status":"ok","timestamp":1621770749865,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"5Bkdrqlq1qDL","outputId":"8c938515-690c-44ad-de1e-c93bbe7d648b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/ZINC_full.zip\n","Extracting ./ZINC_full/ZINC_full.zip\n","Processing...\n","Done!\n","Train Dataset: ZINC_full(224511):\n","======================\n","Number of graphs: 224511\n","Number of features: 28\n","Number of classes: 5\n","Test Dataset: ZINC_full(24945):\n","======================\n","Number of graphs: 24945\n","Number of features: 28\n","Number of classes: 5\n"]}],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"ZINC_full\").shuffle()\n","\n","train_dataset = dataset[len(dataset) // 10:]\n","test_dataset = dataset[:len(dataset) // 10]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3180,"status":"ok","timestamp":1621771052855,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"DeCEFRAa1qFh","outputId":"85aae7f9-3881-48fd-8222-a6d7ff6b29e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1023.10146437 1023.10146437 1023.10146437 1023.10146437 1023.10146437]\n","[[[ 1.70247097e-03  1.70247097e-03  1.70247097e-03  1.70247097e-03\n","    1.70247097e-03]]\n","\n"," [[-2.28462068e-03 -2.28462068e-03 -2.28462068e-03 -2.28462068e-03\n","   -2.28462068e-03]]\n","\n"," [[ 1.59893801e-03  1.59893801e-03  1.59893801e-03  1.59893801e-03\n","    1.59893801e-03]]\n","\n"," ...\n","\n"," [[ 7.80110603e-04  7.80110603e-04  7.80110603e-04  7.80110603e-04\n","    7.80110603e-04]]\n","\n"," [[ 1.13117208e-03  1.13117208e-03  1.13117208e-03  1.13117208e-03\n","    1.13117208e-03]]\n","\n"," [[-2.78891433e-05 -2.78891433e-05 -2.78891433e-05 -2.78891433e-05\n","   -2.78891433e-05]]]\n","tensor([-0.0006, -0.0006, -0.0006, -0.0006, -0.0006], dtype=torch.float64)\n"]}],"source":["import numpy as np\n","import torch.nn.functional as F\n","y = np.zeros((len(dataset),1, 5))\n","for i in range(len(dataset)):\n","  y[i, :, :] = dataset[i].y\n","factor = np.zeros((5))\n","for i in range(5): \n","  norm = np.linalg.norm(y[:,0,i], ord=2)\n","  factor[i] = norm\n","print(factor)\n","#y_2=F.normalize(torch.from_numpy(y), p=2, dim=2)\n","#factor = y/y_2\n","print(y/factor)\n","print(dataset[789].y/factor)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":975},"executionInfo":{"elapsed":1724340,"status":"error","timestamp":1621773617291,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"TiFWzHAXEEnY","outputId":"658de219-9f4a-4f70-c27c-36afb351b1ae"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.l1_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([63])) that is different to the input size (torch.Size([63, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.l1_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([49])) that is different to the input size (torch.Size([49, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.l1_loss(input, target, reduction=self.reduction)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 001, Train Loss at epoch: 0.0545524, Train Mae at epoch: 0.0082084, Test MAE at epoch: 0.0081616\n","Epoch: 002, Train Loss at epoch: 0.0096159, Train Mae at epoch: 0.0058059, Test MAE at epoch: 0.0058148\n","Epoch: 003, Train Loss at epoch: 0.0055894, Train Mae at epoch: 0.0036736, Test MAE at epoch: 0.0036758\n","Epoch: 004, Train Loss at epoch: 0.0027401, Train Mae at epoch: 0.0017342, Test MAE at epoch: 0.0017250\n","Epoch: 005, Train Loss at epoch: 0.0015018, Train Mae at epoch: 0.0015369, Test MAE at epoch: 0.0015283\n","Epoch: 006, Train Loss at epoch: 0.0013868, Train Mae at epoch: 0.0015688, Test MAE at epoch: 0.0015619\n","Epoch: 007, Train Loss at epoch: 0.0013151, Train Mae at epoch: 0.0015141, Test MAE at epoch: 0.0015053\n","Epoch: 008, Train Loss at epoch: 0.0012606, Train Mae at epoch: 0.0015346, Test MAE at epoch: 0.0015251\n","Epoch: 009, Train Loss at epoch: 0.0012283, Train Mae at epoch: 0.0015657, Test MAE at epoch: 0.0015566\n","Epoch: 010, Train Loss at epoch: 0.0012045, Train Mae at epoch: 0.0015804, Test MAE at epoch: 0.0015717\n","Epoch: 011, Train Loss at epoch: 0.0011862, Train Mae at epoch: 0.0015892, Test MAE at epoch: 0.0015798\n","Epoch: 012, Train Loss at epoch: 0.0011685, Train Mae at epoch: 0.0015987, Test MAE at epoch: 0.0015892\n","Epoch: 013, Train Loss at epoch: 0.0011589, Train Mae at epoch: 0.0016093, Test MAE at epoch: 0.0016003\n","Epoch: 014, Train Loss at epoch: 0.0011442, Train Mae at epoch: 0.0016214, Test MAE at epoch: 0.0016126\n","Epoch: 015, Train Loss at epoch: 0.0011301, Train Mae at epoch: 0.0016139, Test MAE at epoch: 0.0016053\n","Epoch: 016, Train Loss at epoch: 0.0011218, Train Mae at epoch: 0.0016288, Test MAE at epoch: 0.0016208\n","Epoch: 017, Train Loss at epoch: 0.0011105, Train Mae at epoch: 0.0016601, Test MAE at epoch: 0.0016527\n","Epoch: 018, Train Loss at epoch: 0.0011029, Train Mae at epoch: 0.0016731, Test MAE at epoch: 0.0016656\n","Epoch: 019, Train Loss at epoch: 0.0010935, Train Mae at epoch: 0.0016950, Test MAE at epoch: 0.0016881\n","Epoch: 020, Train Loss at epoch: 0.0010869, Train Mae at epoch: 0.0016838, Test MAE at epoch: 0.0016767\n","Epoch: 021, Train Loss at epoch: 0.0010793, Train Mae at epoch: 0.0017049, Test MAE at epoch: 0.0016979\n","Epoch: 022, Train Loss at epoch: 0.0010746, Train Mae at epoch: 0.0017680, Test MAE at epoch: 0.0017616\n","Epoch: 023, Train Loss at epoch: 0.0010692, Train Mae at epoch: 0.0017200, Test MAE at epoch: 0.0017133\n","Epoch: 024, Train Loss at epoch: 0.0010644, Train Mae at epoch: 0.0017855, Test MAE at epoch: 0.0017795\n","Epoch: 025, Train Loss at epoch: 0.0010585, Train Mae at epoch: 0.0018131, Test MAE at epoch: 0.0018069\n","Epoch: 026, Train Loss at epoch: 0.0010548, Train Mae at epoch: 0.0018513, Test MAE at epoch: 0.0018457\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-201-452b79a2c373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-201-452b79a2c373>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mloss_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL1Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mmae\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_mae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m#error += torch.linalg.norm(output_probs - data.y, ord = 1)/32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv, BatchNorm\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","        #self.norm1 = BatchNorm(num_features)\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, 1)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return x\n","\n","def train(epoch):\n","\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    mae = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = data.y/factor[0]\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch).flatten()\n","        loss = torch.nn.MSELoss()\n","        #print(data.y.shape, output_probs.shape)\n","        loss = loss(output_probs, data.y)\n","        loss_mae = torch.nn.L1Loss()\n","        mae += loss_mae(output_probs, data.y).item()\n","        loss.backward()\n","        optimizer.step()\n","        #error += torch.linalg.norm(output_probs - data.y, ord = 1)/32\n","        torch.cuda.empty_cache()\n","    return mae/len(train_loader)\n","\n","def test(loader):\n","    model.eval()\n","\n","    mae = 0\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = data.y/factor[0]\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        #error += torch.linalg.norm(output_probs - data.y, ord = 1)/32\n","        loss_mae = torch.nn.L1Loss()\n","        mae += loss_mae(output_probs, data.y).item()\n","        torch.cuda.empty_cache()\n","    return mae/len(loader)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.000005)\n","\n","for epoch in range(1, 5000):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss at epoch: {:.7f}, '\n","          'Train Mae at epoch: {:.7f}, Test MAE at epoch: {:.7f}'.format(epoch, train_loss,\n","                                                  train_acc, test_acc))\n","    torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"Ki5tSuaY1l7R"},"source":["## Alchemy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cc8APdfO1vDl"},"outputs":[],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","import torch\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"alchemy_full\").shuffle()\n","train_dataset = dataset[len(dataset) // 10:]\n","test_dataset = dataset[:len(dataset) // 10]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":392,"status":"ok","timestamp":1621797780569,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"bi9xsNVrR1-h","outputId":"5d5350e7-b581-4296-fb16-f3c15c90a1ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Dataset: alchemy_full(182322):\n","======================\n","Number of graphs: 182322\n","Number of features: 6\n","Number of classes: 12\n","Test Dataset: alchemy_full(20257):\n","======================\n","Number of graphs: 20257\n","Number of features: 6\n","Number of classes: 12\n"]}],"source":["print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2431,"status":"ok","timestamp":1621800713847,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"jQ8i_2doaOb5","outputId":"b1f65a3d-a457-406e-b51b-99f4646e512b"},"outputs":[{"name":"stdout","output_type":"stream","text":["-15.716988681808667\n","[[[8.61489461e+01 2.83672304e-02 1.08626915e+02 2.28857479e+05\n","   1.03899945e+02 2.28836977e+05 4.21827207e+04 2.28841587e+05\n","   2.28836566e+05 2.03088601e+01 1.39834646e+03 7.75887194e+05]]]\n","72.92028404696889\n","[[[ 0.00256459  0.00254872  0.00129465 ... -0.00173361  0.00256202\n","    0.00285802]]\n","\n"," [[ 0.00245759  0.00213979  0.00289205 ...  0.00368338  0.0008161\n","    0.00180161]]\n","\n"," [[ 0.00245484  0.00233015  0.00275714 ...  0.00236879  0.00233375\n","    0.00177605]]\n","\n"," ...\n","\n"," [[ 0.00210734  0.00219267  0.00193987 ... -0.00151985  0.00212387\n","    0.00206586]]\n","\n"," [[ 0.0016671   0.00177317  0.00122139 ... -0.00249846  0.00177157\n","    0.00165223]]\n","\n"," [[ 0.00194077  0.00211159  0.00122023 ... -0.00193829  0.00310869\n","    0.00153758]]]\n","tensor([[ 0.0022,  0.0021,  0.0010, -0.0017, -0.0016, -0.0017,  0.0022, -0.0017,\n","         -0.0017, -0.0027,  0.0007,  0.0021]], dtype=torch.float64)\n"]}],"source":["import numpy as np\n","import torch.nn.functional as F\n","y = np.zeros((len(dataset),1, 12))\n","for i in range(len(dataset)):\n","  y[i, :, :] = dataset[i].y\n","factor = np.zeros((1,1,12))\n","add = np.zeros((1,1,12))\n","std = np.zeros((1,1,12))\n","for i in range(12): \n","  norm = np.linalg.norm(y[:,0,i], ord=2)\n","  factor[:,:,i] =  norm\n","  add[:,:,i] =   np.mean(y[:,0,i])\n","  std[:,:,i] = np.std(y[:,0,i])\n","print(np.mean(add))\n","print(factor)\n","print(np.mean(std))\n","print(y/factor)\n","#y_2=F.normalize(torch.from_numpy(y), p=2, dim=2)\n","#factor = y/y_2\n","#print(y/y_2)\n","#factor = factor[0]\n","print(dataset[789].y/factor[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eP6N4BSy1viT","outputId":"266e0c78-ce39-41c8-e091-2c317590f5c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 001, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004819805823898557, 6.764281948221451e-07), Test MAE at epoch: (0.0004823373416541526, 6.775814158615794e-07)\n","Epoch: 002, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004795847443710763, 6.786705356933753e-07), Test MAE at epoch: (0.00048006120443047385, 6.803181391245892e-07)\n","Epoch: 003, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047511912860834715, 6.803291739224391e-07), Test MAE at epoch: (0.0004757227007393675, 6.819335193467448e-07)\n","Epoch: 004, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004928759236087145, 6.829439876105816e-07), Test MAE at epoch: (0.0004934297308284637, 6.845198352820828e-07)\n","Epoch: 005, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000499771294518197, 6.84431467462287e-07), Test MAE at epoch: (0.0005003257152589173, 6.859426849617305e-07)\n","Epoch: 006, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000503967607123519, 6.851299796545656e-07), Test MAE at epoch: (0.0005045235699611167, 6.866267538165693e-07)\n","Epoch: 007, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042566299699501, 6.852087639746887e-07), Test MAE at epoch: (0.0005048117710553603, 6.867045902990092e-07)\n","Epoch: 008, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042910800688426, 6.852190575816134e-07), Test MAE at epoch: (0.0005048461870234518, 6.867147741471659e-07)\n","Epoch: 009, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042958175983324, 6.852204914862834e-07), Test MAE at epoch: (0.0005048509210323157, 6.867161920049353e-07)\n","Epoch: 010, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042964496795924, 6.852206827367543e-07), Test MAE at epoch: (0.0005048515517683259, 6.867163798392611e-07)\n","Epoch: 011, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965295950946, 6.852207074573566e-07), Test MAE at epoch: (0.0005048516315513817, 6.86716405840194e-07)\n","Epoch: 012, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965524674976, 6.852207135626869e-07), Test MAE at epoch: (0.0005048516543203089, 6.867164117576477e-07)\n","Epoch: 013, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000504296544724183, 6.852207119665222e-07), Test MAE at epoch: (0.0005048516455983408, 6.867164088885792e-07)\n","Epoch: 014, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965295950946, 6.852207074573566e-07), Test MAE at epoch: (0.0005048516315513817, 6.86716405840194e-07)\n","Epoch: 015, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965524674976, 6.852207135626869e-07), Test MAE at epoch: (0.0005048516543203089, 6.867164117576477e-07)\n","Epoch: 016, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000504296544724183, 6.852207119665222e-07), Test MAE at epoch: (0.0005048516455983408, 6.867164088885792e-07)\n","Epoch: 017, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965295950946, 6.852207074573566e-07), Test MAE at epoch: (0.0005048516315513817, 6.86716405840194e-07)\n","Epoch: 018, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965524674976, 6.852207135626869e-07), Test MAE at epoch: (0.0005048516543203089, 6.867164117576477e-07)\n","Epoch: 019, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000504296544724183, 6.852207119665222e-07), Test MAE at epoch: (0.0005048516455983408, 6.867164088885792e-07)\n","Epoch: 020, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965295950946, 6.852207074573566e-07), Test MAE at epoch: (0.0005048516315513817, 6.86716405840194e-07)\n","Epoch: 021, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965524674976, 6.852207135626869e-07), Test MAE at epoch: (0.0005048516543203089, 6.867164117576477e-07)\n","Epoch: 022, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000504296544724183, 6.852207119665222e-07), Test MAE at epoch: (0.0005048516455983408, 6.867164088885792e-07)\n","Epoch: 023, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965295950946, 6.852207074573566e-07), Test MAE at epoch: (0.0005048516315513817, 6.86716405840194e-07)\n","Epoch: 024, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965524674976, 6.852207135626869e-07), Test MAE at epoch: (0.0005048516543203089, 6.867164117576477e-07)\n","Epoch: 025, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000504296544724183, 6.852207119665222e-07), Test MAE at epoch: (0.0005048516455983408, 6.867164088885792e-07)\n","Epoch: 026, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965295950946, 6.852207074573566e-07), Test MAE at epoch: (0.0005048516315513817, 6.86716405840194e-07)\n","Epoch: 027, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965524674976, 6.852207135626869e-07), Test MAE at epoch: (0.0005048516543203089, 6.867164117576477e-07)\n","Epoch: 028, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000504296544724183, 6.852207119665222e-07), Test MAE at epoch: (0.0005048516455983408, 6.867164088885792e-07)\n","Epoch: 029, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965295950946, 6.852207074573566e-07), Test MAE at epoch: (0.0005048516315513817, 6.86716405840194e-07)\n","Epoch: 030, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965524674976, 6.852207135626869e-07), Test MAE at epoch: (0.0005048516543203089, 6.867164117576477e-07)\n","Epoch: 031, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000504296544724183, 6.852207119665222e-07), Test MAE at epoch: (0.0005048516455983408, 6.867164088885792e-07)\n","Epoch: 032, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965295950946, 6.852207074573566e-07), Test MAE at epoch: (0.0005048516315513817, 6.86716405840194e-07)\n","Epoch: 033, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965524674976, 6.852207135626869e-07), Test MAE at epoch: (0.0005048516543203089, 6.867164117576477e-07)\n","Epoch: 034, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000504296544724183, 6.852207119665222e-07), Test MAE at epoch: (0.0005048516455983408, 6.867164088885792e-07)\n","Epoch: 035, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965295950946, 6.852207074573566e-07), Test MAE at epoch: (0.0005048516315513817, 6.86716405840194e-07)\n","Epoch: 036, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965524674976, 6.852207135626869e-07), Test MAE at epoch: (0.0005048516543203089, 6.867164117576477e-07)\n","Epoch: 037, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047534993784847024, 6.90309427081267e-07), Test MAE at epoch: (0.000475887847900514, 6.922333443956801e-07)\n","Epoch: 038, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00048225161747545364, 6.774644677262219e-07), Test MAE at epoch: (0.00048273648168415724, 6.788619603732272e-07)\n","Epoch: 039, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00048668051041514285, 6.800225778095639e-07), Test MAE at epoch: (0.00048720796004213886, 6.815743104513788e-07)\n","Epoch: 040, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005036684461533742, 6.850350522823355e-07), Test MAE at epoch: (0.0005042261715973977, 6.86534257201225e-07)\n","Epoch: 041, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042453459480358, 6.852055533191261e-07), Test MAE at epoch: (0.0005048005023643622, 6.867014240129886e-07)\n","Epoch: 042, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042897077961656, 6.852186360644184e-07), Test MAE at epoch: (0.0005048448167563554, 6.867143575046305e-07)\n","Epoch: 043, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042956106842974, 6.852204293954728e-07), Test MAE at epoch: (0.0005048507129904235, 6.867161288854292e-07)\n","Epoch: 044, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042964274916248, 6.852206755141086e-07), Test MAE at epoch: (0.0005048515309274127, 6.867163739218075e-07)\n","Epoch: 045, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000504296522168459, 6.852207046441161e-07), Test MAE at epoch: (0.000504851623563895, 6.867164045849765e-07)\n","Epoch: 046, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000504296522168459, 6.852207046441161e-07), Test MAE at epoch: (0.000504851623563895, 6.867164045849765e-07)\n","Epoch: 047, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965366948355, 6.852207094126584e-07), Test MAE at epoch: (0.0005048516388961969, 6.867164067367779e-07)\n","Epoch: 048, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965366948355, 6.852207094126584e-07), Test MAE at epoch: (0.0005048516388961969, 6.867164067367779e-07)\n","Epoch: 049, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965366948355, 6.852207094126584e-07), Test MAE at epoch: (0.0005048516388961969, 6.867164067367779e-07)\n","Epoch: 050, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0005042965366948355, 6.852207094126584e-07), Test MAE at epoch: (0.0005048516388961969, 6.867164067367779e-07)\n","Epoch: 051, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004955296857490424, 6.964234302939503e-07), Test MAE at epoch: (0.0004960510180895848, 6.983682300887201e-07)\n","Epoch: 052, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959961808013323, 6.960060450708075e-07), Test MAE at epoch: (0.0004965151247549332, 6.979423646637767e-07)\n","Epoch: 053, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959995082507473, 6.959851927539373e-07), Test MAE at epoch: (0.0004965183424266872, 6.97921187710841e-07)\n","Epoch: 054, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994684819822, 6.959843704397615e-07), Test MAE at epoch: (0.0004965182945017676, 6.979203499428507e-07)\n","Epoch: 055, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994523926409, 6.959843199710258e-07), Test MAE at epoch: (0.0004965182784349843, 6.979202992858607e-07)\n","Epoch: 056, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 057, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 058, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 059, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 060, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 061, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 062, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 063, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 064, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 065, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 066, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 067, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 068, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 069, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 070, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 071, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 072, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 073, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 074, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 075, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 076, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 077, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 078, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 079, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 080, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 081, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 082, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 083, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 084, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 085, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 086, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 087, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 088, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 089, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 090, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 091, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 092, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 093, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 094, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 095, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 096, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 097, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 098, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 099, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 100, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994637215802, 6.959843221158723e-07), Test MAE at epoch: (0.0004965182922983231, 6.979203020652707e-07)\n","Epoch: 101, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004959994532507391, 6.959843197116491e-07), Test MAE at epoch: (0.0004965182794448964, 6.979202992858607e-07)\n","Epoch: 102, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000484393894567052, 6.866263726700704e-07), Test MAE at epoch: (0.0004848973204569791, 6.885301039642328e-07)\n","Epoch: 103, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841804908885676, 6.867339022821325e-07), Test MAE at epoch: (0.0004846849947931298, 6.886397980449006e-07)\n","Epoch: 104, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762549379038, 6.867382587745233e-07), Test MAE at epoch: (0.00048468080384154403, 6.886442456389637e-07)\n","Epoch: 105, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762068844049, 6.867384646797822e-07), Test MAE at epoch: (0.0004846807611498053, 6.886444611777317e-07)\n","Epoch: 106, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 107, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 108, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 109, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 110, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 111, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 112, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 113, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 114, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 115, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 116, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 117, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 118, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 119, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 120, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 121, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 122, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 123, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 124, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 125, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 126, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 127, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 128, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 129, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 130, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 131, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 132, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 133, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 134, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 135, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 136, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 137, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 138, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 139, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 140, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 141, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 142, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 143, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 144, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 145, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 146, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 147, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 148, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 149, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 150, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 151, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 152, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004841762298896089, 6.867384725309177e-07), Test MAE at epoch: (0.00048468078345968165, 6.886444656606512e-07)\n","Epoch: 153, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004754884499752003, 6.794451072831142e-07), Test MAE at epoch: (0.0004760112212412647, 6.810378934529316e-07)\n","Epoch: 154, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004756467794609168, 6.793970595702757e-07), Test MAE at epoch: (0.0004761685654543023, 6.809902364326458e-07)\n","Epoch: 155, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004756534206506065, 6.793952193518804e-07), Test MAE at epoch: (0.000476175146041532, 6.809884134982731e-07)\n","Epoch: 156, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004756536559329593, 6.793951517942053e-07), Test MAE at epoch: (0.00047617537868855525, 6.809883464337979e-07)\n","Epoch: 157, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 158, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 159, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 160, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 161, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 162, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 163, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 164, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 165, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 166, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 167, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 168, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 169, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 170, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 171, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 172, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 173, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 174, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 175, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 176, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 177, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 178, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 179, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 180, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 181, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 182, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 183, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 184, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 185, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 186, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 187, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 188, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 189, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 190, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 191, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 192, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 193, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 194, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 195, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 196, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 197, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 198, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 199, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 200, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 201, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 202, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 203, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047565368356576425, 6.793951451501693e-07), Test MAE at epoch: (0.0004761754046708392, 6.80988339799077e-07)\n","Epoch: 204, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004761300808056259, 6.777288620898065e-07), Test MAE at epoch: (0.000476618652978959, 6.791942167911895e-07)\n","Epoch: 205, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004761391496572646, 6.777391140268539e-07), Test MAE at epoch: (0.00047662776569124866, 6.792052222688263e-07)\n","Epoch: 206, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004761394813530789, 6.777394781619245e-07), Test MAE at epoch: (0.00047662809868681034, 6.792056118345281e-07)\n","Epoch: 207, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950220282196, 6.777394915796848e-07), Test MAE at epoch: (0.00047662812163935803, 6.792056264488456e-07)\n","Epoch: 208, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 209, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 210, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 211, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 212, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 213, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 214, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 215, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 216, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 217, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 218, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 219, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 220, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 221, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 222, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 223, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 224, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 225, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 226, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 227, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 228, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 229, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 230, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 231, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 232, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 233, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 234, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 235, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 236, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 237, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 238, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 239, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 240, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 241, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 242, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 243, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 244, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 245, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 246, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 247, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 248, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 249, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 250, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 251, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 252, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 253, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 254, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047613950171248014, 6.777394969068848e-07), Test MAE at epoch: (0.0004766281211803071, 6.792056344284423e-07)\n","Epoch: 255, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.0004755764925355865, 6.76951338393274e-07), Test MAE at epoch: (0.0004760703500338216, 6.783333466133822e-07)\n","Epoch: 256, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047555301273177893, 6.76959048467809e-07), Test MAE at epoch: (0.0004760470472302652, 6.783411933363031e-07)\n","Epoch: 257, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047555191129123713, 6.769593993547118e-07), Test MAE at epoch: (0.0004760459560661486, 6.783415507146432e-07)\n","Epoch: 258, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.00047555184386923605, 6.769594151866713e-07), Test MAE at epoch: (0.00047604588812660744, 6.783415681083706e-07)\n","Epoch: 259, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 260, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 261, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 262, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 263, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 264, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 265, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 266, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 267, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 268, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 269, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 270, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 271, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 272, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 273, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 274, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 275, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 276, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 277, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 278, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 279, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 280, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 281, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n","Epoch: 282, Train Loss at epoch: 0.0000000, Train Mae at epoch: (0.000475551845238107, 6.769594148474863e-07), Test MAE at epoch: (0.00047604588757574627, 6.783415664945197e-07)\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv, BatchNorm\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","        #self.norm1 = BatchNorm(num_features)\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return x\n","\n","def train(epoch):\n","\n","    model.train()\n","\n","    if epoch % 51 == 0:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    mae = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = (data.y)/factor\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        loss = torch.nn.MSELoss()\n","       # print(data.y.shape)\n","        loss = loss(output_probs, data.y[0,:,:])\n","        #loss_mae = torch.nn.L1Loss()\n","        #mae += loss_mae(output_probs, data.y).item()\n","        mse = loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        #error += torch.linalg.norm(output_probs - data.y, ord = 1)/32\n","        torch.cuda.empty_cache()\n","    return mse/len(train_loader)\n","\n","def test(loader):\n","    model.eval()\n","\n","    mae = 0\n","    mse = 0\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = data.y/factor[0]\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        #error += torch.linalg.norm(output_probs - data.y, ord = 1)/32\n","        loss = torch.nn.MSELoss()\n","        loss = loss(output_probs, data.y)\n","        mse += loss.item()\n","        loss_mae = torch.nn.L1Loss()\n","        mae += loss_mae(output_probs, data.y).item()\n","        torch.cuda.empty_cache()\n","    return (mae/len(loader), mse/len(loader))\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","for epoch in range(1, 5000):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss at epoch: {:.7f}, '\n","          'Train Mae at epoch: {}, Test MAE at epoch: {}'.format(epoch, train_loss,\n","                                                  train_acc, test_acc))\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"elapsed":734,"status":"error","timestamp":1621929761617,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"2QCqhc1EhCmF","outputId":"54336f4f-8948-43ff-e9bc-cb82cf004ab5"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-7fc481e7ce64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0004674\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'factor' is not defined"]}],"source":["val = 0.0004674\n","for i in range(len(train_dataset)):\n","  y[i, :, :] = train_dataset[i].y/factor\n","\n","for i in range(12):\n","  print(abs(val/np.amax(y[:,0,i])))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M7KP4JvDxnQa"},"outputs":[],"source":["val_m = 0\n","for i in range(12):\n","  print(abs(val/np.amax(y[:,0,i])))\n","  val += abs(val/np.amax(y[:,0,i]))\n","val_12"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1621699724412,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"M4Wa0Jv908BD","outputId":"8a0a53bb-8ca0-4702-e30e-d1d4dab33ac7"},"outputs":[{"data":{"text/plain":["array([[[ 1.00959433e-02,  3.05722875e+01,  1.35131094e-02, ...,\n","         -4.29623001e-02,  9.87634454e-04,  1.46670660e-06]],\n","\n","       [[ 1.27195259e-02,  4.03578521e+01,  9.24372860e-03, ...,\n","         -9.43824355e-02,  1.06234852e-03,  1.91834316e-06]],\n","\n","       [[ 1.45689475e-02,  3.41176480e+01,  1.12648326e-02, ...,\n","         -2.63528656e-02,  5.65095029e-04,  1.24055888e-06]],\n","\n","       ...,\n","\n","       [[ 1.07753901e-02,  3.02985071e+01,  9.13723567e-03, ...,\n","          5.25852394e-01,  2.11684610e-03,  8.11316561e-07]],\n","\n","       [[ 1.21211129e-02,  3.01634458e+01,  8.12563658e-03, ...,\n","         -1.74023977e-01,  4.15146619e-04,  1.08187252e-06]],\n","\n","       [[ 8.36539763e-03,  2.62953373e+01,  9.00005714e-03, ...,\n","          2.34850124e-01,  9.48243648e-04,  8.32138649e-07]]])"]},"execution_count":18,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["y"]},{"cell_type":"markdown","metadata":{"id":"BLtNaFg11vsI"},"source":["## QM-9"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pt3805_w1w7k"},"outputs":[],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"QM9\").shuffle()\n","test_dataset = dataset[:len(dataset) // 10]\n","train_dataset = dataset[len(dataset) // 10:]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":417,"status":"ok","timestamp":1621794637691,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"obM2LeoNj0ih","outputId":"5da15cab-ded6-4c48-8971-7199abe468be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Dataset: QM9(116490):\n","======================\n","Number of graphs: 116490\n","Number of features: 0\n","Number of classes: 19\n","Test Dataset: QM9(12943):\n","======================\n","Number of graphs: 12943\n","Number of features: 0\n","Number of classes: 19\n"]}],"source":["print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9313,"status":"ok","timestamp":1621794650282,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"lifqt-H_B4nf","outputId":"bb2c844b-39f6-4fde-dbde-7fdde50ce692"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1.10702396e+03 2.72470975e+04 2.36137043e+03 4.71898827e+02\n"," 2.50781796e+03 4.40173228e+05 1.49499767e+03 4.04197394e+06\n"," 4.04189109e+06 4.04188189e+06 4.04230007e+06 1.14752584e+04\n"," 2.76306257e+04 2.78005238e+04 2.79601507e+04 2.57089955e+04\n"," 6.62096125e+05 7.68474920e+02 5.69364761e+02]\n","[[[ 1.80339367e-03  2.38263904e-03 -3.21622411e-03 ...  9.15632881e-06\n","    2.07205196e-03  2.21490708e-03]]\n","\n"," [[ 2.30455709e-03  2.73607136e-03 -2.46604086e-03 ...  3.36469280e-06\n","    2.13520299e-03  1.95995614e-03]]\n","\n"," [[ 4.13071471e-03  2.87700367e-03 -2.94081116e-03 ...  4.79596525e-06\n","    1.86983337e-03  2.24102378e-03]]\n","\n"," ...\n","\n"," [[ 1.31577997e-03  3.34751249e-03 -2.63658932e-03 ...  5.50702500e-06\n","    1.00306458e-03  1.28044459e-03]]\n","\n"," [[ 5.57196625e-03  2.78158072e-03 -2.83018513e-03 ...  5.45642819e-06\n","    1.53852776e-03  2.05950583e-03]]\n","\n"," [[ 2.12000830e-03  2.94490075e-03 -2.71264493e-03 ...  2.93916536e-06\n","    2.49099872e-03  2.08748427e-03]]]\n","tensor([[ 2.4751e-03,  2.2924e-03, -2.8359e-03, -1.6030e-03,  2.3687e-03,\n","          1.5699e-03,  2.2886e-03, -2.0767e-03, -2.0767e-03, -2.0767e-03,\n","         -2.0768e-03,  1.9931e-03, -2.2928e-03, -2.2936e-03, -2.2934e-03,\n","         -2.2977e-03,  8.6734e-06,  2.7115e-03,  3.5586e-03]],\n","       dtype=torch.float64)\n"]}],"source":["import numpy as np\n","import torch.nn.functional as F\n","y = np.zeros((len(dataset),1, 19))\n","for i in range(len(dataset)):\n","  y[i, :, :] = dataset[i].y\n","factor = np.zeros((19))\n","for i in range(19): \n","  norm = np.linalg.norm(y[:,0,i], ord=2)\n","  factor[i] = norm\n","print(factor)\n","#y_2=F.normalize(torch.from_numpy(y), p=2, dim=2)\n","#factor = y/y_2\n","print(y/factor)\n","#factor = factor[0]\n","print(dataset[789].y/factor)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"elapsed":418,"status":"error","timestamp":1621794771021,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"O4n6bI-DB43d","outputId":"f1f28227-69fc-4ac1-f864-f32a2f06af2c"},"outputs":[{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-ce53e4038547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-ce53e4038547>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0moutput_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-ce53e4038547>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, batch, edge_weight)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m#x = F.relu(self.conv2(x, edge_index, edge_weight))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Static graphs not supported in `GATConv`.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mx_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0malpha_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_l\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matt_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0malpha_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_r\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matt_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv, BatchNorm\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","        #self.norm1 = BatchNorm(num_features)\n","        self.conv1 = GATConv(dim, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return x\n","\n","def train(epoch):\n","\n","    model.train()\n","\n","    if epoch % 51 == 0:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    mae = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = data.y/factor\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        loss = torch.nn.MSELoss()\n","        loss = loss(output_probs, data.y)\n","        loss_mae = torch.nn.L1Loss()\n","        #mae += loss_mae(output_probs, data.y).item()\n","        mse = loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        #error += torch.linalg.norm(output_probs - data.y, ord = 1)/32\n","        torch.cuda.empty_cache()\n","    return mse/len(train_loader)\n","\n","def test(loader):\n","    model.eval()\n","\n","    mae = 0\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = data.y/factor\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        #error += torch.linalg.norm(output_probs - data.y, ord = 1)/32\n","        loss_mae = torch.nn.L1Loss()\n","        mae += loss_mae(output_probs, data.y).item()\n","        torch.cuda.empty_cache()\n","    return mae/len(loader)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n","\n","for epoch in range(1, 5000):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss at epoch: {:.7f}, '\n","          'Train Mae at epoch: {:.7f}, Test MAE at epoch: {:.7f}'.format(epoch, train_loss,\n","                                                  train_acc, test_acc))\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2010,"status":"ok","timestamp":1621703771544,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"rLSeuK3BB_qe","outputId":"86182353-f1f9-4387-9fcd-d8a1e091e274"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0013021301745470685\n","4.4665723312540075\n","0.001149414683179826\n","1.345966467375715e-06\n","0.006236937837500347\n","1.3461162329045604e-06\n","2.8699843268999417e-06\n","1.3460873655495797e-06\n","1.3461199005669944e-06\n","0.004641981063331782\n","3.119193433880219e-05\n","8.95305235762369e-08\n"]}],"source":["val = 0.0004674\n","for i in range(len(train_dataset)):\n","  y[i, :, :] = train_dataset[i].y\n","\n","for i in range(12):\n","  print(abs(val/np.amax(y[:,0,i])))"]},{"cell_type":"markdown","metadata":{"id":"CicE52nRVNbw"},"source":["### Whole Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kd7zeMFxE7qB"},"outputs":[],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import MoleculeNet\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"QM9\").shuffle()\n","test_dataset = dataset[:len(dataset) // 10]\n","train_dataset = dataset[len(dataset) // 10:]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EBCl9jqGVAIC"},"outputs":[],"source":["import numpy as np\n","import torch.nn.functional as F\n","y = np.zeros((len(dataset),1, 12))\n","for i in range(len(dataset)):\n","  y[i, :, :] = dataset[i].y\n","\n","y_2=F.normalize(torch.from_numpy(y), p=2, dim=0)\n","factor = y/y_2\n","print(y/y_2)\n","factor = factor[0]\n","print(dataset[789].y/factor)\n","\n","test_dataset = dataset[:len(dataset) // 10]\n","train_dataset = dataset[len(dataset) // 10:]\n","\n","print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=16)\n","train_loader = DataLoader(train_dataset, batch_size=16)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"elapsed":418,"status":"error","timestamp":1621794301000,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"WhkWfKVTVI6u","outputId":"ed592afd-a372-405f-e96f-84d01c6ab3b5"},"outputs":[{"ename":"ZeroDivisionError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-89-ba94eae1c4f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m364\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.000005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-89-ba94eae1c4f7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dim)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#self.norm1 = BatchNorm(num_features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m#self.conv2 = GraphConv(dim, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGATConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/conv/graph_conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, aggr, bias, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0min_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0mfan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calculate_correct_fan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgain\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv, BatchNorm\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","        #self.norm1 = BatchNorm(num_features)\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return x\n","\n","def train(epoch):\n","\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    mae = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = data.y/factor\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        loss = torch.nn.MSELoss()\n","        loss = loss(output_probs, data.y)\n","        loss_mae = torch.nn.L1Loss()\n","        mae += loss_mae(output_probs, data.y).item()\n","        loss.backward()\n","        optimizer.step()\n","        #error += torch.linalg.norm(output_probs - data.y, ord = 1)/32\n","        torch.cuda.empty_cache()\n","    return mae/len(train_loader)\n","\n","def test(loader):\n","    model.eval()\n","\n","    mae = 0\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = data.y/factor\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        #error += torch.linalg.norm(output_probs - data.y, ord = 1)/32\n","        loss_mae = torch.nn.L1Loss()\n","        mae += loss_mae(output_probs, data.y).item()\n","        torch.cuda.empty_cache()\n","    return mae/len(loader)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.000005)\n","\n","for epoch in range(1, 5000):\n","    train_loss = train(epoch)\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print('Epoch: {:03d}, Train Loss at epoch: {:.7f}, '\n","          'Train Mae at epoch: {:.7f}, Test MAE at epoch: {:.7f}'.format(epoch, train_loss,\n","                                                  train_acc, test_acc))\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LG4IIV_4_dAd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":383,"status":"ok","timestamp":1621937227073,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"mdNCNvqT_dKx","outputId":"24c2b0ef-db73-4322-d463-2bf5fe97bf5a"},"outputs":[{"data":{"text/plain":["Data(edge_index=[2, 4], x=[3, 1])"]},"execution_count":11,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["import torch\n","from torch_geometric.data import Data\n","\n","edge_index = torch.tensor([[0, 1, 1, 2],\n","                           [1, 0, 2, 1]], dtype=torch.long)\n","x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n","\n","data = Data(x=x, edge_index=edge_index)\n","data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":637,"status":"ok","timestamp":1621962667422,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"Eo62u1e__dsI","outputId":"dfd0cc19-0df7-4126-ceb3-4dfd39f94106"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["!echo $CUDA_PATH"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":369,"status":"ok","timestamp":1621962791620,"user":{"displayName":"Julian M. Kleber","photoUrl":"","userId":"12777262448935374285"},"user_tz":-120},"id":"E-proAjkgglm","outputId":"fb9118cb-5f77-49ba-e8ff-dbce577ab87c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"]}],"source":["ls $CUDA_PATH"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7YFh19l_hBa2"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMB3RRMDCmANJ1ec9QmxsfF","collapsed_sections":[],"machine_shape":"hm","name":"Graph_karate.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.4"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
