{"cells":[{"cell_type":"markdown","metadata":{"id":"Uk39Rs6Oc-6p"},"source":["uninstall pytorch libraries 1.10 \n"]},{"cell_type":"markdown","metadata":{"id":"vItLD--qsu06"},"source":["# CARATE-BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":156584,"status":"ok","timestamp":1644326302617,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"IH28P1o0OxiP","outputId":"6b6e71da-c08f-495a-9483-e50a003f2954"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.9.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n","\u001b[K     |█████████████                   | 834.1 MB 97.5 MB/s eta 0:00:13tcmalloc: large alloc 1147494400 bytes == 0x56234830c000 @  0x7f1aa0888615 0x56230f8153bc 0x56230f8f618a 0x56230f8181cd 0x56230f90ab3d 0x56230f88c458 0x56230f88702f 0x56230f819aba 0x56230f88c2c0 0x56230f88702f 0x56230f819aba 0x56230f888cd4 0x56230f90b986 0x56230f888350 0x56230f90b986 0x56230f888350 0x56230f90b986 0x56230f888350 0x56230f819f19 0x56230f85da79 0x56230f818b32 0x56230f88c1dd 0x56230f88702f 0x56230f819aba 0x56230f888cd4 0x56230f88702f 0x56230f819aba 0x56230f887eae 0x56230f8199da 0x56230f888108 0x56230f88702f\n","\u001b[K     |████████████████▌               | 1055.7 MB 1.2 MB/s eta 0:13:34tcmalloc: large alloc 1434370048 bytes == 0x56238c962000 @  0x7f1aa0888615 0x56230f8153bc 0x56230f8f618a 0x56230f8181cd 0x56230f90ab3d 0x56230f88c458 0x56230f88702f 0x56230f819aba 0x56230f88c2c0 0x56230f88702f 0x56230f819aba 0x56230f888cd4 0x56230f90b986 0x56230f888350 0x56230f90b986 0x56230f888350 0x56230f90b986 0x56230f888350 0x56230f819f19 0x56230f85da79 0x56230f818b32 0x56230f88c1dd 0x56230f88702f 0x56230f819aba 0x56230f888cd4 0x56230f88702f 0x56230f819aba 0x56230f887eae 0x56230f8199da 0x56230f888108 0x56230f88702f\n","\u001b[K     |█████████████████████           | 1336.2 MB 1.2 MB/s eta 0:09:38tcmalloc: large alloc 1792966656 bytes == 0x562311794000 @  0x7f1aa0888615 0x56230f8153bc 0x56230f8f618a 0x56230f8181cd 0x56230f90ab3d 0x56230f88c458 0x56230f88702f 0x56230f819aba 0x56230f88c2c0 0x56230f88702f 0x56230f819aba 0x56230f888cd4 0x56230f90b986 0x56230f888350 0x56230f90b986 0x56230f888350 0x56230f90b986 0x56230f888350 0x56230f819f19 0x56230f85da79 0x56230f818b32 0x56230f88c1dd 0x56230f88702f 0x56230f819aba 0x56230f888cd4 0x56230f88702f 0x56230f819aba 0x56230f887eae 0x56230f8199da 0x56230f888108 0x56230f88702f\n","\u001b[K     |██████████████████████████▌     | 1691.1 MB 82.2 MB/s eta 0:00:05tcmalloc: large alloc 2241208320 bytes == 0x56237c57c000 @  0x7f1aa0888615 0x56230f8153bc 0x56230f8f618a 0x56230f8181cd 0x56230f90ab3d 0x56230f88c458 0x56230f88702f 0x56230f819aba 0x56230f88c2c0 0x56230f88702f 0x56230f819aba 0x56230f888cd4 0x56230f90b986 0x56230f888350 0x56230f90b986 0x56230f888350 0x56230f90b986 0x56230f888350 0x56230f819f19 0x56230f85da79 0x56230f818b32 0x56230f88c1dd 0x56230f88702f 0x56230f819aba 0x56230f888cd4 0x56230f88702f 0x56230f819aba 0x56230f887eae 0x56230f8199da 0x56230f888108 0x56230f88702f\n","\u001b[K     |████████████████████████████████| 2041.3 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0x562401ede000 @  0x7f1aa08871e7 0x56230f84b5d7 0x56230f8153bc 0x56230f8f618a 0x56230f8181cd 0x56230f90ab3d 0x56230f88c458 0x56230f88702f 0x56230f819aba 0x56230f888108 0x56230f88702f 0x56230f819aba 0x56230f888108 0x56230f88702f 0x56230f819aba 0x56230f888108 0x56230f88702f 0x56230f819aba 0x56230f888108 0x56230f88702f 0x56230f819aba 0x56230f888108 0x56230f8199da 0x56230f888108 0x56230f88702f 0x56230f819aba 0x56230f888cd4 0x56230f88702f 0x56230f819aba 0x56230f888cd4 0x56230f88702f\n","tcmalloc: large alloc 2551685120 bytes == 0x5624efe2a000 @  0x7f1aa0888615 0x56230f8153bc 0x56230f8f618a 0x56230f8181cd 0x56230f90ab3d 0x56230f88c458 0x56230f88702f 0x56230f819aba 0x56230f888108 0x56230f88702f 0x56230f819aba 0x56230f888108 0x56230f88702f 0x56230f819aba 0x56230f888108 0x56230f88702f 0x56230f819aba 0x56230f888108 0x56230f88702f 0x56230f819aba 0x56230f888108 0x56230f8199da 0x56230f888108 0x56230f88702f 0x56230f819aba 0x56230f888cd4 0x56230f88702f 0x56230f819aba 0x56230f888cd4 0x56230f88702f 0x56230f81a151\n","\u001b[K     |████████████████████████████████| 2041.3 MB 7.1 kB/s \n","\u001b[?25hCollecting torchvision==0.10.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (23.2 MB)\n","\u001b[K     |████████████████████████████████| 23.2 MB 75.6 MB/s \n","\u001b[?25hCollecting torchaudio==0.9.0\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (3.10.0.2)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu111) (1.19.5)\n","Installing collected packages: torch, torchvision, torchaudio\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"]}],"source":["!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"markdown","metadata":{"id":"niCiSAyGc98d"},"source":["# Install PytorchGeometric"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18853,"status":"ok","timestamp":1645433434446,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"XLpyOcH1bKrt","outputId":"1ec47803-1b85-4198-dd52-4766b5af5f8b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 7.9 MB 4.1 MB/s \n","\u001b[K     |████████████████████████████████| 3.5 MB 3.8 MB/s \n","\u001b[K     |████████████████████████████████| 145 kB 4.0 MB/s \n","\u001b[K     |████████████████████████████████| 74 kB 4.3 MB/s \n","\u001b[K     |████████████████████████████████| 112 kB 35.2 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 55.5 MB/s \n","\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7009,"status":"ok","timestamp":1645433450261,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"MT4xPULbSGbq","outputId":"157e6291-85b1-4184-dc0b-51d832542a0e"},"outputs":[{"name":"stdout","output_type":"stream","text":["11.1\n"]}],"source":["!python -c \"import torch; print(torch.version.cuda)\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":495,"status":"ok","timestamp":1645433450752,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"YCS6Lu29PZD-","outputId":"68471cb6-c3b7-4124-e520-17c629378fa5"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.10.0+cu111\n"]}],"source":["import torch\n","print(torch.__version__)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6719,"status":"ok","timestamp":1645433457469,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"lVYmqFjhlNJl","outputId":"438a7e0f-73c7-47e9-f3ae-e192333be11c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rdkit-pypi\n","  Downloading rdkit_pypi-2021.9.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.6 MB)\n","\u001b[K     |████████████████████████████████| 20.6 MB 105.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi) (1.21.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi) (7.1.2)\n","Installing collected packages: rdkit-pypi\n","Successfully installed rdkit-pypi-2021.9.4\n"]}],"source":["!pip install rdkit-pypi"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":526,"status":"ok","timestamp":1645433457992,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"rgGlMZcNPisL"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'matplotlib'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mmatplotlib\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39minline\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnetworkx\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnx\u001b[39;00m\n","File \u001b[0;32m~/carate/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2364\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2362\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2363\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2364\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2365\u001b[0m \u001b[39mreturn\u001b[39;00m result\n","File \u001b[0;32m~/carate/venv/lib/python3.10/site-packages/IPython/core/magics/pylab.py:99\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAvailable matplotlib backends: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m backends_list)\n\u001b[1;32m     98\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     gui, backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49menable_matplotlib(args\u001b[39m.\u001b[39;49mgui\u001b[39m.\u001b[39;49mlower() \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(args\u001b[39m.\u001b[39;49mgui, \u001b[39mstr\u001b[39;49m) \u001b[39melse\u001b[39;49;00m args\u001b[39m.\u001b[39;49mgui)\n\u001b[1;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_show_matplotlib_backend(args\u001b[39m.\u001b[39mgui, backend)\n","File \u001b[0;32m~/carate/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3513\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39menable_matplotlib\u001b[39m(\u001b[39mself\u001b[39m, gui\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   3493\u001b[0m     \u001b[39m\"\"\"Enable interactive matplotlib and inline figure support.\u001b[39;00m\n\u001b[1;32m   3494\u001b[0m \n\u001b[1;32m   3495\u001b[0m \u001b[39m    This takes the following steps:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3511\u001b[0m \u001b[39m        display figures inline.\u001b[39;00m\n\u001b[1;32m   3512\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3513\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib_inline\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_inline\u001b[39;00m \u001b[39mimport\u001b[39;00m configure_inline_support\n\u001b[1;32m   3515\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m pylabtools \u001b[39mas\u001b[39;00m pt\n\u001b[1;32m   3516\u001b[0m     gui, backend \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39mfind_gui_and_backend(gui, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpylab_gui_select)\n","File \u001b[0;32m~/carate/venv/lib/python3.10/site-packages/matplotlib_inline/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m backend_inline, config  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.1.6\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# noqa\u001b[39;00m\n","File \u001b[0;32m~/carate/venv/lib/python3.10/site-packages/matplotlib_inline/backend_inline.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"A matplotlib backend for publishing figures via display_data\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Copyright (c) IPython Development Team.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Distributed under the terms of the BSD 3-Clause License.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m colors\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackends\u001b[39;00m \u001b[39mimport\u001b[39;00m backend_agg\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"]}],"source":["%matplotlib inline\n","import torch\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","\n","def visualize(h, color, epoch=None, loss=None):\n","    plt.figure(figsize=(7,7))\n","    plt.xticks([])\n","    plt.yticks([])\n","\n","    if torch.is_tensor(h):\n","        h = h.detach().cpu().numpy()\n","        plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n","        if epoch is not None and loss is not None:\n","            plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n","    else:\n","        nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n","                         node_color=color, cmap=\"Set2\")\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"M3T4xk6O1X0f"},"source":["#MCF-7\n","\n","Breast Cancer actives to MCF-7 cells\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":382,"status":"ok","timestamp":1645433462399,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"acVc7yBh1X9b"},"outputs":[],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","import rdkit as rdkit\n","\n","\n","def load_data(dataset):\n","  path = '.'\n","  dataset = TUDataset(path, name=dataset).shuffle()\n","\n","  train_dataset = dataset[len(dataset) // 20:]\n","  test_dataset = dataset[:len(dataset) // 20]\n","\n","  print(f'Train Dataset: {train_dataset}:')\n","  print('======================')\n","  print(f'Number of graphs: {len(train_dataset)}')\n","  print(f'Number of features: {train_dataset.num_features}')\n","  print(f'Number of classes: {train_dataset.num_classes}')\n","\n","  print(f'Test Dataset: {test_dataset}:')\n","  print('======================')\n","  print(f'Number of graphs: {len(test_dataset)}')\n","  print(f'Number of features: {test_dataset.num_features}')\n","  print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","  test_loader = DataLoader(test_dataset, batch_size=64)\n","  train_loader = DataLoader(train_dataset, batch_size=64)\n","  return test_loader, train_loader, dataset, train_dataset, test_dataset \n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":166},"executionInfo":{"elapsed":1116,"status":"error","timestamp":1645433465048,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"uyiMzRUYOl1Y","outputId":"1dd41862-712f-45c7-ad59-81a5f61a95c4"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-73c1c1823d2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'torch_geometric' is not defined"]}],"source":["print(torch_geometric.__version__)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":854,"status":"ok","timestamp":1645433468799,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"WyzB5Zew1YAG"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","import sklearn.metrics as metrics\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","import json \n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim, dataset):\n","        super(Net, self).__init__()\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return torch.sigmoid(x)\n","\n","def train(epoch, model, device, train_loader, optimizer, num_classes = 2):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    correct = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = F.one_hot(data.y, num_classes = num_classes).type(torch.FloatTensor)\n","        #assert len(data.y) == len(train_loader.dataset), (str(len(train_loader.dataset))+\" \"+str(len(data.y)))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.5).float()\n","        loss = torch.nn.BCELoss()\n","        loss = loss(output_probs, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        correct += (output == data.y).float().sum()/num_classes\n","    return correct / len(train_loader.dataset)\n","\n","\n","def test(loader, epoch, model, device, test=False):\n","    model.eval()\n","\n","    correct = 0\n","    if test: \n","      outs = []\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        #data.y = F.one_hot(data.y, num_classes = 6).type(torch.FloatTensor)\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        output = (output_probs > 0.5).float()\n","        correct += (torch.argmax(output, dim=1) == data.y).float().sum()\n","        #print(output, data.y)\n","        if test: \n","          outs.append(output.cpu().detach().numpy())\n","    if test: \n","      outputs =np.concatenate(outs, axis=0 ).astype(float)\n","      np.savetxt(\"MCF-7_epoch\"+str(epoch)+\".csv\", outputs)\n","    return correct / len(loader.dataset)\n","\n","def cv(data_set, n=5, num_epoch=150, num_classes = 2):\n","  result = []\n","  acc_store = []\n","  auc_store = []\n","  loss_store = [] \n","  tmp = {}\n","  for i in range(n):\n","    test_loader, train_loader, dataset, train_dataset, test_dataset  = load_data(dataset=data_set)\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = Net(dim=364, dataset=dataset).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n","\n","    for epoch in range(1, num_epoch):\n","        train_loss = train(epoch=epoch, model=model, device=device, optimizer=optimizer, train_loader=train_loader, num_classes = num_classes)\n","        loss_store.append(train_loss.cpu().tolist())\n","        train_acc = test(train_loader, device=device, model=model, epoch=epoch)\n","        test_acc = test(test_loader, device=device, model=model, epoch=epoch, test=True)\n","        acc_store.append([train_acc.cpu().tolist(), test_acc.cpu().tolist()])\n","        print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","              'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                           train_acc, test_acc))\n","        y = np.zeros((len(test_dataset)))\n","        x = np.loadtxt(\"MCF-7_epoch\"+str(epoch)+\".csv\")\n","        for i in range(len(test_dataset)):\n","          y[i] = test_dataset[i].y\n","        y = torch.as_tensor(y)\n","        y = F.one_hot(y.long(), num_classes = num_classes).long()\n","        store_auc = []\n","        for i in range(len(x[0,:])): \n","          auc = metrics.roc_auc_score(y[:,i], x[:,i])\n","          print(\"AUC of \"+str(i) +\"is:\", auc)\n","          store_auc.append(auc)\n","        auc_store.append(store_auc)\n","        \n","        if auc >=0.9:\n","          break\n","        tmp[\"Loss\"] = list(loss_store)\n","        tmp[\"Acc\"] = list(acc_store)\n","        tmp[\"AUC\"] = auc_store\n","    with open(\"/content/drive/MyDrive/CARATE_RESULTS/\"+data_set+\"_\"+str(i)+\".csv\", 'w') as f:\n","        json.dump(tmp, f)\n","        print(\"Saved iteration one to \"+\"/content/drive/MyDrive/CARATE_RESULTS/\"+data_set+\"_\"+str(i)+\".csv\")\n","    result.append(tmp)          \n","  return result \n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":1804072,"status":"error","timestamp":1645435275621,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"eY2Q6SsqeCx-","outputId":"8ebb24c8-6192-42b7-8b99-a9d2a85ae72d"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/MCF-7.zip\n","Extracting ./MCF-7/MCF-7.zip\n","Processing...\n","Done!\n","/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n"]},{"name":"stdout","output_type":"stream","text":["Train Dataset: MCF-7(26382):\n","======================\n","Number of graphs: 26382\n","Number of features: 46\n","Number of classes: 2\n","Test Dataset: MCF-7(1388):\n","======================\n","Number of graphs: 1388\n","Number of features: 46\n","Number of classes: 2\n","Epoch: 001, Train Loss: 0.9172542, Train Acc: 0.9176332, Test Acc: 0.9128242\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","Epoch: 002, Train Loss: 0.9176711, Train Acc: 0.9176332, Test Acc: 0.9128242\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","Epoch: 003, Train Loss: 0.9176711, Train Acc: 0.9178228, Test Acc: 0.9128242\n","AUC of 0is: 0.5\n","AUC of 1is: 0.5\n","Epoch: 004, Train Loss: 0.9172921, Train Acc: 0.9178607, Test Acc: 0.9149855\n","AUC of 0is: 0.5198718910421573\n","AUC of 1is: 0.5198718910421573\n","Epoch: 005, Train Loss: 0.9179365, Train Acc: 0.9183913, Test Acc: 0.9149855\n","AUC of 0is: 0.5240041224471159\n","AUC of 1is: 0.5198718910421573\n","Epoch: 006, Train Loss: 0.9184103, Train Acc: 0.9186566, Test Acc: 0.9157060\n","AUC of 0is: 0.5206611570247934\n","AUC of 1is: 0.5165289256198347\n","Epoch: 007, Train Loss: 0.9186377, Train Acc: 0.9179365, Test Acc: 0.9149855\n","AUC of 0is: 0.5123966942148761\n","AUC of 1is: 0.512396694214876\n","Epoch: 008, Train Loss: 0.9184293, Train Acc: 0.9178228, Test Acc: 0.9142651\n","AUC of 0is: 0.5082644628099173\n","AUC of 1is: 0.5082644628099173\n","Epoch: 009, Train Loss: 0.9188651, Train Acc: 0.9181639, Test Acc: 0.9149855\n","AUC of 0is: 0.5123966942148761\n","AUC of 1is: 0.512396694214876\n","Epoch: 010, Train Loss: 0.9188651, Train Acc: 0.9186566, Test Acc: 0.9149855\n","AUC of 0is: 0.5123966942148761\n","AUC of 1is: 0.512396694214876\n","Epoch: 011, Train Loss: 0.9187135, Train Acc: 0.9186566, Test Acc: 0.9149855\n","AUC of 0is: 0.5123966942148761\n","AUC of 1is: 0.512396694214876\n","Epoch: 012, Train Loss: 0.9197180, Train Acc: 0.9186566, Test Acc: 0.9149855\n","AUC of 0is: 0.5123966942148761\n","AUC of 1is: 0.512396694214876\n","Epoch: 013, Train Loss: 0.9188651, Train Acc: 0.9183155, Test Acc: 0.9157060\n","AUC of 0is: 0.5165289256198347\n","AUC of 1is: 0.5165289256198347\n","Epoch: 014, Train Loss: 0.9193769, Train Acc: 0.9185051, Test Acc: 0.9149855\n","AUC of 0is: 0.5123966942148761\n","AUC of 1is: 0.512396694214876\n","Epoch: 015, Train Loss: 0.9199644, Train Acc: 0.9188462, Test Acc: 0.9149855\n","AUC of 0is: 0.5123966942148761\n","AUC of 1is: 0.512396694214876\n","Epoch: 016, Train Loss: 0.9189410, Train Acc: 0.9189599, Test Acc: 0.9157060\n","AUC of 0is: 0.5165289256198347\n","AUC of 1is: 0.5165289256198347\n","Epoch: 017, Train Loss: 0.9202297, Train Acc: 0.9189220, Test Acc: 0.9157060\n","AUC of 0is: 0.5165289256198347\n","AUC of 1is: 0.5165289256198347\n","Epoch: 018, Train Loss: 0.9198886, Train Acc: 0.9188462, Test Acc: 0.9157060\n","AUC of 0is: 0.5165289256198347\n","AUC of 1is: 0.5165289256198347\n","Epoch: 019, Train Loss: 0.9199644, Train Acc: 0.9189220, Test Acc: 0.9157060\n","AUC of 0is: 0.5165289256198347\n","AUC of 1is: 0.5165289256198347\n","Epoch: 020, Train Loss: 0.9198506, Train Acc: 0.9193769, Test Acc: 0.9157060\n","AUC of 0is: 0.5202665240334753\n","AUC of 1is: 0.5202665240334754\n","Epoch: 021, Train Loss: 0.9206277, Train Acc: 0.9189978, Test Acc: 0.9157060\n","AUC of 0is: 0.5165289256198347\n","AUC of 1is: 0.5165289256198347\n","Epoch: 022, Train Loss: 0.9199644, Train Acc: 0.9187325, Test Acc: 0.9149855\n","AUC of 0is: 0.5123966942148761\n","AUC of 1is: 0.512396694214876\n","Epoch: 023, Train Loss: 0.9210636, Train Acc: 0.9188083, Test Acc: 0.9149855\n","AUC of 0is: 0.5123966942148761\n","AUC of 1is: 0.512396694214876\n","Epoch: 024, Train Loss: 0.9204950, Train Acc: 0.9188841, Test Acc: 0.9157060\n","AUC of 0is: 0.5165289256198347\n","AUC of 1is: 0.5165289256198347\n","Epoch: 025, Train Loss: 0.9201350, Train Acc: 0.9197559, Test Acc: 0.9171469\n","AUC of 0is: 0.524793388429752\n","AUC of 1is: 0.5247933884297521\n","Epoch: 026, Train Loss: 0.9195285, Train Acc: 0.9186566, Test Acc: 0.9149855\n","AUC of 0is: 0.5123966942148761\n","AUC of 1is: 0.512396694214876\n","Epoch: 027, Train Loss: 0.9208552, Train Acc: 0.9206277, Test Acc: 0.9171469\n","AUC of 0is: 0.5360061836706739\n","AUC of 1is: 0.5360061836706739\n","Epoch: 028, Train Loss: 0.9200212, Train Acc: 0.9204003, Test Acc: 0.9164265\n","AUC of 0is: 0.5281363538520747\n","AUC of 1is: 0.5281363538520747\n","Epoch: 029, Train Loss: 0.9206088, Train Acc: 0.9197559, Test Acc: 0.9164265\n","AUC of 0is: 0.5281363538520747\n","AUC of 1is: 0.5281363538520747\n","Epoch: 030, Train Loss: 0.9208552, Train Acc: 0.9206277, Test Acc: 0.9185879\n","AUC of 0is: 0.5405330480669507\n","AUC of 1is: 0.5405330480669506\n","Epoch: 031, Train Loss: 0.9213290, Train Acc: 0.9206277, Test Acc: 0.9171469\n","AUC of 0is: 0.5360061836706739\n","AUC of 1is: 0.5356115506793557\n","Epoch: 032, Train Loss: 0.9216890, Train Acc: 0.9215374, Test Acc: 0.9157060\n","AUC of 0is: 0.5352169176880377\n","AUC of 1is: 0.5352169176880377\n","Epoch: 033, Train Loss: 0.9211963, Train Acc: 0.9198317, Test Acc: 0.9149855\n","AUC of 0is: 0.5198718910421573\n","AUC of 1is: 0.5198718910421573\n","Epoch: 034, Train Loss: 0.9214427, Train Acc: 0.9208173, Test Acc: 0.9185879\n","AUC of 0is: 0.5405330480669507\n","AUC of 1is: 0.5405330480669506\n","Epoch: 035, Train Loss: 0.9220491, Train Acc: 0.9214616, Test Acc: 0.9171469\n","AUC of 0is: 0.5397437820843145\n","AUC of 1is: 0.5397437820843145\n","Epoch: 036, Train Loss: 0.9216890, Train Acc: 0.9221060, Test Acc: 0.9178674\n","AUC of 0is: 0.5438760134892732\n","AUC of 1is: 0.5438760134892731\n","Epoch: 037, Train Loss: 0.9220113, Train Acc: 0.9200212, Test Acc: 0.9157060\n","AUC of 0is: 0.5202665240334753\n","AUC of 1is: 0.5202665240334754\n","Epoch: 038, Train Loss: 0.9205329, Train Acc: 0.9206656, Test Acc: 0.9171469\n","AUC of 0is: 0.5360061836706739\n","AUC of 1is: 0.5360061836706739\n","Epoch: 039, Train Loss: 0.9217649, Train Acc: 0.9212342, Test Acc: 0.9185879\n","AUC of 0is: 0.5405330480669507\n","AUC of 1is: 0.5405330480669506\n","Epoch: 040, Train Loss: 0.9214048, Train Acc: 0.9204382, Test Acc: 0.9178674\n","AUC of 0is: 0.5326632182483514\n","AUC of 1is: 0.5326632182483513\n","Epoch: 041, Train Loss: 0.9222386, Train Acc: 0.9219165, Test Acc: 0.9178674\n","AUC of 0is: 0.5438760134892732\n","AUC of 1is: 0.543481380497955\n","Epoch: 042, Train Loss: 0.9206467, Train Acc: 0.9212721, Test Acc: 0.9178674\n","AUC of 0is: 0.5401384150756325\n","AUC of 1is: 0.5401384150756325\n","Epoch: 043, Train Loss: 0.9218975, Train Acc: 0.9211584, Test Acc: 0.9178674\n","AUC of 0is: 0.5401384150756325\n","AUC of 1is: 0.5401384150756325\n","Epoch: 044, Train Loss: 0.9218028, Train Acc: 0.9221439, Test Acc: 0.9200288\n","AUC of 0is: 0.5450599124632274\n","AUC of 1is: 0.5450599124632273\n","Epoch: 045, Train Loss: 0.9221818, Train Acc: 0.9227883, Test Acc: 0.9185879\n","AUC of 0is: 0.5480082448942318\n","AUC of 1is: 0.5480082448942318\n","Epoch: 046, Train Loss: 0.9227693, Train Acc: 0.9231294, Test Acc: 0.9185879\n","AUC of 0is: 0.5480082448942318\n","AUC of 1is: 0.5480082448942318\n","Epoch: 047, Train Loss: 0.9218596, Train Acc: 0.9219544, Test Acc: 0.9185879\n","AUC of 0is: 0.5442706464805913\n","AUC of 1is: 0.54840287788555\n","Epoch: 048, Train Loss: 0.9228451, Train Acc: 0.9216511, Test Acc: 0.9178674\n","AUC of 0is: 0.5401384150756325\n","AUC of 1is: 0.5401384150756325\n","Epoch: 049, Train Loss: 0.9228830, Train Acc: 0.9230157, Test Acc: 0.9193083\n","AUC of 0is: 0.5446652794719093\n","AUC of 1is: 0.548797510876868\n","Epoch: 050, Train Loss: 0.9241149, Train Acc: 0.9244940, Test Acc: 0.9185879\n","AUC of 0is: 0.5629586385487942\n","AUC of 1is: 0.5629586385487942\n","Epoch: 051, Train Loss: 0.9239633, Train Acc: 0.9232052, Test Acc: 0.9171469\n","AUC of 0is: 0.5322685852570332\n","AUC of 1is: 0.5322685852570334\n","Epoch: 052, Train Loss: 0.9234137, Train Acc: 0.9222576, Test Acc: 0.9171469\n","AUC of 0is: 0.5285309868433927\n","AUC of 1is: 0.5285309868433926\n","Epoch: 053, Train Loss: 0.9240012, Train Acc: 0.9227883, Test Acc: 0.9178674\n","AUC of 0is: 0.5326632182483514\n","AUC of 1is: 0.5367954496533099\n","Epoch: 054, Train Loss: 0.9236032, Train Acc: 0.9245698, Test Acc: 0.9221902\n","AUC of 0is: 0.561194205091744\n","AUC of 1is: 0.5653264364967027\n","Epoch: 055, Train Loss: 0.9240581, Train Acc: 0.9236601, Test Acc: 0.9200288\n","AUC of 0is: 0.5450599124632274\n","AUC of 1is: 0.549192143868186\n","Epoch: 056, Train Loss: 0.9228451, Train Acc: 0.9233189, Test Acc: 0.9193083\n","AUC of 0is: 0.5409276810582686\n","AUC of 1is: 0.5409276810582686\n","Epoch: 057, Train Loss: 0.9239823, Train Acc: 0.9229020, Test Acc: 0.9193083\n","AUC of 0is: 0.5371900826446281\n","AUC of 1is: 0.5371900826446281\n","Epoch: 058, Train Loss: 0.9246456, Train Acc: 0.9242287, Test Acc: 0.9207492\n","AUC of 0is: 0.5529297422818267\n","AUC of 1is: 0.5529297422818268\n","Epoch: 059, Train Loss: 0.9236032, Train Acc: 0.9239633, Test Acc: 0.9207492\n","AUC of 0is: 0.549192143868186\n","AUC of 1is: 0.549192143868186\n","Epoch: 060, Train Loss: 0.9238496, Train Acc: 0.9238875, Test Acc: 0.9193083\n","AUC of 0is: 0.5521404762991905\n","AUC of 1is: 0.5521404762991906\n","Epoch: 061, Train Loss: 0.9247783, Train Acc: 0.9240012, Test Acc: 0.9236311\n","AUC of 0is: 0.5694586679016614\n","AUC of 1is: 0.5694586679016613\n","Epoch: 062, Train Loss: 0.9258017, Train Acc: 0.9236980, Test Acc: 0.9200288\n","AUC of 0is: 0.548797510876868\n","AUC of 1is: 0.548797510876868\n","Epoch: 063, Train Loss: 0.9242855, Train Acc: 0.9240012, Test Acc: 0.9185879\n","AUC of 0is: 0.5405330480669507\n","AUC of 1is: 0.5405330480669506\n","Epoch: 064, Train Loss: 0.9243045, Train Acc: 0.9232431, Test Acc: 0.9171469\n","AUC of 0is: 0.5322685852570332\n","AUC of 1is: 0.5322685852570334\n","Epoch: 065, Train Loss: 0.9252331, Train Acc: 0.9224851, Test Acc: 0.9185879\n","AUC of 0is: 0.5330578512396694\n","AUC of 1is: 0.5330578512396694\n","Epoch: 066, Train Loss: 0.9246835, Train Acc: 0.9231294, Test Acc: 0.9185879\n","AUC of 0is: 0.5330578512396694\n","AUC of 1is: 0.5330578512396694\n","Epoch: 067, Train Loss: 0.9254227, Train Acc: 0.9243424, Test Acc: 0.9207492\n","AUC of 0is: 0.5529297422818267\n","AUC of 1is: 0.5529297422818268\n","Epoch: 068, Train Loss: 0.9242287, Train Acc: 0.9241149, Test Acc: 0.9229106\n","AUC of 0is: 0.5615888380830621\n","AUC of 1is: 0.5615888380830621\n","Epoch: 069, Train Loss: 0.9253848, Train Acc: 0.9257827, Test Acc: 0.9243516\n","AUC of 0is: 0.5773284977202606\n","AUC of 1is: 0.5773284977202606\n","Epoch: 070, Train Loss: 0.9249488, Train Acc: 0.9238496, Test Acc: 0.9214697\n","AUC of 0is: 0.5570619736867853\n","AUC of 1is: 0.5570619736867854\n","Epoch: 071, Train Loss: 0.9252710, Train Acc: 0.9228641, Test Acc: 0.9185879\n","AUC of 0is: 0.5330578512396694\n","AUC of 1is: 0.5330578512396694\n","Epoch: 072, Train Loss: 0.9238117, Train Acc: 0.9243424, Test Acc: 0.9207492\n","AUC of 0is: 0.5529297422818267\n","AUC of 1is: 0.5570619736867854\n","Epoch: 073, Train Loss: 0.9246077, Train Acc: 0.9230536, Test Acc: 0.9200288\n","AUC of 0is: 0.5450599124632274\n","AUC of 1is: 0.5450599124632273\n","Epoch: 074, Train Loss: 0.9254416, Train Acc: 0.9238875, Test Acc: 0.9207492\n","AUC of 0is: 0.549192143868186\n","AUC of 1is: 0.549192143868186\n","Epoch: 075, Train Loss: 0.9262565, Train Acc: 0.9261997, Test Acc: 0.9257925\n","AUC of 0is: 0.5818553621165374\n","AUC of 1is: 0.5818553621165374\n","Epoch: 076, Train Loss: 0.9254606, Train Acc: 0.9252900, Test Acc: 0.9265130\n","AUC of 0is: 0.5859875935214961\n","AUC of 1is: 0.5859875935214962\n","Epoch: 077, Train Loss: 0.9257069, Train Acc: 0.9256311, Test Acc: 0.9236311\n","AUC of 0is: 0.573196266315302\n","AUC of 1is: 0.573196266315302\n","Epoch: 078, Train Loss: 0.9263703, Train Acc: 0.9251004, Test Acc: 0.9229106\n","AUC of 0is: 0.5578512396694215\n","AUC of 1is: 0.5578512396694215\n","Epoch: 079, Train Loss: 0.9254606, Train Acc: 0.9264271, Test Acc: 0.9265130\n","AUC of 0is: 0.5897251919351366\n","AUC of 1is: 0.5897251919351367\n","Epoch: 080, Train Loss: 0.9260859, Train Acc: 0.9263134, Test Acc: 0.9301152\n","AUC of 0is: 0.6066487505462895\n","AUC of 1is: 0.614913213356207\n","Epoch: 081, Train Loss: 0.9255174, Train Acc: 0.9257069, Test Acc: 0.9243516\n","AUC of 0is: 0.5773284977202606\n","AUC of 1is: 0.5773284977202606\n","Epoch: 082, Train Loss: 0.9257069, Train Acc: 0.9272989, Test Acc: 0.9308357\n","AUC of 0is: 0.6182561787785293\n","AUC of 1is: 0.622388410183488\n","Epoch: 083, Train Loss: 0.9249110, Train Acc: 0.9271852, Test Acc: 0.9293948\n","AUC of 0is: 0.6025165191413309\n","AUC of 1is: 0.6025165191413309\n","Epoch: 084, Train Loss: 0.9273179, Train Acc: 0.9263513, Test Acc: 0.9272334\n","AUC of 0is: 0.5826446280991735\n","AUC of 1is: 0.5826446280991735\n","Epoch: 085, Train Loss: 0.9256880, Train Acc: 0.9259723, Test Acc: 0.9236311\n","AUC of 0is: 0.5657210694880207\n","AUC of 1is: 0.5698533008929795\n","Epoch: 086, Train Loss: 0.9259344, Train Acc: 0.9257069, Test Acc: 0.9272334\n","AUC of 0is: 0.5863822265128141\n","AUC of 1is: 0.5863822265128141\n","Epoch: 087, Train Loss: 0.9258775, Train Acc: 0.9262755, Test Acc: 0.9272334\n","AUC of 0is: 0.5863822265128141\n","AUC of 1is: 0.5905144579177728\n","Epoch: 088, Train Loss: 0.9256880, Train Acc: 0.9265029, Test Acc: 0.9293948\n","AUC of 0is: 0.5950413223140496\n","AUC of 1is: 0.5950413223140496\n","Epoch: 089, Train Loss: 0.9271663, Train Acc: 0.9272231, Test Acc: 0.9272334\n","AUC of 0is: 0.5901198249264548\n","AUC of 1is: 0.5901198249264548\n","Epoch: 090, Train Loss: 0.9276590, Train Acc: 0.9272989, Test Acc: 0.9243516\n","AUC of 0is: 0.5810660961339013\n","AUC of 1is: 0.5851983275388599\n","Epoch: 091, Train Loss: 0.9261428, Train Acc: 0.9280949, Test Acc: 0.9265130\n","AUC of 0is: 0.5972003887624179\n","AUC of 1is: 0.5972003887624179\n","Epoch: 092, Train Loss: 0.9271094, Train Acc: 0.9274884, Test Acc: 0.9257925\n","AUC of 0is: 0.5893305589438186\n","AUC of 1is: 0.5934627903487774\n","Epoch: 093, Train Loss: 0.9251763, Train Acc: 0.9260102, Test Acc: 0.9250720\n","AUC of 0is: 0.5777231307115788\n","AUC of 1is: 0.5777231307115788\n","Epoch: 094, Train Loss: 0.9259533, Train Acc: 0.9268441, Test Acc: 0.9257925\n","AUC of 0is: 0.5777231307115788\n","AUC of 1is: 0.5781177637028967\n","Epoch: 095, Train Loss: 0.9251384, Train Acc: 0.9288909, Test Acc: 0.9315562\n","AUC of 0is: 0.6149132133562069\n","AUC of 1is: 0.614913213356207\n","Epoch: 096, Train Loss: 0.9269578, Train Acc: 0.9293837, Test Acc: 0.9286743\n","AUC of 0is: 0.609597082977294\n","AUC of 1is: 0.6095970829772939\n","Epoch: 097, Train Loss: 0.9265598, Train Acc: 0.9279433, Test Acc: 0.9257925\n","AUC of 0is: 0.5818553621165374\n","AUC of 1is: 0.5818553621165374\n","Epoch: 098, Train Loss: 0.9269578, Train Acc: 0.9265029, Test Acc: 0.9250720\n","AUC of 0is: 0.5702479338842975\n","AUC of 1is: 0.5702479338842975\n","Epoch: 099, Train Loss: 0.9277728, Train Acc: 0.9265409, Test Acc: 0.9236311\n","AUC of 0is: 0.5694586679016614\n","AUC of 1is: 0.5694586679016613\n","Epoch: 100, Train Loss: 0.9266356, Train Acc: 0.9266167, Test Acc: 0.9221902\n","AUC of 0is: 0.5649318035053846\n","AUC of 1is: 0.5649318035053846\n","Epoch: 101, Train Loss: 0.9272042, Train Acc: 0.9264650, Test Acc: 0.9250720\n","AUC of 0is: 0.5739855322979381\n","AUC of 1is: 0.5739855322979381\n","Epoch: 102, Train Loss: 0.9275832, Train Acc: 0.9265409, Test Acc: 0.9279538\n","AUC of 0is: 0.5867768595041323\n","AUC of 1is: 0.5867768595041323\n","Epoch: 103, Train Loss: 0.9275643, Train Acc: 0.9263892, Test Acc: 0.9250720\n","AUC of 0is: 0.5739855322979381\n","AUC of 1is: 0.5739855322979381\n","Epoch: 104, Train Loss: 0.9281897, Train Acc: 0.9277538, Test Acc: 0.9265130\n","AUC of 0is: 0.578512396694215\n","AUC of 1is: 0.5867768595041323\n","Epoch: 105, Train Loss: 0.9266167, Train Acc: 0.9269957, Test Acc: 0.9257925\n","AUC of 0is: 0.5743801652892562\n","AUC of 1is: 0.5743801652892562\n","Epoch: 106, Train Loss: 0.9272420, Train Acc: 0.9268820, Test Acc: 0.9272334\n","AUC of 0is: 0.5826446280991735\n","AUC of 1is: 0.5826446280991735\n","Epoch: 107, Train Loss: 0.9274884, Train Acc: 0.9281328, Test Acc: 0.9257925\n","AUC of 0is: 0.5893305589438186\n","AUC of 1is: 0.5893305589438186\n","Epoch: 108, Train Loss: 0.9269767, Train Acc: 0.9274505, Test Acc: 0.9250720\n","AUC of 0is: 0.5814607291252193\n","AUC of 1is: 0.5814607291252193\n","Epoch: 109, Train Loss: 0.9265219, Train Acc: 0.9288151, Test Acc: 0.9279538\n","AUC of 0is: 0.5942520563314135\n","AUC of 1is: 0.5942520563314134\n","Epoch: 110, Train Loss: 0.9280381, Train Acc: 0.9275643, Test Acc: 0.9265130\n","AUC of 0is: 0.5859875935214961\n","AUC of 1is: 0.5901198249264548\n","Epoch: 111, Train Loss: 0.9288720, Train Acc: 0.9298006, Test Acc: 0.9279538\n","AUC of 0is: 0.6092024499859758\n","AUC of 1is: 0.6092024499859758\n","Epoch: 112, Train Loss: 0.9275074, Train Acc: 0.9282845, Test Acc: 0.9236311\n","AUC of 0is: 0.5806714631425831\n","AUC of 1is: 0.5806714631425831\n","Epoch: 113, Train Loss: 0.9272989, Train Acc: 0.9297248, Test Acc: 0.9286743\n","AUC of 0is: 0.6058594845636532\n","AUC of 1is: 0.6058594845636533\n","Epoch: 114, Train Loss: 0.9264082, Train Acc: 0.9274505, Test Acc: 0.9243516\n","AUC of 0is: 0.5773284977202606\n","AUC of 1is: 0.5773284977202606\n","Epoch: 115, Train Loss: 0.9278675, Train Acc: 0.9287393, Test Acc: 0.9272334\n","AUC of 0is: 0.5938574233400954\n","AUC of 1is: 0.5938574233400955\n","Epoch: 116, Train Loss: 0.9277917, Train Acc: 0.9291183, Test Acc: 0.9286743\n","AUC of 0is: 0.6021218861500127\n","AUC of 1is: 0.6021218861500127\n","Epoch: 117, Train Loss: 0.9277538, Train Acc: 0.9324160, Test Acc: 0.9322766\n","AUC of 0is: 0.6302582400020873\n","AUC of 1is: 0.6302582400020873\n","Epoch: 118, Train Loss: 0.9272989, Train Acc: 0.9301797, Test Acc: 0.9301152\n","AUC of 0is: 0.6141239473735707\n","AUC of 1is: 0.6141239473735707\n","Epoch: 119, Train Loss: 0.9275264, Train Acc: 0.9290046, Test Acc: 0.9272334\n","AUC of 0is: 0.5938574233400954\n","AUC of 1is: 0.5938574233400955\n","Epoch: 120, Train Loss: 0.9280381, Train Acc: 0.9297627, Test Acc: 0.9293948\n","AUC of 0is: 0.6058594845636532\n","AUC of 1is: 0.6062541175549714\n","Epoch: 121, Train Loss: 0.9289667, Train Acc: 0.9318854, Test Acc: 0.9315562\n","AUC of 0is: 0.6261260085971286\n","AUC of 1is: 0.6261260085971286\n","Epoch: 122, Train Loss: 0.9275643, Train Acc: 0.9307861, Test Acc: 0.9286743\n","AUC of 0is: 0.6050702185810172\n","AUC of 1is: 0.6058594845636533\n","Epoch: 123, Train Loss: 0.9303313, Train Acc: 0.9304450, Test Acc: 0.9315562\n","AUC of 0is: 0.622388410183488\n","AUC of 1is: 0.622388410183488\n","Epoch: 124, Train Loss: 0.9291562, Train Acc: 0.9286635, Test Acc: 0.9286743\n","AUC of 0is: 0.5983842877363721\n","AUC of 1is: 0.5983842877363721\n","Epoch: 125, Train Loss: 0.9280191, Train Acc: 0.9299144, Test Acc: 0.9293948\n","AUC of 0is: 0.6025165191413309\n","AUC of 1is: 0.6025165191413309\n","Epoch: 126, Train Loss: 0.9276590, Train Acc: 0.9304450, Test Acc: 0.9322766\n","AUC of 0is: 0.6227830431748062\n","AUC of 1is: 0.6227830431748062\n","Epoch: 127, Train Loss: 0.9277159, Train Acc: 0.9305208, Test Acc: 0.9286743\n","AUC of 0is: 0.6058594845636532\n","AUC of 1is: 0.6058594845636533\n","Epoch: 128, Train Loss: 0.9283792, Train Acc: 0.9305208, Test Acc: 0.9286743\n","AUC of 0is: 0.6058594845636532\n","AUC of 1is: 0.6058594845636533\n","Epoch: 129, Train Loss: 0.9288151, Train Acc: 0.9305587, Test Acc: 0.9315562\n","AUC of 0is: 0.622388410183488\n","AUC of 1is: 0.622388410183488\n","Epoch: 130, Train Loss: 0.9289857, Train Acc: 0.9323024, Test Acc: 0.9329971\n","AUC of 0is: 0.634390471407046\n","AUC of 1is: 0.634390471407046\n","Epoch: 131, Train Loss: 0.9282276, Train Acc: 0.9301797, Test Acc: 0.9279538\n","AUC of 0is: 0.5979896547450541\n","AUC of 1is: 0.5979896547450541\n","Epoch: 132, Train Loss: 0.9270715, Train Acc: 0.9303692, Test Acc: 0.9322766\n","AUC of 0is: 0.6227830431748062\n","AUC of 1is: 0.6227830431748062\n","Epoch: 133, Train Loss: 0.9287204, Train Acc: 0.9307482, Test Acc: 0.9315562\n","AUC of 0is: 0.622388410183488\n","AUC of 1is: 0.622388410183488\n","Epoch: 134, Train Loss: 0.9288720, Train Acc: 0.9307482, Test Acc: 0.9322766\n","AUC of 0is: 0.6227830431748062\n","AUC of 1is: 0.6227830431748062\n","Epoch: 135, Train Loss: 0.9294216, Train Acc: 0.9323782, Test Acc: 0.9365994\n","AUC of 0is: 0.6438388331909177\n","AUC of 1is: 0.6438388331909175\n","Epoch: 136, Train Loss: 0.9284360, Train Acc: 0.9317338, Test Acc: 0.9286743\n","AUC of 0is: 0.609597082977294\n","AUC of 1is: 0.6095970829772939\n","Epoch: 137, Train Loss: 0.9290046, Train Acc: 0.9325297, Test Acc: 0.9322766\n","AUC of 0is: 0.6302582400020873\n","AUC of 1is: 0.634390471407046\n","Epoch: 138, Train Loss: 0.9292700, Train Acc: 0.9310515, Test Acc: 0.9272334\n","AUC of 0is: 0.6088078169946578\n","AUC of 1is: 0.6129400483996165\n","Epoch: 139, Train Loss: 0.9293079, Train Acc: 0.9313926, Test Acc: 0.9279538\n","AUC of 0is: 0.6058594845636532\n","AUC of 1is: 0.6017272531586946\n","Epoch: 140, Train Loss: 0.9288720, Train Acc: 0.9310136, Test Acc: 0.9286743\n","AUC of 0is: 0.6058594845636532\n","AUC of 1is: 0.6058594845636533\n","Epoch: 141, Train Loss: 0.9279054, Train Acc: 0.9320749, Test Acc: 0.9286743\n","AUC of 0is: 0.609597082977294\n","AUC of 1is: 0.6095970829772939\n","Epoch: 142, Train Loss: 0.9290425, Train Acc: 0.9330604, Test Acc: 0.9301152\n","AUC of 0is: 0.6253367426144925\n","AUC of 1is: 0.6253367426144926\n","Epoch: 143, Train Loss: 0.9298006, Train Acc: 0.9327193, Test Acc: 0.9308357\n","AUC of 0is: 0.6294689740194512\n","AUC of 1is: 0.6294689740194511\n","Epoch: 144, Train Loss: 0.9285877, Train Acc: 0.9326435, Test Acc: 0.9301152\n","AUC of 0is: 0.6253367426144925\n","AUC of 1is: 0.6253367426144926\n","Epoch: 145, Train Loss: 0.9293268, Train Acc: 0.9316580, Test Acc: 0.9279538\n","AUC of 0is: 0.6241528436405384\n","AUC of 1is: 0.6237582106492202\n","Epoch: 146, Train Loss: 0.9284360, Train Acc: 0.9322265, Test Acc: 0.9286743\n","AUC of 0is: 0.6208098782182156\n","AUC of 1is: 0.6208098782182158\n","Epoch: 147, Train Loss: 0.9297627, Train Acc: 0.9325677, Test Acc: 0.9315562\n","AUC of 0is: 0.6261260085971286\n","AUC of 1is: 0.6261260085971286\n","Epoch: 148, Train Loss: 0.9288341, Train Acc: 0.9315063, Test Acc: 0.9279538\n","AUC of 0is: 0.6054648515723352\n","AUC of 1is: 0.6054648515723352\n","Epoch: 149, Train Loss: 0.9296869, Train Acc: 0.9318475, Test Acc: 0.9337175\n","AUC of 0is: 0.6310475059847235\n","AUC of 1is: 0.6310475059847235\n","Epoch: 150, Train Loss: 0.9291183, Train Acc: 0.9332120, Test Acc: 0.9308357\n","AUC of 0is: 0.6444193676740135\n","AUC of 1is: 0.6444193676740135\n","Epoch: 151, Train Loss: 0.9289857, Train Acc: 0.9327572, Test Acc: 0.9322766\n","AUC of 0is: 0.6339958384157279\n","AUC of 1is: 0.6339958384157279\n","Epoch: 152, Train Loss: 0.9295353, Train Acc: 0.9316580, Test Acc: 0.9279538\n","AUC of 0is: 0.6204152452268976\n","AUC of 1is: 0.6204152452268977\n","Epoch: 153, Train Loss: 0.9292510, Train Acc: 0.9328330, Test Acc: 0.9337175\n","AUC of 0is: 0.6347851043983641\n","AUC of 1is: 0.634390471407046\n","Epoch: 154, Train Loss: 0.9295732, Train Acc: 0.9327193, Test Acc: 0.9329971\n","AUC of 0is: 0.634390471407046\n","AUC of 1is: 0.634390471407046\n","Epoch: 155, Train Loss: 0.9287962, Train Acc: 0.9312031, Test Acc: 0.9329971\n","AUC of 0is: 0.6347851043983641\n","AUC of 1is: 0.6306528729934054\n","Epoch: 156, Train Loss: 0.9291183, Train Acc: 0.9334774, Test Acc: 0.9358789\n","AUC of 0is: 0.6509193970268807\n","AUC of 1is: 0.6509193970268807\n","Epoch: 157, Train Loss: 0.9312789, Train Acc: 0.9330983, Test Acc: 0.9315562\n","AUC of 0is: 0.622388410183488\n","AUC of 1is: 0.622388410183488\n","Epoch: 158, Train Loss: 0.9301986, Train Acc: 0.9330983, Test Acc: 0.9301152\n","AUC of 0is: 0.6178615457872112\n","AUC of 1is: 0.6178615457872113\n","Epoch: 159, Train Loss: 0.9299144, Train Acc: 0.9330604, Test Acc: 0.9337175\n","AUC of 0is: 0.6463925326306039\n","AUC of 1is: 0.6422603012256453\n","Epoch: 160, Train Loss: 0.9300660, Train Acc: 0.9331741, Test Acc: 0.9358789\n","AUC of 0is: 0.6471817986132401\n","AUC of 1is: 0.6471817986132401\n","Epoch: 161, Train Loss: 0.9308051, Train Acc: 0.9332879, Test Acc: 0.9344380\n","AUC of 0is: 0.6463925326306039\n","AUC of 1is: 0.6463925326306039\n","Epoch: 162, Train Loss: 0.9297248, Train Acc: 0.9341218, Test Acc: 0.9351585\n","AUC of 0is: 0.6505247640355627\n","AUC of 1is: 0.6505247640355627\n","Epoch: 163, Train Loss: 0.9299144, Train Acc: 0.9340081, Test Acc: 0.9344380\n","AUC of 0is: 0.6385227028120046\n","AUC of 1is: 0.6430495672082814\n","Epoch: 164, Train Loss: 0.9298196, Train Acc: 0.9332120, Test Acc: 0.9337175\n","AUC of 0is: 0.6459978996392859\n","AUC of 1is: 0.6459978996392859\n","Epoch: 165, Train Loss: 0.9294974, Train Acc: 0.9330225, Test Acc: 0.9308357\n","AUC of 0is: 0.6332065724330918\n","AUC of 1is: 0.6332065724330918\n","Epoch: 166, Train Loss: 0.9293837, Train Acc: 0.9329088, Test Acc: 0.9329971\n","AUC of 0is: 0.634390471407046\n","AUC of 1is: 0.634390471407046\n","Epoch: 167, Train Loss: 0.9308051, Train Acc: 0.9337048, Test Acc: 0.9286743\n","AUC of 0is: 0.6320226734591375\n","AUC of 1is: 0.6320226734591375\n","Epoch: 168, Train Loss: 0.9297248, Train Acc: 0.9331741, Test Acc: 0.9308357\n","AUC of 0is: 0.6332065724330918\n","AUC of 1is: 0.6332065724330918\n","Epoch: 169, Train Loss: 0.9299902, Train Acc: 0.9342355, Test Acc: 0.9337175\n","AUC of 0is: 0.6501301310442447\n","AUC of 1is: 0.6459978996392859\n","Epoch: 170, Train Loss: 0.9290425, Train Acc: 0.9330225, Test Acc: 0.9308357\n","AUC of 0is: 0.640681769260373\n","AUC of 1is: 0.6406817692603729\n","Epoch: 171, Train Loss: 0.9303313, Train Acc: 0.9338564, Test Acc: 0.9301152\n","AUC of 0is: 0.640287136269055\n","AUC of 1is: 0.6444193676740135\n","Epoch: 172, Train Loss: 0.9296111, Train Acc: 0.9341975, Test Acc: 0.9337175\n","AUC of 0is: 0.653473096466567\n","AUC of 1is: 0.6534730964665671\n","Epoch: 173, Train Loss: 0.9294785, Train Acc: 0.9335532, Test Acc: 0.9351585\n","AUC of 0is: 0.646787165621922\n","AUC of 1is: 0.646787165621922\n","Epoch: 174, Train Loss: 0.9308619, Train Acc: 0.9333258, Test Acc: 0.9344380\n","AUC of 0is: 0.6422603012256454\n","AUC of 1is: 0.6426549342169633\n","Epoch: 175, Train Loss: 0.9312599, Train Acc: 0.9347661, Test Acc: 0.9337175\n","AUC of 0is: 0.6572106948802077\n","AUC of 1is: 0.6572106948802078\n","Epoch: 176, Train Loss: 0.9312599, Train Acc: 0.9334016, Test Acc: 0.9279538\n","AUC of 0is: 0.6391032372951007\n","AUC of 1is: 0.6391032372951007\n","Epoch: 177, Train Loss: 0.9308809, Train Acc: 0.9346904, Test Acc: 0.9358789\n","AUC of 0is: 0.658394593854162\n","AUC of 1is: 0.6583945938541619\n","Epoch: 178, Train Loss: 0.9308619, Train Acc: 0.9331362, Test Acc: 0.9344380\n","AUC of 0is: 0.6426549342169634\n","AUC of 1is: 0.6426549342169633\n","Epoch: 179, Train Loss: 0.9297817, Train Acc: 0.9341596, Test Acc: 0.9279538\n","AUC of 0is: 0.6204152452268976\n","AUC of 1is: 0.6204152452268977\n","Epoch: 180, Train Loss: 0.9301986, Train Acc: 0.9336669, Test Acc: 0.9272334\n","AUC of 0is: 0.6274958090628608\n","AUC of 1is: 0.6274958090628607\n","Epoch: 181, Train Loss: 0.9307293, Train Acc: 0.9363961, Test Acc: 0.9329971\n","AUC of 0is: 0.6605536603025303\n","AUC of 1is: 0.6605536603025303\n","Epoch: 182, Train Loss: 0.9312978, Train Acc: 0.9358653, Test Acc: 0.9344380\n","AUC of 0is: 0.6613429262851663\n","AUC of 1is: 0.6613429262851663\n","Epoch: 183, Train Loss: 0.9316390, Train Acc: 0.9351452, Test Acc: 0.9344380\n","AUC of 0is: 0.6538677294578852\n","AUC of 1is: 0.6538677294578852\n","Epoch: 184, Train Loss: 0.9303692, Train Acc: 0.9348798, Test Acc: 0.9315562\n","AUC of 0is: 0.641076402251691\n","AUC of 1is: 0.6406817692603729\n","Epoch: 185, Train Loss: 0.9305398, Train Acc: 0.9348040, Test Acc: 0.9315562\n","AUC of 0is: 0.641076402251691\n","AUC of 1is: 0.641076402251691\n","Epoch: 186, Train Loss: 0.9309188, Train Acc: 0.9348040, Test Acc: 0.9308357\n","AUC of 0is: 0.6332065724330918\n","AUC of 1is: 0.6332065724330918\n","Epoch: 187, Train Loss: 0.9310136, Train Acc: 0.9341975, Test Acc: 0.9329971\n","AUC of 0is: 0.634390471407046\n","AUC of 1is: 0.634390471407046\n","Epoch: 188, Train Loss: 0.9308809, Train Acc: 0.9336669, Test Acc: 0.9308357\n","AUC of 0is: 0.6257313756058106\n","AUC of 1is: 0.6257313756058106\n","Epoch: 189, Train Loss: 0.9307293, Train Acc: 0.9346904, Test Acc: 0.9308357\n","AUC of 0is: 0.6444193676740135\n","AUC of 1is: 0.6440247346826955\n","Epoch: 190, Train Loss: 0.9309567, Train Acc: 0.9361686, Test Acc: 0.9322766\n","AUC of 0is: 0.6676342241384934\n","AUC of 1is: 0.6676342241384934\n","Epoch: 191, Train Loss: 0.9309188, Train Acc: 0.9357517, Test Acc: 0.9337175\n","AUC of 0is: 0.653473096466567\n","AUC of 1is: 0.6534730964665671\n","Epoch: 192, Train Loss: 0.9318854, Train Acc: 0.9348798, Test Acc: 0.9315562\n","AUC of 0is: 0.6261260085971286\n","AUC of 1is: 0.6261260085971286\n","Epoch: 193, Train Loss: 0.9318286, Train Acc: 0.9340839, Test Acc: 0.9329971\n","AUC of 0is: 0.6497354980529264\n","AUC of 1is: 0.6456032666479677\n","Epoch: 194, Train Loss: 0.9335911, Train Acc: 0.9345387, Test Acc: 0.9308357\n","AUC of 0is: 0.6369441708467323\n","AUC of 1is: 0.6369441708467324\n","Epoch: 195, Train Loss: 0.9299712, Train Acc: 0.9348040, Test Acc: 0.9286743\n","AUC of 0is: 0.6394978702864187\n","AUC of 1is: 0.6394978702864187\n","Epoch: 196, Train Loss: 0.9313357, Train Acc: 0.9361686, Test Acc: 0.9344380\n","AUC of 0is: 0.6501301310442447\n","AUC of 1is: 0.6501301310442446\n","Epoch: 197, Train Loss: 0.9310325, Train Acc: 0.9340081, Test Acc: 0.9257925\n","AUC of 0is: 0.6121507824169803\n","AUC of 1is: 0.6080185510120216\n","Epoch: 198, Train Loss: 0.9307861, Train Acc: 0.9335532, Test Acc: 0.9301152\n","AUC of 0is: 0.6290743410281331\n","AUC of 1is: 0.6290743410281331\n","Epoch: 199, Train Loss: 0.9310325, Train Acc: 0.9344250, Test Acc: 0.9322766\n","AUC of 0is: 0.6377334368293686\n","AUC of 1is: 0.6377334368293684\n","Epoch: 200, Train Loss: 0.9308999, Train Acc: 0.9350694, Test Acc: 0.9308357\n","AUC of 0is: 0.6444193676740135\n","AUC of 1is: 0.6444193676740135\n","Epoch: 201, Train Loss: 0.9307861, Train Acc: 0.9345008, Test Acc: 0.9293948\n","AUC of 0is: 0.640287136269055\n","AUC of 1is: 0.6357602718727782\n","Epoch: 202, Train Loss: 0.9312410, Train Acc: 0.9346904, Test Acc: 0.9293948\n","AUC of 0is: 0.6249421096231744\n","AUC of 1is: 0.6249421096231744\n","Epoch: 203, Train Loss: 0.9309757, Train Acc: 0.9336669, Test Acc: 0.9293948\n","AUC of 0is: 0.6286797080368149\n","AUC of 1is: 0.628285075045497\n","Epoch: 204, Train Loss: 0.9311652, Train Acc: 0.9347661, Test Acc: 0.9286743\n","AUC of 0is: 0.6282850750454969\n","AUC of 1is: 0.628285075045497\n","Epoch: 205, Train Loss: 0.9320749, Train Acc: 0.9349936, Test Acc: 0.9301152\n","AUC of 0is: 0.6290743410281331\n","AUC of 1is: 0.6286797080368149\n","Epoch: 206, Train Loss: 0.9320749, Train Acc: 0.9358653, Test Acc: 0.9329971\n","AUC of 0is: 0.6493408650616084\n","AUC of 1is: 0.6493408650616084\n","Epoch: 207, Train Loss: 0.9318664, Train Acc: 0.9334395, Test Acc: 0.9279538\n","AUC of 0is: 0.6204152452268976\n","AUC of 1is: 0.6204152452268977\n","Epoch: 208, Train Loss: 0.9326435, Train Acc: 0.9339322, Test Acc: 0.9279538\n","AUC of 0is: 0.6129400483996165\n","AUC of 1is: 0.6129400483996165\n","Epoch: 209, Train Loss: 0.9321128, Train Acc: 0.9350315, Test Acc: 0.9293948\n","AUC of 0is: 0.6361549048640962\n","AUC of 1is: 0.6361549048640962\n","Epoch: 210, Train Loss: 0.9313926, Train Acc: 0.9347282, Test Acc: 0.9301152\n","AUC of 0is: 0.6253367426144925\n","AUC of 1is: 0.6253367426144926\n","Epoch: 211, Train Loss: 0.9318475, Train Acc: 0.9349557, Test Acc: 0.9301152\n","AUC of 0is: 0.6290743410281331\n","AUC of 1is: 0.6290743410281331\n","Epoch: 212, Train Loss: 0.9329467, Train Acc: 0.9357517, Test Acc: 0.9308357\n","AUC of 0is: 0.6369441708467323\n","AUC of 1is: 0.6369441708467324\n","Epoch: 213, Train Loss: 0.9332500, Train Acc: 0.9357896, Test Acc: 0.9308357\n","AUC of 0is: 0.640681769260373\n","AUC of 1is: 0.6406817692603729\n","Epoch: 214, Train Loss: 0.9326245, Train Acc: 0.9348419, Test Acc: 0.9286743\n","AUC of 0is: 0.6282850750454969\n","AUC of 1is: 0.628285075045497\n","Epoch: 215, Train Loss: 0.9337996, Train Acc: 0.9354105, Test Acc: 0.9308357\n","AUC of 0is: 0.640681769260373\n","AUC of 1is: 0.6406817692603729\n","Epoch: 216, Train Loss: 0.9329088, Train Acc: 0.9353347, Test Acc: 0.9337175\n","AUC of 0is: 0.653473096466567\n","AUC of 1is: 0.6534730964665671\n","Epoch: 217, Train Loss: 0.9327951, Train Acc: 0.9333637, Test Acc: 0.9286743\n","AUC of 0is: 0.6320226734591375\n","AUC of 1is: 0.6320226734591375\n","Epoch: 218, Train Loss: 0.9317338, Train Acc: 0.9361307, Test Acc: 0.9351585\n","AUC of 0is: 0.665475157690125\n","AUC of 1is: 0.665475157690125\n","Epoch: 219, Train Loss: 0.9314684, Train Acc: 0.9346904, Test Acc: 0.9344380\n","AUC of 0is: 0.6572106948802077\n","AUC of 1is: 0.6576053278715257\n","Epoch: 220, Train Loss: 0.9310704, Train Acc: 0.9353726, Test Acc: 0.9337175\n","AUC of 0is: 0.6646858917074889\n","AUC of 1is: 0.6646858917074889\n","Epoch: 221, Train Loss: 0.9324729, Train Acc: 0.9361686, Test Acc: 0.9351585\n","AUC of 0is: 0.665475157690125\n","AUC of 1is: 0.665475157690125\n","Epoch: 222, Train Loss: 0.9326624, Train Acc: 0.9349936, Test Acc: 0.9337175\n","AUC of 0is: 0.6684234901211294\n","AUC of 1is: 0.6684234901211294\n","Epoch: 223, Train Loss: 0.9329467, Train Acc: 0.9335153, Test Acc: 0.9301152\n","AUC of 0is: 0.6141239473735707\n","AUC of 1is: 0.6141239473735707\n","Epoch: 224, Train Loss: 0.9329467, Train Acc: 0.9337427, Test Acc: 0.9293948\n","AUC of 0is: 0.6174669127958932\n","AUC of 1is: 0.6174669127958933\n","Epoch: 225, Train Loss: 0.9320749, Train Acc: 0.9351073, Test Acc: 0.9286743\n","AUC of 0is: 0.6320226734591375\n","AUC of 1is: 0.6320226734591375\n","Epoch: 226, Train Loss: 0.9322076, Train Acc: 0.9363582, Test Acc: 0.9322766\n","AUC of 0is: 0.6339958384157279\n","AUC of 1is: 0.6339958384157279\n","Epoch: 227, Train Loss: 0.9317906, Train Acc: 0.9354863, Test Acc: 0.9308357\n","AUC of 0is: 0.6369441708467323\n","AUC of 1is: 0.6369441708467324\n","Epoch: 228, Train Loss: 0.9323213, Train Acc: 0.9360170, Test Acc: 0.9322766\n","AUC of 0is: 0.6452086336566497\n","AUC of 1is: 0.6452086336566496\n","Epoch: 229, Train Loss: 0.9329278, Train Acc: 0.9345387, Test Acc: 0.9322766\n","AUC of 0is: 0.6452086336566497\n","AUC of 1is: 0.6452086336566496\n","Epoch: 230, Train Loss: 0.9335153, Train Acc: 0.9359791, Test Acc: 0.9315562\n","AUC of 0is: 0.6448140006653317\n","AUC of 1is: 0.6448140006653316\n","Epoch: 231, Train Loss: 0.9325108, Train Acc: 0.9344250, Test Acc: 0.9315562\n","AUC of 0is: 0.6298636070107693\n","AUC of 1is: 0.6298636070107693\n","Epoch: 232, Train Loss: 0.9319043, Train Acc: 0.9353347, Test Acc: 0.9337175\n","AUC of 0is: 0.6422603012256454\n","AUC of 1is: 0.6422603012256453\n","Epoch: 233, Train Loss: 0.9325866, Train Acc: 0.9348798, Test Acc: 0.9293948\n","AUC of 0is: 0.6286797080368149\n","AUC of 1is: 0.6286797080368149\n","Epoch: 234, Train Loss: 0.9329467, Train Acc: 0.9361307, Test Acc: 0.9308357\n","AUC of 0is: 0.6332065724330918\n","AUC of 1is: 0.6332065724330918\n","Epoch: 235, Train Loss: 0.9331552, Train Acc: 0.9346904, Test Acc: 0.9279538\n","AUC of 0is: 0.6129400483996165\n","AUC of 1is: 0.6129400483996165\n","Epoch: 236, Train Loss: 0.9325866, Train Acc: 0.9349557, Test Acc: 0.9286743\n","AUC of 0is: 0.6208098782182156\n","AUC of 1is: 0.6208098782182158\n","Epoch: 237, Train Loss: 0.9331741, Train Acc: 0.9373816, Test Acc: 0.9365994\n","AUC of 0is: 0.6662644236727612\n","AUC of 1is: 0.6662644236727612\n","Epoch: 238, Train Loss: 0.9321128, Train Acc: 0.9373816, Test Acc: 0.9351585\n","AUC of 0is: 0.6579999608628438\n","AUC of 1is: 0.6579999608628438\n","Epoch: 239, Train Loss: 0.9310515, Train Acc: 0.9340460, Test Acc: 0.9293948\n","AUC of 0is: 0.6174669127958932\n","AUC of 1is: 0.6174669127958933\n","Epoch: 240, Train Loss: 0.9330225, Train Acc: 0.9370783, Test Acc: 0.9329971\n","AUC of 0is: 0.6601590273112121\n","AUC of 1is: 0.6605536603025303\n","Epoch: 241, Train Loss: 0.9327572, Train Acc: 0.9342734, Test Acc: 0.9286743\n","AUC of 0is: 0.6245474766318564\n","AUC of 1is: 0.6245474766318564\n","Epoch: 242, Train Loss: 0.9330415, Train Acc: 0.9343113, Test Acc: 0.9308357\n","AUC of 0is: 0.6294689740194512\n","AUC of 1is: 0.6294689740194511\n","Epoch: 243, Train Loss: 0.9328899, Train Acc: 0.9352968, Test Acc: 0.9308357\n","AUC of 0is: 0.6294689740194512\n","AUC of 1is: 0.6294689740194511\n","Epoch: 244, Train Loss: 0.9332500, Train Acc: 0.9350315, Test Acc: 0.9308357\n","AUC of 0is: 0.6444193676740135\n","AUC of 1is: 0.6444193676740135\n","Epoch: 245, Train Loss: 0.9328709, Train Acc: 0.9363202, Test Acc: 0.9301152\n","AUC of 0is: 0.647762333096336\n","AUC of 1is: 0.6477623330963361\n","Epoch: 246, Train Loss: 0.9338943, Train Acc: 0.9352968, Test Acc: 0.9301152\n","AUC of 0is: 0.6440247346826955\n","AUC of 1is: 0.6440247346826955\n","Epoch: 247, Train Loss: 0.9322644, Train Acc: 0.9342734, Test Acc: 0.9293948\n","AUC of 0is: 0.6324173064504556\n","AUC of 1is: 0.6324173064504557\n","Epoch: 248, Train Loss: 0.9328709, Train Acc: 0.9341975, Test Acc: 0.9293948\n","AUC of 0is: 0.6212045112095338\n","AUC of 1is: 0.6212045112095338\n","Epoch: 249, Train Loss: 0.9324918, Train Acc: 0.9342734, Test Acc: 0.9315562\n","AUC of 0is: 0.641076402251691\n","AUC of 1is: 0.641076402251691\n","Epoch: 250, Train Loss: 0.9339512, Train Acc: 0.9348798, Test Acc: 0.9315562\n","AUC of 0is: 0.6298636070107693\n","AUC of 1is: 0.6298636070107693\n","Epoch: 251, Train Loss: 0.9342355, Train Acc: 0.9357517, Test Acc: 0.9308357\n","AUC of 0is: 0.640681769260373\n","AUC of 1is: 0.6406817692603729\n","Epoch: 252, Train Loss: 0.9337237, Train Acc: 0.9345387, Test Acc: 0.9329971\n","AUC of 0is: 0.6456032666479679\n","AUC of 1is: 0.6456032666479677\n","Epoch: 253, Train Loss: 0.9335911, Train Acc: 0.9343871, Test Acc: 0.9308357\n","AUC of 0is: 0.6332065724330918\n","AUC of 1is: 0.6332065724330918\n","Epoch: 254, Train Loss: 0.9350694, Train Acc: 0.9346524, Test Acc: 0.9286743\n","AUC of 0is: 0.6282850750454969\n","AUC of 1is: 0.628285075045497\n","Epoch: 255, Train Loss: 0.9338943, Train Acc: 0.9341218, Test Acc: 0.9322766\n","AUC of 0is: 0.6377334368293686\n","AUC of 1is: 0.6377334368293684\n","Epoch: 256, Train Loss: 0.9335532, Train Acc: 0.9365855, Test Acc: 0.9329971\n","AUC of 0is: 0.6605536603025303\n","AUC of 1is: 0.6605536603025303\n","Epoch: 257, Train Loss: 0.9328330, Train Acc: 0.9365097, Test Acc: 0.9351585\n","AUC of 0is: 0.646787165621922\n","AUC of 1is: 0.646787165621922\n","Epoch: 258, Train Loss: 0.9341975, Train Acc: 0.9341975, Test Acc: 0.9315562\n","AUC of 0is: 0.622388410183488\n","AUC of 1is: 0.622388410183488\n","Epoch: 259, Train Loss: 0.9338564, Train Acc: 0.9330604, Test Acc: 0.9322766\n","AUC of 0is: 0.6227830431748062\n","AUC of 1is: 0.6227830431748062\n","Epoch: 260, Train Loss: 0.9335532, Train Acc: 0.9359033, Test Acc: 0.9337175\n","AUC of 0is: 0.6459978996392859\n","AUC of 1is: 0.6459978996392859\n","Epoch: 261, Train Loss: 0.9335721, Train Acc: 0.9329846, Test Acc: 0.9286743\n","AUC of 0is: 0.6282850750454969\n","AUC of 1is: 0.628285075045497\n","Epoch: 262, Train Loss: 0.9339133, Train Acc: 0.9332120, Test Acc: 0.9279538\n","AUC of 0is: 0.6204152452268976\n","AUC of 1is: 0.6204152452268977\n","Epoch: 263, Train Loss: 0.9334964, Train Acc: 0.9351452, Test Acc: 0.9315562\n","AUC of 0is: 0.641076402251691\n","AUC of 1is: 0.641076402251691\n","Epoch: 264, Train Loss: 0.9341786, Train Acc: 0.9359791, Test Acc: 0.9351585\n","AUC of 0is: 0.6505247640355627\n","AUC of 1is: 0.6505247640355627\n","Epoch: 265, Train Loss: 0.9338564, Train Acc: 0.9354863, Test Acc: 0.9358789\n","AUC of 0is: 0.6509193970268807\n","AUC of 1is: 0.6550516284318394\n","Epoch: 266, Train Loss: 0.9333258, Train Acc: 0.9350694, Test Acc: 0.9322766\n","AUC of 0is: 0.6265206415884467\n","AUC of 1is: 0.6265206415884467\n","Epoch: 267, Train Loss: 0.9339512, Train Acc: 0.9364718, Test Acc: 0.9351585\n","AUC of 0is: 0.6542623624492032\n","AUC of 1is: 0.6542623624492033\n","Epoch: 268, Train Loss: 0.9335532, Train Acc: 0.9367372, Test Acc: 0.9358789\n","AUC of 0is: 0.665869790681443\n","AUC of 1is: 0.6658697906814431\n","Epoch: 269, Train Loss: 0.9351262, Train Acc: 0.9370783, Test Acc: 0.9351585\n","AUC of 0is: 0.6579999608628438\n","AUC of 1is: 0.6579999608628438\n","Epoch: 270, Train Loss: 0.9340081, Train Acc: 0.9351831, Test Acc: 0.9329971\n","AUC of 0is: 0.6418656682343272\n","AUC of 1is: 0.6418656682343271\n","Epoch: 271, Train Loss: 0.9345198, Train Acc: 0.9348798, Test Acc: 0.9315562\n","AUC of 0is: 0.6336012054244098\n","AUC of 1is: 0.6336012054244099\n","Epoch: 272, Train Loss: 0.9340649, Train Acc: 0.9377985, Test Acc: 0.9351585\n","AUC of 0is: 0.665475157690125\n","AUC of 1is: 0.665475157690125\n","Epoch: 273, Train Loss: 0.9362255, Train Acc: 0.9359791, Test Acc: 0.9315562\n","AUC of 0is: 0.6336012054244098\n","AUC of 1is: 0.6336012054244099\n","Epoch: 274, Train Loss: 0.9331362, Train Acc: 0.9351452, Test Acc: 0.9308357\n","AUC of 0is: 0.640681769260373\n","AUC of 1is: 0.6406817692603729\n","Epoch: 275, Train Loss: 0.9339322, Train Acc: 0.9361307, Test Acc: 0.9351585\n","AUC of 0is: 0.665475157690125\n","AUC of 1is: 0.665475157690125\n","Epoch: 276, Train Loss: 0.9340081, Train Acc: 0.9370025, Test Acc: 0.9344380\n","AUC of 0is: 0.6613429262851663\n","AUC of 1is: 0.6613429262851663\n","Epoch: 277, Train Loss: 0.9339512, Train Acc: 0.9350694, Test Acc: 0.9337175\n","AUC of 0is: 0.6459978996392859\n","AUC of 1is: 0.6459978996392859\n","Epoch: 278, Train Loss: 0.9347851, Train Acc: 0.9372678, Test Acc: 0.9373199\n","AUC of 0is: 0.6778718519050011\n","AUC of 1is: 0.6778718519050012\n","Epoch: 279, Train Loss: 0.9342165, Train Acc: 0.9349557, Test Acc: 0.9301152\n","AUC of 0is: 0.6290743410281331\n","AUC of 1is: 0.6290743410281331\n","Epoch: 280, Train Loss: 0.9353347, Train Acc: 0.9367372, Test Acc: 0.9344380\n","AUC of 0is: 0.6426549342169634\n","AUC of 1is: 0.6426549342169633\n","Epoch: 281, Train Loss: 0.9342165, Train Acc: 0.9354105, Test Acc: 0.9293948\n","AUC of 0is: 0.6286797080368149\n","AUC of 1is: 0.6286797080368149\n","Epoch: 282, Train Loss: 0.9348988, Train Acc: 0.9362823, Test Acc: 0.9322766\n","AUC of 0is: 0.6489462320702903\n","AUC of 1is: 0.6489462320702905\n","Epoch: 283, Train Loss: 0.9331362, Train Acc: 0.9348040, Test Acc: 0.9265130\n","AUC of 0is: 0.6084131840033398\n","AUC of 1is: 0.6084131840033397\n","Epoch: 284, Train Loss: 0.9342923, Train Acc: 0.9349936, Test Acc: 0.9308357\n","AUC of 0is: 0.640681769260373\n","AUC of 1is: 0.6406817692603729\n","Epoch: 285, Train Loss: 0.9332120, Train Acc: 0.9372299, Test Acc: 0.9329971\n","AUC of 0is: 0.6493408650616084\n","AUC of 1is: 0.6493408650616084\n","Epoch: 286, Train Loss: 0.9345766, Train Acc: 0.9351073, Test Acc: 0.9293948\n","AUC of 0is: 0.6398925032777368\n","AUC of 1is: 0.6398925032777368\n","Epoch: 287, Train Loss: 0.9352210, Train Acc: 0.9356380, Test Acc: 0.9301152\n","AUC of 0is: 0.6440247346826955\n","AUC of 1is: 0.6440247346826955\n","Epoch: 288, Train Loss: 0.9343492, Train Acc: 0.9348419, Test Acc: 0.9301152\n","AUC of 0is: 0.6215991442008519\n","AUC of 1is: 0.6215991442008519\n","Epoch: 289, Train Loss: 0.9339322, Train Acc: 0.9344629, Test Acc: 0.9308357\n","AUC of 0is: 0.6332065724330918\n","AUC of 1is: 0.6332065724330918\n","Epoch: 290, Train Loss: 0.9329088, Train Acc: 0.9351073, Test Acc: 0.9322766\n","AUC of 0is: 0.6377334368293686\n","AUC of 1is: 0.6377334368293684\n","Epoch: 291, Train Loss: 0.9340270, Train Acc: 0.9329088, Test Acc: 0.9286743\n","AUC of 0is: 0.6208098782182156\n","AUC of 1is: 0.6208098782182158\n","Epoch: 292, Train Loss: 0.9341786, Train Acc: 0.9344629, Test Acc: 0.9301152\n","AUC of 0is: 0.6290743410281331\n","AUC of 1is: 0.6290743410281331\n","Epoch: 293, Train Loss: 0.9343113, Train Acc: 0.9346145, Test Acc: 0.9322766\n","AUC of 0is: 0.6526838304839309\n","AUC of 1is: 0.652683830483931\n","Epoch: 294, Train Loss: 0.9339322, Train Acc: 0.9363961, Test Acc: 0.9344380\n","AUC of 0is: 0.6538677294578852\n","AUC of 1is: 0.6538677294578852\n","Epoch: 295, Train Loss: 0.9351831, Train Acc: 0.9351073, Test Acc: 0.9337175\n","AUC of 0is: 0.653473096466567\n","AUC of 1is: 0.6534730964665671\n","Epoch: 296, Train Loss: 0.9339322, Train Acc: 0.9362823, Test Acc: 0.9344380\n","AUC of 0is: 0.6463925326306039\n","AUC of 1is: 0.6463925326306039\n","Epoch: 297, Train Loss: 0.9356000, Train Acc: 0.9346904, Test Acc: 0.9373199\n","AUC of 0is: 0.6591838598367981\n","AUC of 1is: 0.659183859836798\n","Epoch: 298, Train Loss: 0.9354295, Train Acc: 0.9362823, Test Acc: 0.9358789\n","AUC of 0is: 0.6546569954405212\n","AUC of 1is: 0.6546569954405214\n","Epoch: 299, Train Loss: 0.9339702, Train Acc: 0.9363582, Test Acc: 0.9344380\n","AUC of 0is: 0.6576053278715257\n","AUC of 1is: 0.6576053278715257\n"]},{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-687287cce681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"MCF-7\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-e392b3e486a0>\u001b[0m in \u001b[0;36mcv\u001b[0;34m(data_set, n, num_epoch, num_classes)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Acc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_store\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"AUC\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc_store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/CARATE_RESULTS/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved iteration one to \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/CARATE_RESULTS/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CARATE_RESULTS/MCF-7_1.csv'"]}],"source":["dataset = \"MCF-7\"\n","result = cv(data_set=dataset, n=5, num_epoch=300)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"tvHLlD8Hrndp"},"outputs":[{"ename":"NameError","evalue":"name 'cv' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMOLT-4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m result \u001b[39m=\u001b[39m cv(data_set\u001b[39m=\u001b[39mdataset, n\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, num_epoch\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'cv' is not defined"]}],"source":["dataset = \"MOLT-4\"\n","result = cv(data_set=dataset, n=5, num_epoch=300)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kQ2aKlYWuoWu"},"outputs":[],"source":["dataset = \"Yeast\"\n","\n","result = cv(data_set=dataset, n=5, num_epoch=300)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wvPa6LRTeHNV"},"outputs":[],"source":["dataset = \"PROTEINS\"\n","\n","result = cv(data_set=dataset, n=5, num_epoch=300)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"02JQHyrKeHZQ"},"outputs":[],"source":["dataset = \"ENZYMES\"\n","result = cv(data_set=dataset, n=5, num_epoch=1000, num_classes=6)\n"]},{"cell_type":"markdown","metadata":{"id":"MkXXxkIy1jL3"},"source":["# Regression\n","* investigate single and multiclass regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmC-WhjxzF-j"},"outputs":[],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","import rdkit as rdkit\n","\n","def load_data(dataset, split = 20 ):\n","  path = '.'\n","  dataset = TUDataset(path, name=dataset).shuffle()\n","\n","  train_dataset = dataset[len(dataset) // split:]\n","  test_dataset = dataset[:len(dataset) // split]\n","\n","  print(f'Train Dataset: {train_dataset}:')\n","  print('======================')\n","  print(f'Number of graphs: {len(train_dataset)}')\n","  print(f'Number of features: {train_dataset.num_features}')\n","  print(f'Number of classes: {train_dataset.num_classes}')\n","\n","  print(f'Test Dataset: {test_dataset}:')\n","  print('======================')\n","  print(f'Number of graphs: {len(test_dataset)}')\n","  print(f'Number of features: {test_dataset.num_features}')\n","  print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","  test_loader = DataLoader(test_dataset, batch_size=64)\n","  train_loader = DataLoader(train_dataset, batch_size=64)\n","\n","  return test_loader, train_loader, dataset, train_dataset, test_dataset \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"skB9vvQuzxC3"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","import sklearn.metrics as metrics\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim, dataset):\n","        super(Net, self).__init__()\n","        num_features = dataset.num_features\n","        self.dim = dim\n","\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return torch.sigmoid(x)\n","\n","def train(epoch, model, factor, device, train_loader, optimizer, split = 20, num_classes = 2):\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    mae = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = data.y/factor[0]\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch).flatten()\n","        loss = torch.nn.MSELoss()\n","        loss = loss(output_probs, data.y)\n","        loss_mae = torch.nn.L1Loss()\n","        mae += loss_mae(output_probs, data.y).item()\n","        loss.backward()\n","        optimizer.step()\n","        torch.cuda.empty_cache()\n","    return mae/len(train_loader)\n","\n","\n","def test(loader, epoch, model, device, test=False):\n","    model.eval()\n","\n","    mae = 0\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = data.y/factor[0]\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        loss_mae = torch.nn.L1Loss()\n","        mae += loss_mae(output_probs, data.y).item()\n","        torch.cuda.empty_cache()\n","    return mae/len(loader)\n","\n","def normalization_factor(data_set, num_classes): \n","  import numpy as np\n","  import torch.nn.functional as F\n","  y = np.zeros((len(data_set),1, num_classes))\n","  for i in range(len(data_set)):\n","    y[i, :, :] = data_set[i].y\n","  factor = np.zeros((num_classes))\n","  for i in range(num_classes): \n","    norm = np.linalg.norm(y[:,0,i], ord=2)\n","    factor[i] = norm\n","  return factor\n","\n","def cv_regression(data_set, n=5, num_epoch=250, num_classes = 2):\n","  result = {}\n","  test_mae = []\n","  test_mse = []\n","  train_mae = [] \n","  tmp = {}\n","  \n","  for i in range(n):\n","    test_loader, train_loader, dataset, train_dataset, test_dataset  = load_data(dataset=data_set)\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model = Net(dim=364, dataset=dataset).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n","    factor = normalization_factor(data_set = dataset, num_classes=num_classes)\n","    for epoch in range(1, num_epoch):\n","        loss = train(epoch=epoch, model=model, factor = factor, device=device, optimizer=optimizer, train_loader=train_loader, num_classes = num_classes)\n","        train_mae.append(train_loss.cpu().tolist())\n","        #train_acc = test(train_loader, device=device, model=model, epoch=epoch)\n","        ts_mse, ts_mae = test(test_loader, device=device, model=model, epoch=epoch, test=True)\n","        test_mse.append(ts_mse.cpu().tolist())\n","        test_mae.append(ts_mase.cupu().tolist())\n","        print('Epoch: {:03d}, Train Loss: {:.7f}, '\n","              'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n","                                                           train_acc, test_acc))\n","        y = np.zeros((len(test_dataset)))\n","        x = np.loadtxt(\"MCF-7_epoch\"+str(epoch)+\".csv\")\n","        for i in range(len(test_dataset)):\n","          y[i] = test_dataset[i].y\n","        y = torch.as_tensor(y)\n","        y = F.one_hot(y.long(), num_classes = num_classes).long()\n","        store_auc = []\n","        for i in range(len(x[0,:])): \n","          auc = metrics.roc_auc_score(y[:,i], x[:,i])\n","          print(\"AUC of \"+str(i) +\"is:\", auc)\n","          store_auc.append(auc)\n","        auc_store.append(store_auc)\n","        \n","        if auc >=0.9:\n","          break\n","        tmp[\"MAE Train\"] = list(loss_store)\n","        tmp[\"MAE Test\"] = list(acc_store)\n","        tmp[\"MSE Test\"] = auc_store\n","    result[str(i)] = tmp \n","          \n","  return result \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496},"executionInfo":{"elapsed":4,"status":"error","timestamp":1642184465990,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"aGRu56cF9WED","outputId":"baa007e8-607e-4dee-ed69-8ca40acf6d35"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-cf90815a20c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ZINC_full\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/CARATE_RESULTS/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"2_20split.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-ca86f700392e>\u001b[0m in \u001b[0;36mcv_regression\u001b[0;34m(data_set, n, num_epoch, num_classes)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m364\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"]}],"source":["dataset = \"ZINC_full\"\n","result = cv_regression(data_set=dataset, n=5, num_epoch=250, num_classes=1)\n","import csv\n","with open(\"/content/drive/MyDrive/CARATE_RESULTS/\"+dataset+\"2_20split.csv\", 'w') as f:\n","    w = csv.writer(f)\n","    for k, v in result.items():\n","        w.writerow([k, v])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":659},"executionInfo":{"elapsed":34050,"status":"error","timestamp":1642447512286,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"fXr5xB7hAwoR","outputId":"92d428ed-9935-4e1a-95f2-8de61cf7745e"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/alchemy_full.zip\n","Extracting ./alchemy_full/alchemy_full.zip\n","Processing...\n","Done!\n"]},{"name":"stdout","output_type":"stream","text":["Train Dataset: alchemy_full(192451):\n","======================\n","Number of graphs: 192451\n","Number of features: 6\n","Number of classes: 12\n","Test Dataset: alchemy_full(10128):\n","======================\n","Number of graphs: 10128\n","Number of features: 6\n","Number of classes: 12\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n"]},{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-346ea8b52695>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"alchemy_full\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/CARATE_RESULTS/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_20split.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-3b2b27d846d6>\u001b[0m in \u001b[0;36mcv_regression\u001b[0;34m(data_set, n, num_epoch, num_classes)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalization_factor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m364\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.000005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-3b2b27d846d6>\u001b[0m in \u001b[0;36mnormalization_factor\u001b[0;34m(data_set, num_classes)\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m   \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (1,12) into shape (1,1)"]}],"source":["dataset = \"alchemy_full\"\n","result = cv_regression(data_set=dataset, n=5, num_epoch=250, num_classes=1)\n","import csv\n","with open(\"/content/drive/MyDrive/CARATE_RESULTS/\"+dataset+\"_20split.csv\", 'w') as f:\n","    w = csv.writer(f)\n","    for k, v in result.items():\n","        w.writerow([k, v])"]},{"cell_type":"markdown","metadata":{"id":"Q7qry4p71l4h"},"source":["## ZINC"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Bkdrqlq1qDL"},"outputs":[],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","import rdkit as rdkit\n","\n","\n","def load_data(data_set):\n","  path = '.'\n","  dataset = TUDataset(path, name=data_set).shuffle()\n","\n","  train_dataset = dataset[len(dataset) // 20:]\n","  test_dataset = dataset[:len(dataset) // 20]\n","\n","  print(f'Train Dataset: {train_dataset}:')\n","  print('======================')\n","  print(f'Number of graphs: {len(train_dataset)}')\n","  print(f'Number of features: {train_dataset.num_features}')\n","  print(f'Number of classes: {train_dataset.num_classes}')\n","\n","  print(f'Test Dataset: {test_dataset}:')\n","  print('======================')\n","  print(f'Number of graphs: {len(test_dataset)}')\n","  print(f'Number of features: {test_dataset.num_features}')\n","  print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","  test_loader = DataLoader(test_dataset, batch_size=64)\n","  train_loader = DataLoader(train_dataset, batch_size=64)\n","  return test_loader, train_loader, dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TiFWzHAXEEnY"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv, BatchNorm\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim, dataset):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","        #self.norm1 = BatchNorm(num_features)\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, 1)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return x\n","\n","def train(model, epoch, train_loader, optimizer, device, factor, num_classes):\n","\n","    model.train()\n","\n","    if epoch == 51:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    mae = 0\n","    mse = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = data.y/factor[0]\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch).flatten()\n","        loss = torch.nn.MSELoss()\n","        loss = loss(torch.reshape(output_probs, (-1,)), torch.reshape(data.y, (-1,)))\n","        #mse += loss.item()\n","        loss_mae = torch.nn.L1Loss()\n","        mae += loss_mae(torch.reshape(output_probs, (-1,)), torch.reshape(data.y, (-1,))).item()\n","        loss.backward()\n","        optimizer.step()\n","        torch.cuda.empty_cache()\n","    return mae/len(train_loader)\n","\n","def test(model, loader, device, factor, num_classes):\n","    model.eval()\n","\n","    mae = 0\n","    mse = 0\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = data.y/factor[0]\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        loss_mae = torch.nn.L1Loss()\n","        mae += loss_mae(torch.reshape(output_probs, (-1,)),torch.reshape(data.y, (-1,))).item()\n","        loss = torch.nn.MSELoss()\n","        mse += loss(torch.reshape(output_probs, (-1,)), torch.reshape(data.y, (-1,))).item()\n","        torch.cuda.empty_cache()\n","    return mae/len(loader), mse/len(loader)\n","\n","def normalization_factor(data_set, num_classes): \n","  import numpy as np\n","  import torch.nn.functional as F\n","  y = np.zeros((len(data_set),1, num_classes))\n","  for i in range(len(data_set)):\n","    y[i, :, :] = data_set[i].y\n","  factor = np.zeros((num_classes))\n","  for i in range(num_classes): \n","    norm = np.linalg.norm(y[:,0,i], ord=2)\n","    factor[i] = norm\n","  return factor\n","\n","def save_result(dataset, result): \n","  import csv\n","  with open(\"/content/drive/MyDrive/CARATE_RESULTS/\"+dataset+\"_20split.csv\", 'w') as f:\n","      w = csv.writer(f)\n","      for k, v in result.items():\n","          w.writerow([k, v])\n","def cv_regression(data_set, n = 5, num_epoch=150, num_classes=1): \n","  result = {}\n","  test_mae = []\n","  test_mse = []\n","  train_mae = [] \n","  train_mse = [] \n","  tmp = {}\n","  \n","  for i in range(n):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    train_loader, test_loader, dataset = load_data(data_set=data_set)\n","    factor = normalization_factor(data_set=dataset, num_classes=1)\n","    model = Net(dim=364, dataset=dataset).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.000005)\n","    for epoch in range(1, num_epoch):\n","        mae = train(model=model, epoch=epoch, optimizer=optimizer, train_loader=train_loader, device=device, factor=factor, num_classes = num_classes)\n","        train_mae_val, train_mse_val = test(model, loader=train_loader, device=device, factor=factor, num_classes = num_classes)\n","        test_mae_val, test_mse_val = test(model, loader=test_loader, device=device, factor=factor, num_classes = num_classes)\n","        train_mae.append(train_mae_val)\n","        train_mse.append(train_mse_val)\n","        test_mse.append(test_mae_val)\n","        test_mse.append(test_mse_val)\n","\n","        print('Epoch: {:03d}, Train MAE, MSE at epoch: ({:.7f}, {:.7f}), Test MAE, MSE at epoch: ({:.7f}, {:.7f})'.format(epoch, train_mae_val,\n","                                                      train_mse_val, test_mae_val, test_mse_val))\n","        torch.cuda.empty_cache()\n","\n","    tmp[\"MAE Train\"] = list(train_mae)\n","    tmp[\"MSE Train\"] = list(train_mse)\n","    tmp[\"MAE Test\"] = list(train_mae)\n","    tmp[\"MSE Test\"] = list(train_mse)\n","    result[str(i)] = tmp \n","    save_result(dataset=data_set, result=result)\n","  return result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":694},"executionInfo":{"elapsed":155643,"status":"error","timestamp":1642447762142,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"h82-ggqYpcev","outputId":"ec226a8a-e9b3-40e3-9b9b-9b5d3141bdf1"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/ZINC_full.zip\n","Extracting ./ZINC_full/ZINC_full.zip\n","Processing...\n","Done!\n"]},{"name":"stdout","output_type":"stream","text":["Train Dataset: ZINC_full(236984):\n","======================\n","Number of graphs: 236984\n","Number of features: 28\n","Number of classes: 247313\n","Test Dataset: ZINC_full(12472):\n","======================\n","Number of graphs: 12472\n","Number of features: 28\n","Number of classes: 247313\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 001, Train MAE, MSE at epoch: (0.0297123, 0.0012545), Test MAE, MSE at epoch: (0.0297109, 0.0012496)\n","Epoch: 002, Train MAE, MSE at epoch: (0.0279458, 0.0010718), Test MAE, MSE at epoch: (0.0279541, 0.0010793)\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-8774c149c9cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ZINC_full\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/CARATE_RESULTS/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"1_20split.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-3b2b27d846d6>\u001b[0m in \u001b[0;36mcv_regression\u001b[0;34m(data_set, n, num_epoch, num_classes)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mtrain_mae_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mse_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mtest_mae_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mse_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mtrain_mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mae_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-3b2b27d846d6>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, loader, device, factor, num_classes)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/loader/dataloader.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             return Batch.from_data_list(batch, self.follow_batch,\n\u001b[0;32m---> 20\u001b[0;31m                                         self.exclude_keys)\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/batch.py\u001b[0m in \u001b[0;36mfrom_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0madd_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mfollow_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mexclude_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         )\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# Collate attributes into a unified representation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             value, slices, incs = _collate(attr, values, data_list, stores,\n\u001b[0;32m---> 86\u001b[0;31m                                            increment)\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36m_collate\u001b[0;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_dim\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mincrement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mincs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_incs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mincs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36mget_incs\u001b[0;34m(key, values, data_list, stores)\u001b[0m\n\u001b[1;32m    220\u001b[0m     repeats = [\n\u001b[1;32m    221\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     ]\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    220\u001b[0m     repeats = [\n\u001b[1;32m    221\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     ]\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__inc__\u001b[0;34m(self, key, value, *args, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__inc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'batch'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["dataset = \"ZINC_full\"\n","result = cv_regression(data_set=dataset, n=1, num_epoch=250, num_classes=1)\n","import csv\n","with open(\"/content/drive/MyDrive/CARATE_RESULTS/\"+dataset+\"5_20split.csv\", 'w') as f:\n","    w = csv.writer(f)\n","    for k, v in result.items():\n","        w.writerow([k, v])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGuuk0zumxoe"},"outputs":[],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","import rdkit as rdkit\n","\n","\n","def load_data(data_set):\n","  path = '.'\n","  dataset = TUDataset(path, name=data_set).shuffle()\n","\n","  train_dataset = dataset[len(dataset) // 10:]\n","  test_dataset = dataset[:len(dataset) // 10]\n","\n","  print(f'Train Dataset: {train_dataset}:')\n","  print('======================')\n","  print(f'Number of graphs: {len(train_dataset)}')\n","  print(f'Number of features: {train_dataset.num_features}')\n","  print(f'Number of classes: {train_dataset.num_classes}')\n","\n","  print(f'Test Dataset: {test_dataset}:')\n","  print('======================')\n","  print(f'Number of graphs: {len(test_dataset)}')\n","  print(f'Number of features: {test_dataset.num_features}')\n","  print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","  test_loader = DataLoader(test_dataset, batch_size=64)\n","  train_loader = DataLoader(train_dataset, batch_size=64)\n","  return test_loader, train_loader, dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MNVwMGOqgKMk"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv, BatchNorm\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim, dataset):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","        #self.norm1 = BatchNorm(num_features)\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return x\n","        \n","\n","def train(model, epoch, train_loader, optimizer, device, std, mean, num_classes):\n","\n","    model.train()\n","\n","    if epoch % 51 == 0:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    mae = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        #data.y = (data.y)/factor\n","        data.y = (data.y.numpy()-mean)/std\n","        data.y = torch.from_numpy(data.y).type(torch.FloatTensor)\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        loss = torch.nn.MSELoss()\n","       # print(data.y.shape)\n","        loss = loss(output_probs, data.y)\n","        #loss_mae = torch.nn.L1Loss()\n","        #mae += loss_mae(output_probs, data.y).item()\n","        mse = loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        #error += torch.linalg.norm(output_probs - data.y, ord = 1)/32\n","        torch.cuda.empty_cache()\n","    return mse/len(train_loader)\n","\n","def test(model, loader, device, std, mean, num_classes):\n","    model.eval()\n","\n","    mae = 0\n","    mse = 0\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = (data.y.numpy()-mean)/std\n","        data.y = torch.from_numpy(data.y).type(torch.FloatTensor)\n","\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        #error += torch.linalg.norm(output_probs - data.y, ord = 1)/32\n","        loss = torch.nn.MSELoss()\n","        loss = loss(output_probs, data.y)\n","        mse += loss.item()\n","        loss_mae = torch.nn.L1Loss()\n","        mae += loss_mae(output_probs, data.y).item()\n","        torch.cuda.empty_cache()\n","    return (mae/len(loader), mse/len(loader))\n","\n","def normalization_factor(data_set, num_classes): \n","  import numpy as np\n","  import torch.nn.functional as F\n","  y = np.zeros((len(data_set),1, num_classes))\n","  for i in range(len(data_set)):\n","    y[i, :] = data_set[i].y\n","  factor = np.zeros((1,1,num_classes))\n","  mean = np.zeros((1,1,num_classes))\n","  std = np.zeros((1,1,num_classes))\n","  for i in range(num_classes): \n","    norm = np.linalg.norm(y[:,0,i], ord=2)\n","    factor[:,:,i] =  norm\n","    mean[:,:,i] =   np.mean(y[:,0,i])\n","    std[:,:,i] = np.std(y[:,0,i])\n","    return factor, mean, std\n","\n","def save_result(dataset, result): \n","  import csv\n","  with open(\"/content/drive/MyDrive/CARATE_RESULTS/\"+dataset+\"_20split.csv\", 'w') as f:\n","      w = csv.writer(f)\n","      for k, v in result.items():\n","          w.writerow([k, v])\n","def cv_regression(data_set, n = 5, num_epoch=150, num_classes=1): \n","  result = {}\n","  test_mae = []\n","  test_mse = []\n","  train_mae = [] \n","  train_mse = [] \n","  tmp = {}\n","  \n","  for i in range(n):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    train_loader, test_loader, dataset = load_data(data_set=data_set)\n","    factor, mean, std = normalization_factor(data_set=dataset, num_classes=num_classes)\n","    model = Net(dim=364, dataset=dataset).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.000005)\n","    for epoch in range(1, num_epoch):\n","        mae = train(model=model, epoch=epoch, optimizer=optimizer, train_loader=train_loader, device=device, mean= mean, std=std, num_classes = num_classes)\n","        train_mae_val, train_mse_val = test(model, loader=train_loader, device=device, mean= mean, std=std, num_classes = num_classes)\n","        test_mae_val, test_mse_val = test(model, loader=test_loader, device=device, mean= mean, std=std, num_classes = num_classes)\n","        train_mae.append(train_mae_val)\n","        train_mse.append(train_mse_val)\n","        test_mse.append(test_mae_val)\n","        test_mse.append(test_mse_val)\n","\n","        print('Epoch: {:03d}, Train MAE, MSE at epoch: ({:.7f}, {:.7f}), Test MAE, MSE at epoch: ({:.7f}, {:.7f})'.format(epoch, train_mae_val,\n","                                                      train_mse_val, test_mae_val, test_mse_val))\n","        torch.cuda.empty_cache()\n","\n","    tmp[\"MAE Train\"] = list(train_mae)\n","    tmp[\"MSE Train\"] = list(train_mse)\n","    tmp[\"MAE Test\"] = list(train_mae)\n","    tmp[\"MSE Test\"] = list(train_mse)\n","    result[str(i)] = tmp \n","    save_result(dataset=data_set, result=result)\n","  return result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c90A4CrjhCdd","outputId":"78796c77-55bc-4a6d-d7a0-fc977f1a1169"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading https://www.chrsmrrs.com/graphkerneldatasets/alchemy_full.zip\n","Extracting ./alchemy_full/alchemy_full.zip\n","Processing...\n","Done!\n"]},{"name":"stdout","output_type":"stream","text":["Train Dataset: alchemy_full(182322):\n","======================\n","Number of graphs: 182322\n","Number of features: 6\n","Number of classes: 12\n","Test Dataset: alchemy_full(20257):\n","======================\n","Number of graphs: 20257\n","Number of features: 6\n","Number of classes: 12\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: RuntimeWarning: divide by zero encountered in true_divide\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1, 64, 12])) that is different to the input size (torch.Size([64, 12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1, 33, 12])) that is different to the input size (torch.Size([33, 12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:72: RuntimeWarning: divide by zero encountered in true_divide\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:97: UserWarning: Using a target size (torch.Size([1, 64, 12])) that is different to the input size (torch.Size([64, 12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.l1_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:97: UserWarning: Using a target size (torch.Size([1, 33, 12])) that is different to the input size (torch.Size([33, 12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.l1_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([1, 50, 12])) that is different to the input size (torch.Size([50, 12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:97: UserWarning: Using a target size (torch.Size([1, 50, 12])) that is different to the input size (torch.Size([50, 12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.l1_loss(input, target, reduction=self.reduction)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 001, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 002, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 003, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 004, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 005, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 006, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 007, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 008, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 009, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 010, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 011, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 012, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 013, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 014, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 015, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 016, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 017, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 018, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 019, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 020, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 021, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 022, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 023, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 024, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 025, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 026, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 027, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 028, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 029, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 030, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 031, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 032, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 033, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 034, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 035, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 036, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 037, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 038, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 039, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 040, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 041, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 042, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 043, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 044, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 045, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 046, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 047, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 048, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 049, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 050, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 051, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 052, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 053, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 054, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 055, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 056, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 057, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 058, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 059, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 060, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 061, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 062, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 063, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 064, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 065, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 066, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 067, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 068, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 069, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 070, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 071, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 072, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 073, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n","Epoch: 074, Train MAE, MSE at epoch: (nan, nan), Test MAE, MSE at epoch: (nan, nan)\n"]}],"source":["data_name = \"alchemy_full\"\n","result = cv_regression(data_set=data_name, n=1, num_epoch=250, num_classes=12)\n","import csv\n","with open(\"/content/drive/MyDrive/CARATE_RESULTS/\"+data_name+\"1_10split.csv\", 'w') as f:\n","    w = csv.writer(f)\n","    for k, v in result.items():\n","        w.writerow([k, v])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rqSZE3fSI9kd"},"outputs":[],"source":["# Apparently, the algorithm converges to numerical accuracy"]},{"cell_type":"markdown","metadata":{"id":"Ki5tSuaY1l7R"},"source":["## Alchemy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cc8APdfO1vDl"},"outputs":[],"source":["from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import TUDataset\n","import torch\n","import rdkit as rdkit\n","\n","path = '.'\n","dataset = TUDataset(path, name=\"alchemy_full\").shuffle()\n","train_dataset = dataset[len(dataset) // 20:]\n","test_dataset = dataset[:len(dataset) // 20]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1642491817688,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"bi9xsNVrR1-h","outputId":"fa3f0d65-51ed-4ea7-f1ed-f1ba60da1604"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Dataset: alchemy_full(192451):\n","======================\n","Number of graphs: 192451\n","Number of features: 6\n","Number of classes: 12\n","Test Dataset: alchemy_full(10128):\n","======================\n","Number of graphs: 10128\n","Number of features: 6\n","Number of classes: 12\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n","  warnings.warn(out)\n"]}],"source":["print(f'Train Dataset: {train_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(train_dataset)}')\n","print(f'Number of features: {train_dataset.num_features}')\n","print(f'Number of classes: {train_dataset.num_classes}')\n","\n","print(f'Test Dataset: {test_dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(test_dataset)}')\n","print(f'Number of features: {test_dataset.num_features}')\n","print(f'Number of classes: {test_dataset.num_classes}')\n","\n","\n","\n","test_loader = DataLoader(test_dataset, batch_size=64)\n","train_loader = DataLoader(train_dataset, batch_size=64)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18661,"status":"ok","timestamp":1642491837741,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"jQ8i_2doaOb5","outputId":"4a734a0b-fb3d-4dcd-b150-19a1c93c6a2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["-15.716988681808667\n","[[[8.61489461e+01 2.83672304e-02 1.08626915e+02 2.28857479e+05\n","   1.03899945e+02 2.28836977e+05 4.21827207e+04 2.28841587e+05\n","   2.28836566e+05 2.03088601e+01 1.39834646e+03 7.75887194e+05]]]\n","72.92028404696889\n","[[[ 2.61137958e-03  2.72144998e-03  2.54694320e-03 ...  7.01687034e-04\n","    1.75037497e-03  3.18982244e-03]]\n","\n"," [[ 3.22365996e-03  2.74260130e-03  3.05092980e-03 ...  4.14751281e-03\n","    9.45250282e-05  2.42749971e-03]]\n","\n"," [[ 2.58331369e-03  2.35482979e-03  2.20499279e-03 ...  2.55638449e-03\n","    1.35500355e-03  2.30521719e-03]]\n","\n"," ...\n","\n"," [[ 2.07553955e-03  2.21382197e-03  1.81698601e-03 ... -1.14862677e-03\n","    1.92178836e-03  3.81268363e-03]]\n","\n"," [[ 3.55083604e-03  3.08807016e-03  3.03673330e-03 ...  3.43613907e-03\n","    1.16309696e-03  3.38122946e-03]]\n","\n"," [[ 1.92963871e-03  2.30900218e-03  1.76669059e-03 ... -1.39286233e-03\n","    1.91557720e-03  4.01155658e-03]]]\n","tensor([[ 0.0018,  0.0020,  0.0019, -0.0017, -0.0022, -0.0017,  0.0021, -0.0017,\n","         -0.0017, -0.0009,  0.0009,  0.0016]], dtype=torch.float64)\n"]}],"source":["import numpy as np\n","import torch.nn.functional as F\n","y = np.zeros((len(dataset),1, 12))\n","for i in range(len(dataset)):\n","  y[i, :, :] = dataset[i].y\n","factor = np.zeros((1,1,12))\n","add = np.zeros((1,1,12))\n","std = np.zeros((1,1,12))\n","for i in range(12): \n","  norm = np.linalg.norm(y[:,0,i], ord=2)\n","  factor[:,:,i] =  norm\n","  add[:,:,i] =   np.mean(y[:,0,i])\n","  std[:,:,i] = np.std(y[:,0,i])\n","print(np.mean(add))\n","print(factor)\n","print(np.mean(std))\n","print(y/factor)\n","print(dataset[789].y/factor[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11592727,"status":"ok","timestamp":1642508348433,"user":{"displayName":"Julian M. Kleber","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12777262448935374285"},"user_tz":-60},"id":"eP6N4BSy1viT","outputId":"9ca232ba-1c45-4f4c-f396-0a90c11bb3db"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 001, Train Loss at epoch: 0.0014489, Train MAE, MSE at epoch: (0.0005177858969971644,7.273566194733254e-07), Test MAE,MSE at epoch: (0.000513349596774147,7.15892937729886e-07)\n","Epoch: 002, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0005043527221556709,6.811765327021799e-07), Test MAE,MSE at epoch: (0.0004997818268405028,6.698086388427808e-07)\n","Epoch: 003, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0005300315530822697,6.711402049238726e-07), Test MAE,MSE at epoch: (0.0005261032481871123,6.620683938359983e-07)\n","Epoch: 004, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006528387998224253,8.27719101221766e-07), Test MAE,MSE at epoch: (0.0006469085270029334,8.14835625433204e-07)\n","Epoch: 005, Train Loss at epoch: 0.0000299, Train MAE, MSE at epoch: (0.0005049738928720855,6.831383454853263e-07), Test MAE,MSE at epoch: (0.0005005324457452849,6.713595436002999e-07)\n","Epoch: 006, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0005627817631164439,7.246779091701078e-07), Test MAE,MSE at epoch: (0.0005574931479176308,7.12305778369279e-07)\n","Epoch: 007, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006643442618835562,8.375009254045702e-07), Test MAE,MSE at epoch: (0.0006582035453193499,8.244323482570239e-07)\n","Epoch: 008, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.000676599152668248,8.514174530983883e-07), Test MAE,MSE at epoch: (0.0006703072481601259,8.38150133861877e-07)\n","Epoch: 009, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.000676705269684812,8.515306084274667e-07), Test MAE,MSE at epoch: (0.000670411809253852,8.382616048787803e-07)\n","Epoch: 010, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045849707582,8.515299853608565e-07), Test MAE,MSE at epoch: (0.0006704111140566942,8.382609756686094e-07)\n","Epoch: 011, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 012, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 013, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 014, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 015, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 016, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 017, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 018, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 019, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 020, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 021, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 022, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 023, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 024, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 025, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 026, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 027, Train Loss at epoch: 0.0000312, Train MAE, MSE at epoch: (0.005728622082004106,5.978795010295993e-05), Test MAE,MSE at epoch: (0.0057221770157697815,5.9657375218966136e-05)\n","Epoch: 028, Train Loss at epoch: 0.0000008, Train MAE, MSE at epoch: (0.0005453718223334557,7.239615904400077e-07), Test MAE,MSE at epoch: (0.0005407479281226794,7.119567951705457e-07)\n","Epoch: 029, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006205646115941295,7.996613156800223e-07), Test MAE,MSE at epoch: (0.0006146345865244995,7.86835941922252e-07)\n","Epoch: 030, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006726718757682705,8.473077306825811e-07), Test MAE,MSE at epoch: (0.0006664212739663257,8.341167007523573e-07)\n","Epoch: 031, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767938433806696,8.516240753354388e-07), Test MAE,MSE at epoch: (0.0006705008127943338,8.383553986649353e-07)\n","Epoch: 032, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767065990177488,8.515320728447066e-07), Test MAE,MSE at epoch: (0.0006704131370474754,8.382630699374627e-07)\n","Epoch: 033, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045829969612,8.515299801073756e-07), Test MAE,MSE at epoch: (0.0006704111147888661,8.382609685184937e-07)\n","Epoch: 034, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 035, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 036, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 037, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 038, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 039, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 040, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 041, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 042, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 043, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 044, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 045, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 046, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 047, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 048, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 049, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 001, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 002, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 003, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 004, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 005, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 006, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 007, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 008, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 009, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 010, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 011, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 012, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 013, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 014, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 015, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 016, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 017, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 018, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 019, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 020, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 021, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 022, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 023, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 024, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 025, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 026, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 027, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 028, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 029, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 030, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 031, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 032, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 033, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 034, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 035, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 036, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 037, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 038, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 039, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 040, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 041, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 042, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 043, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 044, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 045, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 046, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 047, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 048, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 049, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 001, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 002, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 003, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 004, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 005, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 006, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 007, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 008, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 009, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 010, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 011, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 012, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 013, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 014, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 015, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 016, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 017, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 018, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 019, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 020, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 021, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 022, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 023, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 024, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 025, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 026, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 027, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 028, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 029, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 030, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 031, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 032, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 033, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 034, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 035, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 036, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 037, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 038, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 039, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 040, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 041, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 042, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 043, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 044, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 045, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 046, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 047, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 048, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 049, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 001, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 002, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 003, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 004, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 005, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 006, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 007, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 008, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 009, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 010, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 011, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 012, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 013, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 014, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 015, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 016, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 017, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 018, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 019, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 020, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 021, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 022, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 023, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 024, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 025, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 026, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 027, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 028, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 029, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 030, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 031, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 032, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 033, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 034, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 035, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 036, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 037, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 038, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 039, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 040, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 041, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 042, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 043, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 044, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 045, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 046, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 047, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 048, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 049, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 001, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 002, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 003, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 004, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 005, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 006, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 007, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 008, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 009, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 010, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 011, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 012, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 013, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 014, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 015, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 016, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 017, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 018, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 019, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 020, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 021, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 022, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 023, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 024, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 025, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 026, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 027, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 028, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 029, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 030, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 031, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 032, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 033, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 034, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 035, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 036, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 037, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 038, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 039, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 040, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 041, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 042, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 043, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 044, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 045, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 046, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 047, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 048, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n","Epoch: 049, Train Loss at epoch: 0.0000007, Train MAE, MSE at epoch: (0.0006767045548026255,8.515299590934523e-07), Test MAE,MSE at epoch: (0.0006704110847698208,8.38260943850595e-07)\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import Linear\n","\n","from torch_geometric.nn import global_add_pool, GraphConv, GATConv, BatchNorm\n","\n","class Net(torch.nn.Module):\n","    def __init__(self, dim):\n","        super(Net, self).__init__()\n","\n","        num_features = dataset.num_features\n","        self.dim = dim\n","        #self.norm1 = BatchNorm(num_features)\n","        self.conv1 = GraphConv(num_features, dim)\n","        #self.conv2 = GraphConv(dim, dim)\n","        self.conv3 = GATConv(dim, dim, dropout = 0.6)\n","        self.conv5 = GraphConv(dim, dim)\n","\n","        self.fc1 = Linear(dim, dim)\n","        self.fc2 = Linear(dim, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch, edge_weight=None):\n","        x = F.relu(self.conv1(x, edge_index, edge_weight))\n","        #x = F.relu(self.conv2(x, edge_index, edge_weight))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.conv3(x, edge_index, edge_weight))\n","        x = F.relu(self.conv5(x, edge_index, edge_weight))\n","        x = global_add_pool(x, batch)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.fc2(x)\n","        return x\n","\n","def train(epoch):\n","\n","    model.train()\n","\n","    if epoch % 51 == 0:\n","        for param_group in optimizer.param_groups:\n","            param_group['lr'] = 0.5 * param_group['lr']\n","\n","    mse = 0\n","    for data in train_loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        #data.y = (data.y)/factor\n","        data.y = (data.y.numpy())/factor\n","        data.y = torch.from_numpy(data.y).type(torch.FloatTensor)\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        loss = torch.nn.MSELoss()\n","       # print(data.y.shape)\n","        loss = loss(output_probs, data.y[0,:,:])\n","        #loss_mae = torch.nn.L1Loss()\n","        #mae += loss_mae(output_probs, data.y).item()\n","        mse += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        #error += torch.linalg.norm(output_probs - data.y, ord = 1)/32\n","        torch.cuda.empty_cache()\n","    return mse/len(train_loader)\n","\n","def test(loader):\n","    model.eval()\n","\n","    mae = 0\n","    mse = 0\n","    for data in loader:\n","        data.x = data.x.type(torch.FloatTensor)\n","        data.y = data.y.numpy()/factor[0]\n","        data.y = torch.from_numpy(data.y).type(torch.FloatTensor)\n","        data.y = torch.nan_to_num(data.y.type(torch.FloatTensor))\n","        data = data.to(device)\n","        output_probs = model(data.x, data.edge_index, data.batch)\n","        #error += torch.linalg.norm(output_probs - data.y, ord = 1)/32\n","        loss = torch.nn.MSELoss()\n","        loss = loss(output_probs, data.y)\n","        mse += loss.item()\n","        loss_mae = torch.nn.L1Loss()\n","        mae += loss_mae(output_probs, data.y).item()\n","        torch.cuda.empty_cache()\n","    return (mae/len(loader), mse/len(loader))\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net(dim=364).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","\n","tmp = {}\n","\n","\n","\n","for i in range(5):\n","  result = {}\n","  test_mae = []\n","  test_mse = []\n","  train_mae = [] \n","  train_mse = [] \n","  for epoch in range(1, 50):\n","      train_loss = train(epoch)\n","      train_mae_val, train_mse_val = test(train_loader)\n","      test_mae_val, test_mse_val = test(test_loader)\n","      train_mae.append(train_mae_val)\n","      train_mae.append(train_mse_val)\n","      test_mae.append(test_mae_val)\n","      test_mse.append(test_mse_val)\n","      print('Epoch: {:03d}, Train Loss at epoch: {:.7f}, '\n","            'Train MAE, MSE at epoch: ({},{}), Test MAE,MSE at epoch: ({},{})'.format(epoch, train_loss,\n","                                                    train_mae_val, train_mse_val, test_mae_val, test_mse_val))\n","      torch.cuda.empty_cache()\n","  tmp[\"MAE Train\"] = list(train_mae)\n","  tmp[\"MSE Train\"] = list(train_mse)\n","  tmp[\"MAE Test\"] = list(train_mae)\n","  tmp[\"MSE Test\"] = list(train_mse)\n","  result[str(i)] = tmp \n","  import csv\n","  with open(\"/content/drive/MyDrive/CARATE_RESULTS/\"+\"alchemy_full_\"+str(i)+\"_10split.csv\", 'w') as f:\n","      w = csv.writer(f)\n","      for k, v in result.items():\n","          w.writerow([k, v])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jD2dFEbAqE-3"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO3CnMTY2MFpAa+S6IlwFJD","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1ak3ytXVWx-5Xnidc7s5m37f4_C1vmHXP","name":"Kopie von Paper_Graph_karate.ipynb","provenance":[{"file_id":"1ak3ytXVWx-5Xnidc7s5m37f4_C1vmHXP","timestamp":1644327206126},{"file_id":"1tcpWE_dxJH21oLZ2MejrfidAW-X5Rq4g","timestamp":1640269934485}]},"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"},"vscode":{"interpreter":{"hash":"073ac225df8a8e7b4e029b39e0cb6096bf1899cb57b05e4577524dd487ed77e2"}}},"nbformat":4,"nbformat_minor":0}
